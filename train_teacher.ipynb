{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\fskd\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#필요한 라이브러리들 import\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import dataset\n",
    "import model\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각종 path및 하이퍼 파라미터 설정\n",
    "data_path = 'C:\\\\Users\\\\USER\\\\Desktop\\\\GSH_CRP\\\\codes\\\\rock_sci_paper\\\\data\\\\ro_sci_pa'\n",
    "save_path = 'C:\\\\Users\\\\USER\\\\Desktop\\\\GSH_CRP\\\\codes\\\\rock_sci_paper\\\\model_para'\n",
    "epochs = 200\n",
    "batch_size = 16\n",
    "learning_rate = 0.01\n",
    "seed = 0\n",
    "mode = 'hr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 설정\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# device 설정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform 설정\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomAffine((-45, 45), translate=(0.2,0.2)),\n",
    "    transforms.CenterCrop((224,224)),\n",
    "    transforms.ColorJitter(brightness=0.5),\n",
    "    transforms.ColorJitter(contrast=0.5),\n",
    "    transforms.ColorJitter(saturation=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]\n",
    ")\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.CenterCrop((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n",
      "36\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "# dataset 설정\n",
    "train_dataset = dataset.RockScissorsPaper(\n",
    "    transform=train_transform,\n",
    "    path = data_path,\n",
    "    mode = 'train'\n",
    ")\n",
    "val_dataset = dataset.RockScissorsPaper(\n",
    "    transform=test_transform,\n",
    "    path = data_path,\n",
    "    mode = 'val'\n",
    ")\n",
    "test_dataset = dataset.RockScissorsPaper(\n",
    "    transform=test_transform,\n",
    "    path = data_path,\n",
    "    mode = 'test'\n",
    ")\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader 설정\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델, 손실함수, 옵티마이저 설정\n",
    "model = model.ResNet18(num_classes=3)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    print('\\nEpoch: %d'%epoch)\n",
    "    # model train mode로 전환\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    total = 0\n",
    "    for (inputs, labels) in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if mode=='lr':\n",
    "            h,w = inputs.shape[-2], inputs.shape[-1]\n",
    "            lr_inputs = F.interpolate(inputs, (h//64, w//64))\n",
    "            lr_inputs = F.interpolate(lr_inputs, (h,w))\n",
    "            outputs, _, _, _, _ = model(lr_inputs)\n",
    "        else:\n",
    "            outputs, _, _, _, _ = model(inputs)\n",
    "            \n",
    "        _, pred = torch.max(outputs, 1)\n",
    "        total += outputs.size(0)\n",
    "        running_acc += (pred == labels).sum().item()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    total_loss = running_loss / len(trainloader)\n",
    "    total_acc = 100 * running_acc / total\n",
    "    print(f'Train epoch : {epoch} loss : {total_loss} Acc : {total_acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, loader, mode='val'):\n",
    "    print('\\nEpoch: %d'%epoch)\n",
    "    # model eval mode로 전환\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    total = 0\n",
    "    label_dict = {0:0, 1:0, 2:0}\n",
    "    global BEST_SCORE\n",
    "    with torch.no_grad():\n",
    "        for (inputs, labels) in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            if mode=='lr':\n",
    "                h,w = inputs.shape[-2], inputs.shape[-1]\n",
    "                lr_inputs = F.interpolate(inputs, (h//32, w//32))\n",
    "                lr_inputs = F.interpolate(lr_inputs, (h,w))\n",
    "                outputs, _, _, _, _ = model(lr_inputs)\n",
    "            else:\n",
    "                outputs, _, _, _, _ = model(inputs)\n",
    "\n",
    "            _, pred = torch.max(outputs, 1)\n",
    "            for label in labels:\n",
    "                label_dict[label.item()] += 1\n",
    "            total += outputs.size(0)\n",
    "            running_acc += (pred == labels).sum().item()\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "        total_loss = running_loss / len(loader)\n",
    "        total_acc = 100 * running_acc / total\n",
    "        print(label_dict)\n",
    "        if total_acc > BEST_SCORE and not mode=='test':\n",
    "            path = os.path.join(save_path, f'teacher.pth')\n",
    "            torch.save(model.state_dict(), path)\n",
    "            BEST_SCORE = total_acc\n",
    "        print(f'Test epoch : {epoch} loss : {total_loss} Acc : {total_acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "Train epoch : 0 loss : 1.2680220348494393 Acc : 30.555555555555557%\n",
      "\n",
      "Epoch: 0\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 0 loss : 1.1043172279993694 Acc : 38.888888888888886%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 1\n",
      "Train epoch : 1 loss : 1.2179593869618006 Acc : 34.25925925925926%\n",
      "\n",
      "Epoch: 1\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 1 loss : 1.1503300666809082 Acc : 25.0%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 2\n",
      "Train epoch : 2 loss : 1.1720827051571436 Acc : 39.81481481481482%\n",
      "\n",
      "Epoch: 2\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 2 loss : 1.3310232559839885 Acc : 25.0%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 3\n",
      "Train epoch : 3 loss : 1.220699327332633 Acc : 26.85185185185185%\n",
      "\n",
      "Epoch: 3\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 3 loss : 1.0743070840835571 Acc : 38.888888888888886%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 4\n",
      "Train epoch : 4 loss : 1.2019480807440621 Acc : 42.592592592592595%\n",
      "\n",
      "Epoch: 4\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 4 loss : 1.073360761006673 Acc : 36.111111111111114%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 5\n",
      "Train epoch : 5 loss : 1.1665459190096175 Acc : 31.48148148148148%\n",
      "\n",
      "Epoch: 5\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 5 loss : 1.1302417119344075 Acc : 25.0%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 6\n",
      "Train epoch : 6 loss : 1.1543971470424108 Acc : 28.703703703703702%\n",
      "\n",
      "Epoch: 6\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 6 loss : 1.1034278869628906 Acc : 36.111111111111114%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 7\n",
      "Train epoch : 7 loss : 1.1459856714521135 Acc : 37.03703703703704%\n",
      "\n",
      "Epoch: 7\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 7 loss : 1.4982599417368572 Acc : 25.0%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 8\n",
      "Train epoch : 8 loss : 1.170830249786377 Acc : 33.333333333333336%\n",
      "\n",
      "Epoch: 8\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 8 loss : 1.1338282028834026 Acc : 38.888888888888886%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 9\n",
      "Train epoch : 9 loss : 1.1770199707576208 Acc : 34.25925925925926%\n",
      "\n",
      "Epoch: 9\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 9 loss : 1.79599662621816 Acc : 25.0%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 10\n",
      "Train epoch : 10 loss : 1.1972016266414098 Acc : 37.03703703703704%\n",
      "\n",
      "Epoch: 10\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 10 loss : 1.3169016440709431 Acc : 25.0%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 11\n",
      "Train epoch : 11 loss : 1.2146232042993819 Acc : 31.48148148148148%\n",
      "\n",
      "Epoch: 11\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 11 loss : 1.1618876258532207 Acc : 38.888888888888886%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 12\n",
      "Train epoch : 12 loss : 1.1544980151312692 Acc : 36.111111111111114%\n",
      "\n",
      "Epoch: 12\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 12 loss : 1.1216872533162434 Acc : 38.888888888888886%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 13\n",
      "Train epoch : 13 loss : 1.1988469362258911 Acc : 30.555555555555557%\n",
      "\n",
      "Epoch: 13\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 13 loss : 1.2582833766937256 Acc : 27.77777777777778%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 14\n",
      "Train epoch : 14 loss : 1.1123668466295515 Acc : 42.592592592592595%\n",
      "\n",
      "Epoch: 14\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 14 loss : 1.1235084533691406 Acc : 38.888888888888886%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 15\n",
      "Train epoch : 15 loss : 1.1954550572804041 Acc : 31.48148148148148%\n",
      "\n",
      "Epoch: 15\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 15 loss : 1.4940333763758342 Acc : 25.0%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 16\n",
      "Train epoch : 16 loss : 1.1679952655519759 Acc : 37.03703703703704%\n",
      "\n",
      "Epoch: 16\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 16 loss : 1.1870705684026082 Acc : 27.77777777777778%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 17\n",
      "Train epoch : 17 loss : 1.2231558220727103 Acc : 31.48148148148148%\n",
      "\n",
      "Epoch: 17\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 17 loss : 1.3126674890518188 Acc : 36.111111111111114%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 18\n",
      "Train epoch : 18 loss : 1.2369753633226668 Acc : 26.85185185185185%\n",
      "\n",
      "Epoch: 18\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 18 loss : 1.3055909077326457 Acc : 38.888888888888886%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 19\n",
      "Train epoch : 19 loss : 1.1628727061407906 Acc : 36.111111111111114%\n",
      "\n",
      "Epoch: 19\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 19 loss : 1.1445815165837605 Acc : 38.888888888888886%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 20\n",
      "Train epoch : 20 loss : 1.2192040852137975 Acc : 30.555555555555557%\n",
      "\n",
      "Epoch: 20\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 20 loss : 1.3666208187739055 Acc : 25.0%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 21\n",
      "Train epoch : 21 loss : 1.1440641028540475 Acc : 40.74074074074074%\n",
      "\n",
      "Epoch: 21\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 21 loss : 1.2223755518595378 Acc : 25.0%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 22\n",
      "Train epoch : 22 loss : 1.1903989996228899 Acc : 29.62962962962963%\n",
      "\n",
      "Epoch: 22\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 22 loss : 1.1508186260859172 Acc : 25.0%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 23\n",
      "Train epoch : 23 loss : 1.114240084375654 Acc : 39.81481481481482%\n",
      "\n",
      "Epoch: 23\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 23 loss : 1.1090908249219258 Acc : 36.111111111111114%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 24\n",
      "Train epoch : 24 loss : 1.1428461585726057 Acc : 30.555555555555557%\n",
      "\n",
      "Epoch: 24\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 24 loss : 1.164460301399231 Acc : 13.88888888888889%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 25\n",
      "Train epoch : 25 loss : 1.1915872948510307 Acc : 31.48148148148148%\n",
      "\n",
      "Epoch: 25\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 25 loss : 1.160255988438924 Acc : 25.0%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 26\n",
      "Train epoch : 26 loss : 1.129594853946141 Acc : 33.333333333333336%\n",
      "\n",
      "Epoch: 26\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 26 loss : 1.1869794130325317 Acc : 25.0%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 27\n",
      "Train epoch : 27 loss : 1.1879263264792306 Acc : 30.555555555555557%\n",
      "\n",
      "Epoch: 27\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 27 loss : 1.2824569940567017 Acc : 36.111111111111114%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 28\n",
      "Train epoch : 28 loss : 1.1214971712657384 Acc : 33.333333333333336%\n",
      "\n",
      "Epoch: 28\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 28 loss : 1.1686631441116333 Acc : 38.888888888888886%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 29\n",
      "Train epoch : 29 loss : 1.1397425276892525 Acc : 37.96296296296296%\n",
      "\n",
      "Epoch: 29\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 29 loss : 1.1913143793741863 Acc : 25.0%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 30\n",
      "Train epoch : 30 loss : 1.1318737949643816 Acc : 34.25925925925926%\n",
      "\n",
      "Epoch: 30\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 30 loss : 1.3142462571461995 Acc : 25.0%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 31\n",
      "Train epoch : 31 loss : 1.115972365651812 Acc : 33.333333333333336%\n",
      "\n",
      "Epoch: 31\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 31 loss : 1.051149805386861 Acc : 38.888888888888886%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 32\n",
      "Train epoch : 32 loss : 1.1271818705967493 Acc : 37.03703703703704%\n",
      "\n",
      "Epoch: 32\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 32 loss : 1.17138667901357 Acc : 30.555555555555557%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 33\n",
      "Train epoch : 33 loss : 1.108939221927098 Acc : 37.96296296296296%\n",
      "\n",
      "Epoch: 33\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 33 loss : 1.0778220494588215 Acc : 33.333333333333336%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 34\n",
      "Train epoch : 34 loss : 1.1308551515851701 Acc : 34.25925925925926%\n",
      "\n",
      "Epoch: 34\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 34 loss : 1.2699801524480183 Acc : 38.888888888888886%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 35\n",
      "Train epoch : 35 loss : 1.1638728891100203 Acc : 43.51851851851852%\n",
      "\n",
      "Epoch: 35\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 35 loss : 1.3726833264033 Acc : 25.0%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 36\n",
      "Train epoch : 36 loss : 1.105019518307277 Acc : 40.74074074074074%\n",
      "\n",
      "Epoch: 36\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 36 loss : 1.3354884386062622 Acc : 25.0%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 37\n",
      "Train epoch : 37 loss : 1.1340969460351127 Acc : 34.25925925925926%\n",
      "\n",
      "Epoch: 37\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 37 loss : 1.1512286067008972 Acc : 25.0%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 38\n",
      "Train epoch : 38 loss : 1.1233901211193629 Acc : 31.48148148148148%\n",
      "\n",
      "Epoch: 38\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 38 loss : 1.3151744206746419 Acc : 25.0%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 39\n",
      "Train epoch : 39 loss : 1.1119703820773534 Acc : 37.96296296296296%\n",
      "\n",
      "Epoch: 39\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 39 loss : 1.251677393913269 Acc : 25.0%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 40\n",
      "Train epoch : 40 loss : 1.130415337426322 Acc : 37.03703703703704%\n",
      "\n",
      "Epoch: 40\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 40 loss : 1.2762487729390461 Acc : 25.0%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 41\n",
      "Train epoch : 41 loss : 1.1254448550088065 Acc : 36.111111111111114%\n",
      "\n",
      "Epoch: 41\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 41 loss : 1.1130100687344868 Acc : 41.666666666666664%\n",
      "41.666666666666664\n",
      "\n",
      "Epoch: 42\n",
      "Train epoch : 42 loss : 1.118944423539298 Acc : 34.25925925925926%\n",
      "\n",
      "Epoch: 42\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 42 loss : 1.124315619468689 Acc : 38.888888888888886%\n",
      "41.666666666666664\n",
      "\n",
      "Epoch: 43\n",
      "Train epoch : 43 loss : 1.1180345756667 Acc : 41.666666666666664%\n",
      "\n",
      "Epoch: 43\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 43 loss : 1.143134872118632 Acc : 25.0%\n",
      "41.666666666666664\n",
      "\n",
      "Epoch: 44\n",
      "Train epoch : 44 loss : 1.0952999251229423 Acc : 37.03703703703704%\n",
      "\n",
      "Epoch: 44\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 44 loss : 1.1179318030675252 Acc : 30.555555555555557%\n",
      "41.666666666666664\n",
      "\n",
      "Epoch: 45\n",
      "Train epoch : 45 loss : 1.0729539053780692 Acc : 38.888888888888886%\n",
      "\n",
      "Epoch: 45\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 45 loss : 1.3321560621261597 Acc : 25.0%\n",
      "41.666666666666664\n",
      "\n",
      "Epoch: 46\n",
      "Train epoch : 46 loss : 1.1150906341416496 Acc : 37.96296296296296%\n",
      "\n",
      "Epoch: 46\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 46 loss : 1.2351120313008626 Acc : 38.888888888888886%\n",
      "41.666666666666664\n",
      "\n",
      "Epoch: 47\n",
      "Train epoch : 47 loss : 1.0544028111866541 Acc : 50.0%\n",
      "\n",
      "Epoch: 47\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 47 loss : 1.3094487190246582 Acc : 25.0%\n",
      "41.666666666666664\n",
      "\n",
      "Epoch: 48\n",
      "Train epoch : 48 loss : 1.1329770599092757 Acc : 37.96296296296296%\n",
      "\n",
      "Epoch: 48\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 48 loss : 1.5365533431371052 Acc : 25.0%\n",
      "41.666666666666664\n",
      "\n",
      "Epoch: 49\n",
      "Train epoch : 49 loss : 1.1094341788973128 Acc : 35.18518518518518%\n",
      "\n",
      "Epoch: 49\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 49 loss : 1.198459227879842 Acc : 25.0%\n",
      "41.666666666666664\n",
      "\n",
      "Epoch: 50\n",
      "Train epoch : 50 loss : 1.0937189374651228 Acc : 40.74074074074074%\n",
      "\n",
      "Epoch: 50\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 50 loss : 1.228042999903361 Acc : 25.0%\n",
      "41.666666666666664\n",
      "\n",
      "Epoch: 51\n",
      "Train epoch : 51 loss : 1.116505605833871 Acc : 37.03703703703704%\n",
      "\n",
      "Epoch: 51\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 51 loss : 1.9337472518285115 Acc : 38.888888888888886%\n",
      "41.666666666666664\n",
      "\n",
      "Epoch: 52\n",
      "Train epoch : 52 loss : 1.1024313909666879 Acc : 40.74074074074074%\n",
      "\n",
      "Epoch: 52\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 52 loss : 1.063371221224467 Acc : 38.888888888888886%\n",
      "41.666666666666664\n",
      "\n",
      "Epoch: 53\n",
      "Train epoch : 53 loss : 1.118275421006339 Acc : 42.592592592592595%\n",
      "\n",
      "Epoch: 53\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 53 loss : 1.2294866641362507 Acc : 25.0%\n",
      "41.666666666666664\n",
      "\n",
      "Epoch: 54\n",
      "Train epoch : 54 loss : 1.1068756324904305 Acc : 36.111111111111114%\n",
      "\n",
      "Epoch: 54\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 54 loss : 1.2870182394981384 Acc : 38.888888888888886%\n",
      "41.666666666666664\n",
      "\n",
      "Epoch: 55\n",
      "Train epoch : 55 loss : 1.0722622956548418 Acc : 48.148148148148145%\n",
      "\n",
      "Epoch: 55\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 55 loss : 1.152604619661967 Acc : 30.555555555555557%\n",
      "41.666666666666664\n",
      "\n",
      "Epoch: 56\n",
      "Train epoch : 56 loss : 1.0751838513783045 Acc : 43.51851851851852%\n",
      "\n",
      "Epoch: 56\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 56 loss : 1.4258378744125366 Acc : 25.0%\n",
      "41.666666666666664\n",
      "\n",
      "Epoch: 57\n",
      "Train epoch : 57 loss : 1.0880922079086304 Acc : 37.03703703703704%\n",
      "\n",
      "Epoch: 57\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 57 loss : 1.1299701929092407 Acc : 30.555555555555557%\n",
      "41.666666666666664\n",
      "\n",
      "Epoch: 58\n",
      "Train epoch : 58 loss : 1.0600540127073015 Acc : 41.666666666666664%\n",
      "\n",
      "Epoch: 58\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 58 loss : 0.9372560977935791 Acc : 44.44444444444444%\n",
      "44.44444444444444\n",
      "\n",
      "Epoch: 59\n",
      "Train epoch : 59 loss : 1.1255792890276228 Acc : 38.888888888888886%\n",
      "\n",
      "Epoch: 59\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 59 loss : 1.206839640935262 Acc : 25.0%\n",
      "44.44444444444444\n",
      "\n",
      "Epoch: 60\n",
      "Train epoch : 60 loss : 1.069046642099108 Acc : 43.51851851851852%\n",
      "\n",
      "Epoch: 60\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 60 loss : 1.0898285706837971 Acc : 41.666666666666664%\n",
      "44.44444444444444\n",
      "\n",
      "Epoch: 61\n",
      "Train epoch : 61 loss : 1.087385049888066 Acc : 42.592592592592595%\n",
      "\n",
      "Epoch: 61\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 61 loss : 1.2667633295059204 Acc : 25.0%\n",
      "44.44444444444444\n",
      "\n",
      "Epoch: 62\n",
      "Train epoch : 62 loss : 1.078690494809832 Acc : 40.74074074074074%\n",
      "\n",
      "Epoch: 62\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 62 loss : 1.2569167613983154 Acc : 44.44444444444444%\n",
      "44.44444444444444\n",
      "\n",
      "Epoch: 63\n",
      "Train epoch : 63 loss : 1.0211655156952995 Acc : 42.592592592592595%\n",
      "\n",
      "Epoch: 63\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 63 loss : 1.0840750535329182 Acc : 41.666666666666664%\n",
      "44.44444444444444\n",
      "\n",
      "Epoch: 64\n",
      "Train epoch : 64 loss : 1.00031544481005 Acc : 48.148148148148145%\n",
      "\n",
      "Epoch: 64\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 64 loss : 1.3302880922953289 Acc : 27.77777777777778%\n",
      "44.44444444444444\n",
      "\n",
      "Epoch: 65\n",
      "Train epoch : 65 loss : 1.0967319692884172 Acc : 47.22222222222222%\n",
      "\n",
      "Epoch: 65\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 65 loss : 0.9839109579722086 Acc : 44.44444444444444%\n",
      "44.44444444444444\n",
      "\n",
      "Epoch: 66\n",
      "Train epoch : 66 loss : 1.0734790308134896 Acc : 42.592592592592595%\n",
      "\n",
      "Epoch: 66\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 66 loss : 1.5414912700653076 Acc : 25.0%\n",
      "44.44444444444444\n",
      "\n",
      "Epoch: 67\n",
      "Train epoch : 67 loss : 1.0585818801607405 Acc : 43.51851851851852%\n",
      "\n",
      "Epoch: 67\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 67 loss : 1.288352131843567 Acc : 27.77777777777778%\n",
      "44.44444444444444\n",
      "\n",
      "Epoch: 68\n",
      "Train epoch : 68 loss : 1.1112499662808009 Acc : 42.592592592592595%\n",
      "\n",
      "Epoch: 68\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 68 loss : 0.9919853210449219 Acc : 38.888888888888886%\n",
      "44.44444444444444\n",
      "\n",
      "Epoch: 69\n",
      "Train epoch : 69 loss : 0.9833863973617554 Acc : 47.22222222222222%\n",
      "\n",
      "Epoch: 69\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 69 loss : 1.4366519848505657 Acc : 25.0%\n",
      "44.44444444444444\n",
      "\n",
      "Epoch: 70\n",
      "Train epoch : 70 loss : 1.1241463422775269 Acc : 43.51851851851852%\n",
      "\n",
      "Epoch: 70\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 70 loss : 0.9387955069541931 Acc : 50.0%\n",
      "50.0\n",
      "\n",
      "Epoch: 71\n",
      "Train epoch : 71 loss : 1.0829656379563468 Acc : 43.51851851851852%\n",
      "\n",
      "Epoch: 71\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 71 loss : 0.9446121454238892 Acc : 41.666666666666664%\n",
      "50.0\n",
      "\n",
      "Epoch: 72\n",
      "Train epoch : 72 loss : 1.048139946801322 Acc : 47.22222222222222%\n",
      "\n",
      "Epoch: 72\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 72 loss : 1.7692869305610657 Acc : 38.888888888888886%\n",
      "50.0\n",
      "\n",
      "Epoch: 73\n",
      "Train epoch : 73 loss : 1.0459113121032715 Acc : 46.2962962962963%\n",
      "\n",
      "Epoch: 73\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 73 loss : 1.0493789116541545 Acc : 38.888888888888886%\n",
      "50.0\n",
      "\n",
      "Epoch: 74\n",
      "Train epoch : 74 loss : 1.0110792517662048 Acc : 50.0%\n",
      "\n",
      "Epoch: 74\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 74 loss : 1.6930328210194905 Acc : 25.0%\n",
      "50.0\n",
      "\n",
      "Epoch: 75\n",
      "Train epoch : 75 loss : 0.970771883215223 Acc : 51.851851851851855%\n",
      "\n",
      "Epoch: 75\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 75 loss : 1.2381896376609802 Acc : 47.22222222222222%\n",
      "50.0\n",
      "\n",
      "Epoch: 76\n",
      "Train epoch : 76 loss : 1.105436554976872 Acc : 41.666666666666664%\n",
      "\n",
      "Epoch: 76\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 76 loss : 1.6060547828674316 Acc : 25.0%\n",
      "50.0\n",
      "\n",
      "Epoch: 77\n",
      "Train epoch : 77 loss : 0.9633781739643642 Acc : 51.851851851851855%\n",
      "\n",
      "Epoch: 77\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 77 loss : 0.9667797485987345 Acc : 47.22222222222222%\n",
      "50.0\n",
      "\n",
      "Epoch: 78\n",
      "Train epoch : 78 loss : 1.0283608266285487 Acc : 50.925925925925924%\n",
      "\n",
      "Epoch: 78\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 78 loss : 0.9306633671124777 Acc : 61.111111111111114%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 79\n",
      "Train epoch : 79 loss : 1.072848984173366 Acc : 47.22222222222222%\n",
      "\n",
      "Epoch: 79\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 79 loss : 1.444965918858846 Acc : 25.0%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 80\n",
      "Train epoch : 80 loss : 1.1366786020142692 Acc : 46.2962962962963%\n",
      "\n",
      "Epoch: 80\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 80 loss : 0.9873749613761902 Acc : 55.55555555555556%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 81\n",
      "Train epoch : 81 loss : 1.0545091543878828 Acc : 48.148148148148145%\n",
      "\n",
      "Epoch: 81\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 81 loss : 1.8090043465296428 Acc : 25.0%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 82\n",
      "Train epoch : 82 loss : 0.9861956749643598 Acc : 42.592592592592595%\n",
      "\n",
      "Epoch: 82\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 82 loss : 1.2452357808748882 Acc : 41.666666666666664%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 83\n",
      "Train epoch : 83 loss : 1.0896559017045158 Acc : 51.851851851851855%\n",
      "\n",
      "Epoch: 83\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 83 loss : 1.0259477694829304 Acc : 47.22222222222222%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 84\n",
      "Train epoch : 84 loss : 1.0215335403169905 Acc : 42.592592592592595%\n",
      "\n",
      "Epoch: 84\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 84 loss : 0.9483715494473776 Acc : 52.77777777777778%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 85\n",
      "Train epoch : 85 loss : 1.0613216417176383 Acc : 44.44444444444444%\n",
      "\n",
      "Epoch: 85\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 85 loss : 1.5585719744364421 Acc : 25.0%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 86\n",
      "Train epoch : 86 loss : 1.0456765975270952 Acc : 45.370370370370374%\n",
      "\n",
      "Epoch: 86\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 86 loss : 0.9752270579338074 Acc : 41.666666666666664%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 87\n",
      "Train epoch : 87 loss : 0.9335215858050755 Acc : 55.55555555555556%\n",
      "\n",
      "Epoch: 87\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 87 loss : 0.9582620660463969 Acc : 50.0%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 88\n",
      "Train epoch : 88 loss : 1.0335196682385035 Acc : 41.666666666666664%\n",
      "\n",
      "Epoch: 88\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 88 loss : 1.0645460486412048 Acc : 44.44444444444444%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 89\n",
      "Train epoch : 89 loss : 0.9810997332845416 Acc : 57.407407407407405%\n",
      "\n",
      "Epoch: 89\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 89 loss : 1.4341914256413777 Acc : 25.0%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 90\n",
      "Train epoch : 90 loss : 1.034408790724618 Acc : 44.44444444444444%\n",
      "\n",
      "Epoch: 90\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 90 loss : 1.5382161140441895 Acc : 38.888888888888886%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 91\n",
      "Train epoch : 91 loss : 0.9890587755611965 Acc : 49.074074074074076%\n",
      "\n",
      "Epoch: 91\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 91 loss : 0.9552201628684998 Acc : 41.666666666666664%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 92\n",
      "Train epoch : 92 loss : 0.9815622738429478 Acc : 49.074074074074076%\n",
      "\n",
      "Epoch: 92\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 92 loss : 0.9772171775499979 Acc : 50.0%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 93\n",
      "Train epoch : 93 loss : 0.9832831961768014 Acc : 54.629629629629626%\n",
      "\n",
      "Epoch: 93\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 93 loss : 0.9007082978884379 Acc : 55.55555555555556%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 94\n",
      "Train epoch : 94 loss : 1.0128030691828047 Acc : 50.0%\n",
      "\n",
      "Epoch: 94\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 94 loss : 1.1644209623336792 Acc : 44.44444444444444%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 95\n",
      "Train epoch : 95 loss : 0.9544598715645927 Acc : 50.0%\n",
      "\n",
      "Epoch: 95\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 95 loss : 1.0712533593177795 Acc : 36.111111111111114%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 96\n",
      "Train epoch : 96 loss : 0.9531496167182922 Acc : 51.851851851851855%\n",
      "\n",
      "Epoch: 96\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 96 loss : 1.333403746287028 Acc : 27.77777777777778%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 97\n",
      "Train epoch : 97 loss : 1.0125757455825806 Acc : 42.592592592592595%\n",
      "\n",
      "Epoch: 97\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 97 loss : 1.2674657901128132 Acc : 27.77777777777778%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 98\n",
      "Train epoch : 98 loss : 0.988032443182809 Acc : 48.148148148148145%\n",
      "\n",
      "Epoch: 98\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 98 loss : 1.2249395847320557 Acc : 36.111111111111114%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 99\n",
      "Train epoch : 99 loss : 0.9597958837236676 Acc : 56.48148148148148%\n",
      "\n",
      "Epoch: 99\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 99 loss : 0.9073835611343384 Acc : 41.666666666666664%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 100\n",
      "Train epoch : 100 loss : 0.9247381857463292 Acc : 50.0%\n",
      "\n",
      "Epoch: 100\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 100 loss : 0.8633680542310079 Acc : 55.55555555555556%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 101\n",
      "Train epoch : 101 loss : 0.9675699557576861 Acc : 50.925925925925924%\n",
      "\n",
      "Epoch: 101\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 101 loss : 0.8939393162727356 Acc : 47.22222222222222%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 102\n",
      "Train epoch : 102 loss : 0.9527590870857239 Acc : 50.0%\n",
      "\n",
      "Epoch: 102\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 102 loss : 0.9440110921859741 Acc : 50.0%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 103\n",
      "Train epoch : 103 loss : 0.9785645944731576 Acc : 49.074074074074076%\n",
      "\n",
      "Epoch: 103\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 103 loss : 1.6083362897237141 Acc : 25.0%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 104\n",
      "Train epoch : 104 loss : 0.9187313062804086 Acc : 50.0%\n",
      "\n",
      "Epoch: 104\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 104 loss : 1.0326228340466816 Acc : 50.0%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 105\n",
      "Train epoch : 105 loss : 0.9730371832847595 Acc : 50.925925925925924%\n",
      "\n",
      "Epoch: 105\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 105 loss : 0.8737874031066895 Acc : 44.44444444444444%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 106\n",
      "Train epoch : 106 loss : 0.926214473588126 Acc : 54.629629629629626%\n",
      "\n",
      "Epoch: 106\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 106 loss : 0.8138837019602457 Acc : 55.55555555555556%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 107\n",
      "Train epoch : 107 loss : 0.9355567182813372 Acc : 52.77777777777778%\n",
      "\n",
      "Epoch: 107\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 107 loss : 1.8206942478815715 Acc : 38.888888888888886%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 108\n",
      "Train epoch : 108 loss : 0.8821222271238055 Acc : 55.55555555555556%\n",
      "\n",
      "Epoch: 108\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 108 loss : 0.8592256307601929 Acc : 50.0%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 109\n",
      "Train epoch : 109 loss : 0.8670230422701154 Acc : 56.48148148148148%\n",
      "\n",
      "Epoch: 109\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 109 loss : 0.9197651346524557 Acc : 58.333333333333336%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 110\n",
      "Train epoch : 110 loss : 0.9292809452329364 Acc : 52.77777777777778%\n",
      "\n",
      "Epoch: 110\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 110 loss : 1.1627839008967082 Acc : 36.111111111111114%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 111\n",
      "Train epoch : 111 loss : 0.8688106196267265 Acc : 55.55555555555556%\n",
      "\n",
      "Epoch: 111\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 111 loss : 0.8901416858037313 Acc : 58.333333333333336%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 112\n",
      "Train epoch : 112 loss : 0.9514801502227783 Acc : 50.925925925925924%\n",
      "\n",
      "Epoch: 112\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 112 loss : 1.2104748487472534 Acc : 36.111111111111114%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 113\n",
      "Train epoch : 113 loss : 0.8800039121082851 Acc : 57.407407407407405%\n",
      "\n",
      "Epoch: 113\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 113 loss : 1.2526680827140808 Acc : 30.555555555555557%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 114\n",
      "Train epoch : 114 loss : 0.9076076149940491 Acc : 58.333333333333336%\n",
      "\n",
      "Epoch: 114\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 114 loss : 1.2705520391464233 Acc : 55.55555555555556%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 115\n",
      "Train epoch : 115 loss : 0.9292528459003994 Acc : 55.55555555555556%\n",
      "\n",
      "Epoch: 115\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 115 loss : 2.403849999109904 Acc : 44.44444444444444%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 116\n",
      "Train epoch : 116 loss : 0.841620283467429 Acc : 62.03703703703704%\n",
      "\n",
      "Epoch: 116\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 116 loss : 1.0880205432573955 Acc : 55.55555555555556%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 117\n",
      "Train epoch : 117 loss : 0.9627854483468192 Acc : 54.629629629629626%\n",
      "\n",
      "Epoch: 117\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 117 loss : 0.8334557811419169 Acc : 55.55555555555556%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 118\n",
      "Train epoch : 118 loss : 0.8201970713479179 Acc : 64.81481481481481%\n",
      "\n",
      "Epoch: 118\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 118 loss : 2.040900150934855 Acc : 38.888888888888886%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 119\n",
      "Train epoch : 119 loss : 0.9368827087538583 Acc : 51.851851851851855%\n",
      "\n",
      "Epoch: 119\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 119 loss : 1.1879435976346333 Acc : 41.666666666666664%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 120\n",
      "Train epoch : 120 loss : 0.9318850295884269 Acc : 49.074074074074076%\n",
      "\n",
      "Epoch: 120\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 120 loss : 0.6263647079467773 Acc : 66.66666666666667%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 121\n",
      "Train epoch : 121 loss : 0.8801665306091309 Acc : 57.407407407407405%\n",
      "\n",
      "Epoch: 121\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 121 loss : 1.0024655262629192 Acc : 50.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 122\n",
      "Train epoch : 122 loss : 0.7993952802249363 Acc : 60.18518518518518%\n",
      "\n",
      "Epoch: 122\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 122 loss : 0.8245191276073456 Acc : 41.666666666666664%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 123\n",
      "Train epoch : 123 loss : 0.8491535186767578 Acc : 65.74074074074075%\n",
      "\n",
      "Epoch: 123\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 123 loss : 0.9337786634763082 Acc : 58.333333333333336%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 124\n",
      "Train epoch : 124 loss : 0.8495480162756783 Acc : 59.25925925925926%\n",
      "\n",
      "Epoch: 124\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 124 loss : 0.9383857647577921 Acc : 58.333333333333336%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 125\n",
      "Train epoch : 125 loss : 0.8628586445535932 Acc : 53.7037037037037%\n",
      "\n",
      "Epoch: 125\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 125 loss : 0.8787301182746887 Acc : 66.66666666666667%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 126\n",
      "Train epoch : 126 loss : 0.8119003346988133 Acc : 63.888888888888886%\n",
      "\n",
      "Epoch: 126\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 126 loss : 0.8988468845685323 Acc : 50.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 127\n",
      "Train epoch : 127 loss : 0.8073353086199079 Acc : 64.81481481481481%\n",
      "\n",
      "Epoch: 127\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 127 loss : 0.9389389952023824 Acc : 55.55555555555556%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 128\n",
      "Train epoch : 128 loss : 0.8120506490979876 Acc : 60.18518518518518%\n",
      "\n",
      "Epoch: 128\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 128 loss : 1.1236076951026917 Acc : 41.666666666666664%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 129\n",
      "Train epoch : 129 loss : 0.9076598967824664 Acc : 55.55555555555556%\n",
      "\n",
      "Epoch: 129\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 129 loss : 0.6552892426649729 Acc : 58.333333333333336%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 130\n",
      "Train epoch : 130 loss : 0.889113860470908 Acc : 52.77777777777778%\n",
      "\n",
      "Epoch: 130\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 130 loss : 0.7391228675842285 Acc : 72.22222222222223%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 131\n",
      "Train epoch : 131 loss : 0.8307238817214966 Acc : 63.888888888888886%\n",
      "\n",
      "Epoch: 131\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 131 loss : 1.1706853707631428 Acc : 38.888888888888886%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 132\n",
      "Train epoch : 132 loss : 0.9215098449162075 Acc : 56.48148148148148%\n",
      "\n",
      "Epoch: 132\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 132 loss : 0.9729224046071371 Acc : 47.22222222222222%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 133\n",
      "Train epoch : 133 loss : 0.8204819560050964 Acc : 62.03703703703704%\n",
      "\n",
      "Epoch: 133\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 133 loss : 1.0171504815419514 Acc : 47.22222222222222%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 134\n",
      "Train epoch : 134 loss : 0.7777412278311593 Acc : 63.888888888888886%\n",
      "\n",
      "Epoch: 134\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 134 loss : 0.728951891263326 Acc : 63.888888888888886%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 135\n",
      "Train epoch : 135 loss : 0.8699396167482648 Acc : 53.7037037037037%\n",
      "\n",
      "Epoch: 135\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 135 loss : 1.538534681002299 Acc : 44.44444444444444%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 136\n",
      "Train epoch : 136 loss : 0.8323243004935128 Acc : 62.03703703703704%\n",
      "\n",
      "Epoch: 136\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 136 loss : 0.8369670684138933 Acc : 44.44444444444444%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 137\n",
      "Train epoch : 137 loss : 0.8508368134498596 Acc : 62.03703703703704%\n",
      "\n",
      "Epoch: 137\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 137 loss : 1.2827417850494385 Acc : 50.0%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 138\n",
      "Train epoch : 138 loss : 0.7297760929380145 Acc : 66.66666666666667%\n",
      "\n",
      "Epoch: 138\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 138 loss : 0.7572555939356486 Acc : 58.333333333333336%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 139\n",
      "Train epoch : 139 loss : 0.7796162962913513 Acc : 67.5925925925926%\n",
      "\n",
      "Epoch: 139\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 139 loss : 1.0771835446357727 Acc : 50.0%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 140\n",
      "Train epoch : 140 loss : 0.8074428694588798 Acc : 63.888888888888886%\n",
      "\n",
      "Epoch: 140\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 140 loss : 1.6526858409245808 Acc : 47.22222222222222%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 141\n",
      "Train epoch : 141 loss : 0.80978924036026 Acc : 66.66666666666667%\n",
      "\n",
      "Epoch: 141\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 141 loss : 0.6707429885864258 Acc : 58.333333333333336%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 142\n",
      "Train epoch : 142 loss : 0.7531182169914246 Acc : 65.74074074074075%\n",
      "\n",
      "Epoch: 142\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 142 loss : 1.441681941350301 Acc : 47.22222222222222%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 143\n",
      "Train epoch : 143 loss : 0.7860319869858878 Acc : 65.74074074074075%\n",
      "\n",
      "Epoch: 143\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 143 loss : 0.6687857011953989 Acc : 66.66666666666667%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 144\n",
      "Train epoch : 144 loss : 0.7941826837403434 Acc : 62.03703703703704%\n",
      "\n",
      "Epoch: 144\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 144 loss : 0.5945845345656077 Acc : 69.44444444444444%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 145\n",
      "Train epoch : 145 loss : 0.8350109713418143 Acc : 61.111111111111114%\n",
      "\n",
      "Epoch: 145\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 145 loss : 0.8918498357137045 Acc : 61.111111111111114%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 146\n",
      "Train epoch : 146 loss : 0.7780157285077232 Acc : 60.18518518518518%\n",
      "\n",
      "Epoch: 146\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 146 loss : 0.8360244234402975 Acc : 61.111111111111114%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 147\n",
      "Train epoch : 147 loss : 0.799048227923257 Acc : 63.888888888888886%\n",
      "\n",
      "Epoch: 147\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 147 loss : 0.7705487410227457 Acc : 61.111111111111114%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 148\n",
      "Train epoch : 148 loss : 0.8078404154096331 Acc : 63.888888888888886%\n",
      "\n",
      "Epoch: 148\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 148 loss : 0.5398581922054291 Acc : 69.44444444444444%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 149\n",
      "Train epoch : 149 loss : 0.8315562052386147 Acc : 65.74074074074075%\n",
      "\n",
      "Epoch: 149\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 149 loss : 7.9437336921691895 Acc : 38.888888888888886%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 150\n",
      "Train epoch : 150 loss : 0.8978878515107291 Acc : 52.77777777777778%\n",
      "\n",
      "Epoch: 150\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 150 loss : 1.0713085333506267 Acc : 52.77777777777778%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 151\n",
      "Train epoch : 151 loss : 0.6885675958224705 Acc : 70.37037037037037%\n",
      "\n",
      "Epoch: 151\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 151 loss : 0.9613743623097738 Acc : 47.22222222222222%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 152\n",
      "Train epoch : 152 loss : 0.7856474093028477 Acc : 62.96296296296296%\n",
      "\n",
      "Epoch: 152\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 152 loss : 0.7516099413235983 Acc : 69.44444444444444%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 153\n",
      "Train epoch : 153 loss : 0.711302365575518 Acc : 64.81481481481481%\n",
      "\n",
      "Epoch: 153\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 153 loss : 1.5735413630803425 Acc : 52.77777777777778%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 154\n",
      "Train epoch : 154 loss : 0.6939086232866559 Acc : 69.44444444444444%\n",
      "\n",
      "Epoch: 154\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 154 loss : 0.7777618368466696 Acc : 66.66666666666667%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 155\n",
      "Train epoch : 155 loss : 0.7974232946123395 Acc : 62.03703703703704%\n",
      "\n",
      "Epoch: 155\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 155 loss : 1.0104061762491863 Acc : 58.333333333333336%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 156\n",
      "Train epoch : 156 loss : 0.7356473760945457 Acc : 71.29629629629629%\n",
      "\n",
      "Epoch: 156\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 156 loss : 0.8361385862032572 Acc : 55.55555555555556%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 157\n",
      "Train epoch : 157 loss : 0.7028062684195382 Acc : 67.5925925925926%\n",
      "\n",
      "Epoch: 157\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 157 loss : 1.5380606452624004 Acc : 47.22222222222222%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 158\n",
      "Train epoch : 158 loss : 0.6896205033574786 Acc : 67.5925925925926%\n",
      "\n",
      "Epoch: 158\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 158 loss : 0.9347526431083679 Acc : 52.77777777777778%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 159\n",
      "Train epoch : 159 loss : 0.7632459827831813 Acc : 67.5925925925926%\n",
      "\n",
      "Epoch: 159\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 159 loss : 1.1726397275924683 Acc : 41.666666666666664%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 160\n",
      "Train epoch : 160 loss : 1.0908628787313188 Acc : 53.7037037037037%\n",
      "\n",
      "Epoch: 160\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 160 loss : 1.639096736907959 Acc : 41.666666666666664%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 161\n",
      "Train epoch : 161 loss : 0.8371338588850838 Acc : 58.333333333333336%\n",
      "\n",
      "Epoch: 161\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 161 loss : 1.2294667760531108 Acc : 52.77777777777778%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 162\n",
      "Train epoch : 162 loss : 0.6379342760358538 Acc : 73.14814814814815%\n",
      "\n",
      "Epoch: 162\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 162 loss : 0.8892989357312521 Acc : 58.333333333333336%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 163\n",
      "Train epoch : 163 loss : 0.645322105714253 Acc : 75.0%\n",
      "\n",
      "Epoch: 163\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 163 loss : 0.6306353410085043 Acc : 66.66666666666667%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 164\n",
      "Train epoch : 164 loss : 0.7386000667299543 Acc : 72.22222222222223%\n",
      "\n",
      "Epoch: 164\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 164 loss : 0.7575744986534119 Acc : 66.66666666666667%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 165\n",
      "Train epoch : 165 loss : 0.8524281808308193 Acc : 63.888888888888886%\n",
      "\n",
      "Epoch: 165\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 165 loss : 1.4381725986798604 Acc : 44.44444444444444%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 166\n",
      "Train epoch : 166 loss : 0.7274078811917987 Acc : 68.51851851851852%\n",
      "\n",
      "Epoch: 166\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 166 loss : 1.4238181114196777 Acc : 44.44444444444444%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 167\n",
      "Train epoch : 167 loss : 0.8021338156291417 Acc : 65.74074074074075%\n",
      "\n",
      "Epoch: 167\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 167 loss : 0.6184596220652262 Acc : 66.66666666666667%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 168\n",
      "Train epoch : 168 loss : 0.6935330842222486 Acc : 66.66666666666667%\n",
      "\n",
      "Epoch: 168\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 168 loss : 0.7505410512288412 Acc : 66.66666666666667%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 169\n",
      "Train epoch : 169 loss : 0.8395370074680873 Acc : 64.81481481481481%\n",
      "\n",
      "Epoch: 169\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 169 loss : 0.866421103477478 Acc : 55.55555555555556%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 170\n",
      "Train epoch : 170 loss : 0.9416773319244385 Acc : 56.48148148148148%\n",
      "\n",
      "Epoch: 170\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 170 loss : 0.9231250286102295 Acc : 52.77777777777778%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 171\n",
      "Train epoch : 171 loss : 0.8048936724662781 Acc : 62.96296296296296%\n",
      "\n",
      "Epoch: 171\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 171 loss : 1.7710474332173665 Acc : 38.888888888888886%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 172\n",
      "Train epoch : 172 loss : 0.7717470952442714 Acc : 63.888888888888886%\n",
      "\n",
      "Epoch: 172\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 172 loss : 0.9004513422648112 Acc : 47.22222222222222%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 173\n",
      "Train epoch : 173 loss : 0.8133313315255302 Acc : 58.333333333333336%\n",
      "\n",
      "Epoch: 173\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 173 loss : 1.5909202297528584 Acc : 50.0%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 174\n",
      "Train epoch : 174 loss : 0.8245960559163775 Acc : 64.81481481481481%\n",
      "\n",
      "Epoch: 174\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 174 loss : 0.929961621761322 Acc : 58.333333333333336%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 175\n",
      "Train epoch : 175 loss : 0.9249887594154903 Acc : 55.55555555555556%\n",
      "\n",
      "Epoch: 175\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 175 loss : 0.7527001102765402 Acc : 61.111111111111114%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 176\n",
      "Train epoch : 176 loss : 0.7919162426676069 Acc : 64.81481481481481%\n",
      "\n",
      "Epoch: 176\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 176 loss : 3.017582734425863 Acc : 44.44444444444444%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 177\n",
      "Train epoch : 177 loss : 0.6815611634935651 Acc : 69.44444444444444%\n",
      "\n",
      "Epoch: 177\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 177 loss : 2.3306042353312173 Acc : 44.44444444444444%\n",
      "72.22222222222223\n",
      "\n",
      "Epoch: 178\n",
      "Train epoch : 178 loss : 0.7767115788800376 Acc : 68.51851851851852%\n",
      "\n",
      "Epoch: 178\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 178 loss : 0.5704718033472697 Acc : 75.0%\n",
      "75.0\n",
      "\n",
      "Epoch: 179\n",
      "Train epoch : 179 loss : 0.765942667211805 Acc : 62.96296296296296%\n",
      "\n",
      "Epoch: 179\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 179 loss : 0.6023215850194296 Acc : 69.44444444444444%\n",
      "75.0\n",
      "\n",
      "Epoch: 180\n",
      "Train epoch : 180 loss : 0.6298328042030334 Acc : 70.37037037037037%\n",
      "\n",
      "Epoch: 180\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 180 loss : 1.0456146597862244 Acc : 52.77777777777778%\n",
      "75.0\n",
      "\n",
      "Epoch: 181\n",
      "Train epoch : 181 loss : 0.6139527559280396 Acc : 70.37037037037037%\n",
      "\n",
      "Epoch: 181\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 181 loss : 0.9514914552370707 Acc : 41.666666666666664%\n",
      "75.0\n",
      "\n",
      "Epoch: 182\n",
      "Train epoch : 182 loss : 0.8544686096055167 Acc : 65.74074074074075%\n",
      "\n",
      "Epoch: 182\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 182 loss : 1.5171471039454143 Acc : 30.555555555555557%\n",
      "75.0\n",
      "\n",
      "Epoch: 183\n",
      "Train epoch : 183 loss : 0.8022238441876003 Acc : 62.96296296296296%\n",
      "\n",
      "Epoch: 183\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 183 loss : 1.0614917476971943 Acc : 50.0%\n",
      "75.0\n",
      "\n",
      "Epoch: 184\n",
      "Train epoch : 184 loss : 0.7391296710286822 Acc : 63.888888888888886%\n",
      "\n",
      "Epoch: 184\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 184 loss : 0.6077032486597697 Acc : 72.22222222222223%\n",
      "75.0\n",
      "\n",
      "Epoch: 185\n",
      "Train epoch : 185 loss : 0.6677111727850777 Acc : 66.66666666666667%\n",
      "\n",
      "Epoch: 185\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 185 loss : 0.8516746958096822 Acc : 63.888888888888886%\n",
      "75.0\n",
      "\n",
      "Epoch: 186\n",
      "Train epoch : 186 loss : 0.6155244963509696 Acc : 78.70370370370371%\n",
      "\n",
      "Epoch: 186\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 186 loss : 0.7629786531130472 Acc : 63.888888888888886%\n",
      "75.0\n",
      "\n",
      "Epoch: 187\n",
      "Train epoch : 187 loss : 0.5798308040414538 Acc : 73.14814814814815%\n",
      "\n",
      "Epoch: 187\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 187 loss : 0.6955959598223368 Acc : 61.111111111111114%\n",
      "75.0\n",
      "\n",
      "Epoch: 188\n",
      "Train epoch : 188 loss : 0.9027836067335946 Acc : 62.96296296296296%\n",
      "\n",
      "Epoch: 188\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 188 loss : 0.4971770743529002 Acc : 66.66666666666667%\n",
      "75.0\n",
      "\n",
      "Epoch: 189\n",
      "Train epoch : 189 loss : 0.7184798078877586 Acc : 67.5925925925926%\n",
      "\n",
      "Epoch: 189\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 189 loss : 4.042352914810181 Acc : 25.0%\n",
      "75.0\n",
      "\n",
      "Epoch: 190\n",
      "Train epoch : 190 loss : 0.7658839821815491 Acc : 59.25925925925926%\n",
      "\n",
      "Epoch: 190\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 190 loss : 1.1722416679064434 Acc : 52.77777777777778%\n",
      "75.0\n",
      "\n",
      "Epoch: 191\n",
      "Train epoch : 191 loss : 0.6153233349323273 Acc : 79.62962962962963%\n",
      "\n",
      "Epoch: 191\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 191 loss : 0.6264709631601969 Acc : 61.111111111111114%\n",
      "75.0\n",
      "\n",
      "Epoch: 192\n",
      "Train epoch : 192 loss : 0.7594642724309649 Acc : 69.44444444444444%\n",
      "\n",
      "Epoch: 192\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 192 loss : 1.2430704236030579 Acc : 50.0%\n",
      "75.0\n",
      "\n",
      "Epoch: 193\n",
      "Train epoch : 193 loss : 0.6838329519544329 Acc : 64.81481481481481%\n",
      "\n",
      "Epoch: 193\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 193 loss : 0.8440192838509878 Acc : 63.888888888888886%\n",
      "75.0\n",
      "\n",
      "Epoch: 194\n",
      "Train epoch : 194 loss : 0.6857567174094064 Acc : 65.74074074074075%\n",
      "\n",
      "Epoch: 194\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 194 loss : 0.7167211373647054 Acc : 63.888888888888886%\n",
      "75.0\n",
      "\n",
      "Epoch: 195\n",
      "Train epoch : 195 loss : 0.6870603433677128 Acc : 71.29629629629629%\n",
      "\n",
      "Epoch: 195\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 195 loss : 0.7940370043118795 Acc : 58.333333333333336%\n",
      "75.0\n",
      "\n",
      "Epoch: 196\n",
      "Train epoch : 196 loss : 0.6463183164596558 Acc : 66.66666666666667%\n",
      "\n",
      "Epoch: 196\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 196 loss : 1.408117989699046 Acc : 47.22222222222222%\n",
      "75.0\n",
      "\n",
      "Epoch: 197\n",
      "Train epoch : 197 loss : 0.6464538659368243 Acc : 72.22222222222223%\n",
      "\n",
      "Epoch: 197\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 197 loss : 0.7750267585118612 Acc : 63.888888888888886%\n",
      "75.0\n",
      "\n",
      "Epoch: 198\n",
      "Train epoch : 198 loss : 0.5989022127219609 Acc : 73.14814814814815%\n",
      "\n",
      "Epoch: 198\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 198 loss : 0.7617456912994385 Acc : 66.66666666666667%\n",
      "75.0\n",
      "\n",
      "Epoch: 199\n",
      "Train epoch : 199 loss : 0.679979703256062 Acc : 69.44444444444444%\n",
      "\n",
      "Epoch: 199\n",
      "{0: 9, 1: 13, 2: 14}\n",
      "Test epoch : 199 loss : 1.305279274781545 Acc : 52.77777777777778%\n",
      "75.0\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 및 평가\n",
    "BEST_SCORE = 0\n",
    "for epoch in range(epochs):\n",
    "    train(epoch)\n",
    "    test(epoch, valloader)\n",
    "    print(BEST_SCORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: -1\n",
      "{0: 9, 1: 14, 2: 13}\n",
      "Test epoch : -1 loss : 0.6128053665161133 Acc : 69.44444444444444%\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋에서 평가\n",
    "model.load_state_dict(torch.load(os.path.join(save_path, f'teacher.pth')))\n",
    "test(-1, testloader, 'test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fskd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

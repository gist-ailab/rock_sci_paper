{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\fskd\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#필요한 라이브러리들 import\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import dataset\n",
    "import model\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각종 path및 하이퍼 파라미터 설정\n",
    "data_path = 'C:\\\\Users\\\\USER\\\\Desktop\\\\GSH_CRP\\\\codes\\\\rock_sci_paper\\\\data\\\\ro_sci_pa_heo'\n",
    "save_path = 'C:\\\\Users\\\\USER\\\\Desktop\\\\GSH_CRP\\\\codes\\\\rock_sci_paper\\\\model_para'\n",
    "epochs = 200\n",
    "batch_size = 16\n",
    "learning_rate = 0.01\n",
    "seed = 0\n",
    "mode = 'hr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 설정\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# device 설정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform 설정\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomAffine((-45, 45), translate=(0.2,0.2)),\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ColorJitter(brightness=0.5),\n",
    "    transforms.ColorJitter(contrast=0.5),\n",
    "    transforms.ColorJitter(saturation=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]\n",
    ")\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n",
      "30\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "# dataset 설정\n",
    "train_dataset = dataset.RockScissorsPaper(\n",
    "    transform=train_transform,\n",
    "    path = data_path,\n",
    "    mode = 'train'\n",
    ")\n",
    "val_dataset = dataset.RockScissorsPaper(\n",
    "    transform=test_transform,\n",
    "    path = data_path,\n",
    "    mode = 'val'\n",
    ")\n",
    "test_dataset = dataset.RockScissorsPaper(\n",
    "    transform=test_transform,\n",
    "    path = data_path,\n",
    "    mode = 'test'\n",
    ")\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader 설정\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델, 손실함수, 옵티마이저 설정\n",
    "model = model.ResNet18(num_classes=3)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    print('\\nEpoch: %d'%epoch)\n",
    "    # model train mode로 전환\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    total = 0\n",
    "    for (inputs, labels) in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if mode=='lr':\n",
    "            h,w = inputs.shape[-2], inputs.shape[-1]\n",
    "            lr_inputs = F.interpolate(inputs, (h//64, w//64))\n",
    "            lr_inputs = F.interpolate(lr_inputs, (h,w))\n",
    "            outputs, _, _, _, _ = model(lr_inputs)\n",
    "        else:\n",
    "            outputs, _, _, _, _ = model(inputs)\n",
    "            \n",
    "        _, pred = torch.max(outputs, 1)\n",
    "        total += outputs.size(0)\n",
    "        running_acc += (pred == labels).sum().item()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    total_loss = running_loss / len(trainloader)\n",
    "    total_acc = 100 * running_acc / total\n",
    "    print(f'Train epoch : {epoch} loss : {total_loss} Acc : {total_acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, loader, mode='val', mode2=False):\n",
    "    print('\\nEpoch: %d'%epoch)\n",
    "    # model eval mode로 전환\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    total = 0\n",
    "    label_dict = {0:0, 1:0, 2:0}\n",
    "    correct_dict = {0:0, 1:0, 2:0}\n",
    "    global BEST_SCORE\n",
    "    with torch.no_grad():\n",
    "        for (inputs, labels) in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            if mode=='lr':\n",
    "                h,w = inputs.shape[-2], inputs.shape[-1]\n",
    "                lr_inputs = F.interpolate(inputs, (h//32, w//32))\n",
    "                lr_inputs = F.interpolate(lr_inputs, (h,w))\n",
    "                outputs, _, _, _, _ = model(lr_inputs)\n",
    "            else:\n",
    "                outputs, _, _, _, _ = model(inputs)\n",
    "\n",
    "            _, pred = torch.max(outputs, 1)\n",
    "            \n",
    "            total += outputs.size(0)\n",
    "            running_acc += (pred == labels).sum().item()\n",
    "            \n",
    "            if mode2:\n",
    "                for i in range(len(labels)):\n",
    "                    label = labels[i]\n",
    "                    label_dict[label.item()] += 1\n",
    "                    if (pred==labels)[i]:\n",
    "                        correct_dict[label.item()] += 1\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "        total_loss = running_loss / len(loader)\n",
    "        total_acc = 100 * running_acc / total\n",
    "        if mode2:\n",
    "            print(label_dict)\n",
    "            print(correct_dict)\n",
    "        if total_acc >= BEST_SCORE and not mode=='test':\n",
    "            path = os.path.join(save_path, f'teacher.pth')\n",
    "            torch.save(model.state_dict(), path)\n",
    "            BEST_SCORE = total_acc\n",
    "        print(f'Test epoch : {epoch} loss : {total_loss} Acc : {total_acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "Train epoch : 0 loss : 1.2340002218882242 Acc : 35.416666666666664%\n",
      "\n",
      "Epoch: 0\n",
      "Test epoch : 0 loss : 1.1906949281692505 Acc : 30.0%\n",
      "30.0\n",
      "\n",
      "Epoch: 1\n",
      "Train epoch : 1 loss : 1.2448428591092429 Acc : 33.333333333333336%\n",
      "\n",
      "Epoch: 1\n",
      "Test epoch : 1 loss : 1.124809205532074 Acc : 30.0%\n",
      "30.0\n",
      "\n",
      "Epoch: 2\n",
      "Train epoch : 2 loss : 1.2071207443873087 Acc : 26.25%\n",
      "\n",
      "Epoch: 2\n",
      "Test epoch : 2 loss : 1.2212659120559692 Acc : 26.666666666666668%\n",
      "30.0\n",
      "\n",
      "Epoch: 3\n",
      "Train epoch : 3 loss : 1.1561352769533793 Acc : 35.0%\n",
      "\n",
      "Epoch: 3\n",
      "Test epoch : 3 loss : 1.1058106422424316 Acc : 43.333333333333336%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 4\n",
      "Train epoch : 4 loss : 1.154122543334961 Acc : 34.583333333333336%\n",
      "\n",
      "Epoch: 4\n",
      "Test epoch : 4 loss : 1.1298021078109741 Acc : 30.0%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 5\n",
      "Train epoch : 5 loss : 1.134732969601949 Acc : 36.25%\n",
      "\n",
      "Epoch: 5\n",
      "Test epoch : 5 loss : 1.456175446510315 Acc : 30.0%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 6\n",
      "Train epoch : 6 loss : 1.1458361943562825 Acc : 31.25%\n",
      "\n",
      "Epoch: 6\n",
      "Test epoch : 6 loss : 1.5886508226394653 Acc : 26.666666666666668%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 7\n",
      "Train epoch : 7 loss : 1.1348055521647136 Acc : 32.083333333333336%\n",
      "\n",
      "Epoch: 7\n",
      "Test epoch : 7 loss : 1.149485468864441 Acc : 30.0%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 8\n",
      "Train epoch : 8 loss : 1.1576482852300007 Acc : 28.333333333333332%\n",
      "\n",
      "Epoch: 8\n",
      "Test epoch : 8 loss : 1.1922352313995361 Acc : 26.666666666666668%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 9\n",
      "Train epoch : 9 loss : 1.1806071599324544 Acc : 29.166666666666668%\n",
      "\n",
      "Epoch: 9\n",
      "Test epoch : 9 loss : 1.086018145084381 Acc : 33.333333333333336%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 10\n",
      "Train epoch : 10 loss : 1.1315046946207683 Acc : 30.0%\n",
      "\n",
      "Epoch: 10\n",
      "Test epoch : 10 loss : 1.0834074020385742 Acc : 43.333333333333336%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 11\n",
      "Train epoch : 11 loss : 1.1421915531158446 Acc : 32.916666666666664%\n",
      "\n",
      "Epoch: 11\n",
      "Test epoch : 11 loss : 1.134407639503479 Acc : 26.666666666666668%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 12\n",
      "Train epoch : 12 loss : 1.123675775527954 Acc : 35.833333333333336%\n",
      "\n",
      "Epoch: 12\n",
      "Test epoch : 12 loss : 1.1156758069992065 Acc : 30.0%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 13\n",
      "Train epoch : 13 loss : 1.1458630402882894 Acc : 34.583333333333336%\n",
      "\n",
      "Epoch: 13\n",
      "Test epoch : 13 loss : 1.1661580204963684 Acc : 30.0%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 14\n",
      "Train epoch : 14 loss : 1.1284382104873658 Acc : 38.75%\n",
      "\n",
      "Epoch: 14\n",
      "Test epoch : 14 loss : 1.200714349746704 Acc : 26.666666666666668%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 15\n",
      "Train epoch : 15 loss : 1.112512191136678 Acc : 33.75%\n",
      "\n",
      "Epoch: 15\n",
      "Test epoch : 15 loss : 1.0705470442771912 Acc : 43.333333333333336%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 16\n",
      "Train epoch : 16 loss : 1.1276833534240722 Acc : 34.166666666666664%\n",
      "\n",
      "Epoch: 16\n",
      "Test epoch : 16 loss : 1.240633487701416 Acc : 23.333333333333332%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 17\n",
      "Train epoch : 17 loss : 1.143151013056437 Acc : 31.25%\n",
      "\n",
      "Epoch: 17\n",
      "Test epoch : 17 loss : 1.0820174813270569 Acc : 43.333333333333336%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 18\n",
      "Train epoch : 18 loss : 1.1217144926389058 Acc : 34.166666666666664%\n",
      "\n",
      "Epoch: 18\n",
      "Test epoch : 18 loss : 1.132133960723877 Acc : 30.0%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 19\n",
      "Train epoch : 19 loss : 1.1174445708592733 Acc : 33.75%\n",
      "\n",
      "Epoch: 19\n",
      "Test epoch : 19 loss : 1.0770506262779236 Acc : 40.0%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 20\n",
      "Train epoch : 20 loss : 1.1118881464004517 Acc : 38.75%\n",
      "\n",
      "Epoch: 20\n",
      "Test epoch : 20 loss : 1.1908376216888428 Acc : 30.0%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 21\n",
      "Train epoch : 21 loss : 1.1206981579462687 Acc : 32.916666666666664%\n",
      "\n",
      "Epoch: 21\n",
      "Test epoch : 21 loss : 1.0704885721206665 Acc : 43.333333333333336%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 22\n",
      "Train epoch : 22 loss : 1.1450249115626017 Acc : 35.416666666666664%\n",
      "\n",
      "Epoch: 22\n",
      "Test epoch : 22 loss : 1.1356551051139832 Acc : 26.666666666666668%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 23\n",
      "Train epoch : 23 loss : 1.1312470118204752 Acc : 31.25%\n",
      "\n",
      "Epoch: 23\n",
      "Test epoch : 23 loss : 1.191877543926239 Acc : 26.666666666666668%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 24\n",
      "Train epoch : 24 loss : 1.1257365942001343 Acc : 33.333333333333336%\n",
      "\n",
      "Epoch: 24\n",
      "Test epoch : 24 loss : 1.069335401058197 Acc : 50.0%\n",
      "50.0\n",
      "\n",
      "Epoch: 25\n",
      "Train epoch : 25 loss : 1.1149914344151814 Acc : 35.0%\n",
      "\n",
      "Epoch: 25\n",
      "Test epoch : 25 loss : 1.085312008857727 Acc : 33.333333333333336%\n",
      "50.0\n",
      "\n",
      "Epoch: 26\n",
      "Train epoch : 26 loss : 1.1124119838078816 Acc : 37.083333333333336%\n",
      "\n",
      "Epoch: 26\n",
      "Test epoch : 26 loss : 1.1187002062797546 Acc : 26.666666666666668%\n",
      "50.0\n",
      "\n",
      "Epoch: 27\n",
      "Train epoch : 27 loss : 1.1286415815353394 Acc : 28.333333333333332%\n",
      "\n",
      "Epoch: 27\n",
      "Test epoch : 27 loss : 1.0091751515865326 Acc : 50.0%\n",
      "50.0\n",
      "\n",
      "Epoch: 28\n",
      "Train epoch : 28 loss : 1.1153196612993876 Acc : 40.0%\n",
      "\n",
      "Epoch: 28\n",
      "Test epoch : 28 loss : 1.0772398114204407 Acc : 36.666666666666664%\n",
      "50.0\n",
      "\n",
      "Epoch: 29\n",
      "Train epoch : 29 loss : 1.1033153216044107 Acc : 37.083333333333336%\n",
      "\n",
      "Epoch: 29\n",
      "Test epoch : 29 loss : 1.1429285407066345 Acc : 43.333333333333336%\n",
      "50.0\n",
      "\n",
      "Epoch: 30\n",
      "Train epoch : 30 loss : 1.1354093631108602 Acc : 29.583333333333332%\n",
      "\n",
      "Epoch: 30\n",
      "Test epoch : 30 loss : 1.0372649431228638 Acc : 50.0%\n",
      "50.0\n",
      "\n",
      "Epoch: 31\n",
      "Train epoch : 31 loss : 1.0928392966588338 Acc : 39.166666666666664%\n",
      "\n",
      "Epoch: 31\n",
      "Test epoch : 31 loss : 1.1033806800842285 Acc : 26.666666666666668%\n",
      "50.0\n",
      "\n",
      "Epoch: 32\n",
      "Train epoch : 32 loss : 1.0996566534042358 Acc : 38.333333333333336%\n",
      "\n",
      "Epoch: 32\n",
      "Test epoch : 32 loss : 1.0666468739509583 Acc : 46.666666666666664%\n",
      "50.0\n",
      "\n",
      "Epoch: 33\n",
      "Train epoch : 33 loss : 1.1333316485087077 Acc : 32.5%\n",
      "\n",
      "Epoch: 33\n",
      "Test epoch : 33 loss : 1.1227914690971375 Acc : 26.666666666666668%\n",
      "50.0\n",
      "\n",
      "Epoch: 34\n",
      "Train epoch : 34 loss : 1.0819914619127908 Acc : 38.333333333333336%\n",
      "\n",
      "Epoch: 34\n",
      "Test epoch : 34 loss : 0.9971049129962921 Acc : 66.66666666666667%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 35\n",
      "Train epoch : 35 loss : 1.0695007165273032 Acc : 38.75%\n",
      "\n",
      "Epoch: 35\n",
      "Test epoch : 35 loss : 1.0622590482234955 Acc : 46.666666666666664%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 36\n",
      "Train epoch : 36 loss : 1.0694385170936584 Acc : 45.833333333333336%\n",
      "\n",
      "Epoch: 36\n",
      "Test epoch : 36 loss : 1.0704160332679749 Acc : 40.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 37\n",
      "Train epoch : 37 loss : 1.0921305139859518 Acc : 39.166666666666664%\n",
      "\n",
      "Epoch: 37\n",
      "Test epoch : 37 loss : 1.007218062877655 Acc : 53.333333333333336%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 38\n",
      "Train epoch : 38 loss : 1.0744157115618387 Acc : 38.75%\n",
      "\n",
      "Epoch: 38\n",
      "Test epoch : 38 loss : 1.4323241114616394 Acc : 43.333333333333336%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 39\n",
      "Train epoch : 39 loss : 1.0556385159492492 Acc : 39.583333333333336%\n",
      "\n",
      "Epoch: 39\n",
      "Test epoch : 39 loss : 1.0948214530944824 Acc : 43.333333333333336%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 40\n",
      "Train epoch : 40 loss : 1.0543656587600707 Acc : 44.166666666666664%\n",
      "\n",
      "Epoch: 40\n",
      "Test epoch : 40 loss : 0.860672801733017 Acc : 66.66666666666667%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 41\n",
      "Train epoch : 41 loss : 1.0970786015192668 Acc : 41.25%\n",
      "\n",
      "Epoch: 41\n",
      "Test epoch : 41 loss : 1.2204689383506775 Acc : 30.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 42\n",
      "Train epoch : 42 loss : 1.050076711177826 Acc : 45.416666666666664%\n",
      "\n",
      "Epoch: 42\n",
      "Test epoch : 42 loss : 1.020748645067215 Acc : 46.666666666666664%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 43\n",
      "Train epoch : 43 loss : 1.0144221703211467 Acc : 42.5%\n",
      "\n",
      "Epoch: 43\n",
      "Test epoch : 43 loss : 1.3334046602249146 Acc : 30.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 44\n",
      "Train epoch : 44 loss : 1.0290458997090657 Acc : 42.083333333333336%\n",
      "\n",
      "Epoch: 44\n",
      "Test epoch : 44 loss : 1.4021756649017334 Acc : 43.333333333333336%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 45\n",
      "Train epoch : 45 loss : 1.034817365805308 Acc : 44.166666666666664%\n",
      "\n",
      "Epoch: 45\n",
      "Test epoch : 45 loss : 1.056756317615509 Acc : 46.666666666666664%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 46\n",
      "Train epoch : 46 loss : 1.05197807153066 Acc : 43.75%\n",
      "\n",
      "Epoch: 46\n",
      "Test epoch : 46 loss : 1.3265033960342407 Acc : 30.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 47\n",
      "Train epoch : 47 loss : 1.021489715576172 Acc : 45.0%\n",
      "\n",
      "Epoch: 47\n",
      "Test epoch : 47 loss : 1.0094466805458069 Acc : 43.333333333333336%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 48\n",
      "Train epoch : 48 loss : 1.0484625021616618 Acc : 45.0%\n",
      "\n",
      "Epoch: 48\n",
      "Test epoch : 48 loss : 0.847329169511795 Acc : 73.33333333333333%\n",
      "73.33333333333333\n",
      "\n",
      "Epoch: 49\n",
      "Train epoch : 49 loss : 1.0047385533650717 Acc : 53.333333333333336%\n",
      "\n",
      "Epoch: 49\n",
      "Test epoch : 49 loss : 0.9010860919952393 Acc : 43.333333333333336%\n",
      "73.33333333333333\n",
      "\n",
      "Epoch: 50\n",
      "Train epoch : 50 loss : 0.9809592564900717 Acc : 48.333333333333336%\n",
      "\n",
      "Epoch: 50\n",
      "Test epoch : 50 loss : 0.7509315311908722 Acc : 73.33333333333333%\n",
      "73.33333333333333\n",
      "\n",
      "Epoch: 51\n",
      "Train epoch : 51 loss : 0.9998751719792683 Acc : 47.5%\n",
      "\n",
      "Epoch: 51\n",
      "Test epoch : 51 loss : 0.8328175246715546 Acc : 60.0%\n",
      "73.33333333333333\n",
      "\n",
      "Epoch: 52\n",
      "Train epoch : 52 loss : 0.9628674070040385 Acc : 48.75%\n",
      "\n",
      "Epoch: 52\n",
      "Test epoch : 52 loss : 10.136733531951904 Acc : 43.333333333333336%\n",
      "73.33333333333333\n",
      "\n",
      "Epoch: 53\n",
      "Train epoch : 53 loss : 0.919399909178416 Acc : 55.416666666666664%\n",
      "\n",
      "Epoch: 53\n",
      "Test epoch : 53 loss : 0.6255330741405487 Acc : 80.0%\n",
      "80.0\n",
      "\n",
      "Epoch: 54\n",
      "Train epoch : 54 loss : 0.878720740477244 Acc : 52.916666666666664%\n",
      "\n",
      "Epoch: 54\n",
      "Test epoch : 54 loss : 0.5954618752002716 Acc : 80.0%\n",
      "80.0\n",
      "\n",
      "Epoch: 55\n",
      "Train epoch : 55 loss : 0.9001837015151978 Acc : 61.25%\n",
      "\n",
      "Epoch: 55\n",
      "Test epoch : 55 loss : 1.6514169573783875 Acc : 30.0%\n",
      "80.0\n",
      "\n",
      "Epoch: 56\n",
      "Train epoch : 56 loss : 0.8821931560834249 Acc : 55.0%\n",
      "\n",
      "Epoch: 56\n",
      "Test epoch : 56 loss : 0.5265964865684509 Acc : 73.33333333333333%\n",
      "80.0\n",
      "\n",
      "Epoch: 57\n",
      "Train epoch : 57 loss : 0.8176749110221863 Acc : 57.5%\n",
      "\n",
      "Epoch: 57\n",
      "Test epoch : 57 loss : 0.9686647951602936 Acc : 43.333333333333336%\n",
      "80.0\n",
      "\n",
      "Epoch: 58\n",
      "Train epoch : 58 loss : 0.8076410174369812 Acc : 58.75%\n",
      "\n",
      "Epoch: 58\n",
      "Test epoch : 58 loss : 1.3553560376167297 Acc : 43.333333333333336%\n",
      "80.0\n",
      "\n",
      "Epoch: 59\n",
      "Train epoch : 59 loss : 0.7518507997194926 Acc : 65.83333333333333%\n",
      "\n",
      "Epoch: 59\n",
      "Test epoch : 59 loss : 0.7410795390605927 Acc : 66.66666666666667%\n",
      "80.0\n",
      "\n",
      "Epoch: 60\n",
      "Train epoch : 60 loss : 0.7968341549237569 Acc : 62.083333333333336%\n",
      "\n",
      "Epoch: 60\n",
      "Test epoch : 60 loss : 0.9815150201320648 Acc : 33.333333333333336%\n",
      "80.0\n",
      "\n",
      "Epoch: 61\n",
      "Train epoch : 61 loss : 0.7449183265368143 Acc : 66.66666666666667%\n",
      "\n",
      "Epoch: 61\n",
      "Test epoch : 61 loss : 1.8053017854690552 Acc : 30.0%\n",
      "80.0\n",
      "\n",
      "Epoch: 62\n",
      "Train epoch : 62 loss : 0.7608723739782969 Acc : 67.08333333333333%\n",
      "\n",
      "Epoch: 62\n",
      "Test epoch : 62 loss : 0.5957714319229126 Acc : 70.0%\n",
      "80.0\n",
      "\n",
      "Epoch: 63\n",
      "Train epoch : 63 loss : 0.6706109563509624 Acc : 72.5%\n",
      "\n",
      "Epoch: 63\n",
      "Test epoch : 63 loss : 0.9659155309200287 Acc : 40.0%\n",
      "80.0\n",
      "\n",
      "Epoch: 64\n",
      "Train epoch : 64 loss : 0.6059884309768677 Acc : 78.75%\n",
      "\n",
      "Epoch: 64\n",
      "Test epoch : 64 loss : 0.7482298612594604 Acc : 50.0%\n",
      "80.0\n",
      "\n",
      "Epoch: 65\n",
      "Train epoch : 65 loss : 0.7109581470489502 Acc : 65.0%\n",
      "\n",
      "Epoch: 65\n",
      "Test epoch : 65 loss : 0.41231219470500946 Acc : 83.33333333333333%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 66\n",
      "Train epoch : 66 loss : 0.7269993603229523 Acc : 66.66666666666667%\n",
      "\n",
      "Epoch: 66\n",
      "Test epoch : 66 loss : 0.36374640464782715 Acc : 86.66666666666667%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 67\n",
      "Train epoch : 67 loss : 0.7083341181278229 Acc : 67.91666666666667%\n",
      "\n",
      "Epoch: 67\n",
      "Test epoch : 67 loss : 0.8524973690509796 Acc : 50.0%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 68\n",
      "Train epoch : 68 loss : 0.7191918730735779 Acc : 66.25%\n",
      "\n",
      "Epoch: 68\n",
      "Test epoch : 68 loss : 0.7473934292793274 Acc : 50.0%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 69\n",
      "Train epoch : 69 loss : 0.7112860123316447 Acc : 67.5%\n",
      "\n",
      "Epoch: 69\n",
      "Test epoch : 69 loss : 0.3361804932355881 Acc : 86.66666666666667%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 70\n",
      "Train epoch : 70 loss : 0.6781562666098276 Acc : 69.58333333333333%\n",
      "\n",
      "Epoch: 70\n",
      "Test epoch : 70 loss : 0.45274172723293304 Acc : 83.33333333333333%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 71\n",
      "Train epoch : 71 loss : 0.7691407124201457 Acc : 65.41666666666667%\n",
      "\n",
      "Epoch: 71\n",
      "Test epoch : 71 loss : 1.8108803033828735 Acc : 30.0%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 72\n",
      "Train epoch : 72 loss : 0.6638298412164052 Acc : 69.58333333333333%\n",
      "\n",
      "Epoch: 72\n",
      "Test epoch : 72 loss : 0.4745773822069168 Acc : 80.0%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 73\n",
      "Train epoch : 73 loss : 0.6437974433104198 Acc : 70.41666666666667%\n",
      "\n",
      "Epoch: 73\n",
      "Test epoch : 73 loss : 0.29173748195171356 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 74\n",
      "Train epoch : 74 loss : 0.5866103450457255 Acc : 72.91666666666667%\n",
      "\n",
      "Epoch: 74\n",
      "Test epoch : 74 loss : 0.5740198493003845 Acc : 66.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 75\n",
      "Train epoch : 75 loss : 0.651747214794159 Acc : 73.33333333333333%\n",
      "\n",
      "Epoch: 75\n",
      "Test epoch : 75 loss : 1.688640832901001 Acc : 50.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 76\n",
      "Train epoch : 76 loss : 0.632598094145457 Acc : 70.0%\n",
      "\n",
      "Epoch: 76\n",
      "Test epoch : 76 loss : 1.5171030759811401 Acc : 33.333333333333336%\n",
      "100.0\n",
      "\n",
      "Epoch: 77\n",
      "Train epoch : 77 loss : 0.565142979224523 Acc : 77.5%\n",
      "\n",
      "Epoch: 77\n",
      "Test epoch : 77 loss : 1.1934965252876282 Acc : 40.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 78\n",
      "Train epoch : 78 loss : 0.5828193664550781 Acc : 74.16666666666667%\n",
      "\n",
      "Epoch: 78\n",
      "Test epoch : 78 loss : 0.4215758889913559 Acc : 80.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 79\n",
      "Train epoch : 79 loss : 0.5382538318634034 Acc : 78.33333333333333%\n",
      "\n",
      "Epoch: 79\n",
      "Test epoch : 79 loss : 2.218563139438629 Acc : 46.666666666666664%\n",
      "100.0\n",
      "\n",
      "Epoch: 80\n",
      "Train epoch : 80 loss : 0.5458056549231212 Acc : 75.0%\n",
      "\n",
      "Epoch: 80\n",
      "Test epoch : 80 loss : 0.47924181818962097 Acc : 73.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 81\n",
      "Train epoch : 81 loss : 0.609391164779663 Acc : 77.08333333333333%\n",
      "\n",
      "Epoch: 81\n",
      "Test epoch : 81 loss : 0.37147295475006104 Acc : 86.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 82\n",
      "Train epoch : 82 loss : 1.0145611802736918 Acc : 63.75%\n",
      "\n",
      "Epoch: 82\n",
      "Test epoch : 82 loss : 748.9571533203125 Acc : 43.333333333333336%\n",
      "100.0\n",
      "\n",
      "Epoch: 83\n",
      "Train epoch : 83 loss : 1.291705842812856 Acc : 50.416666666666664%\n",
      "\n",
      "Epoch: 83\n",
      "Test epoch : 83 loss : 1.5223422646522522 Acc : 30.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 84\n",
      "Train epoch : 84 loss : 0.7463826100031535 Acc : 65.83333333333333%\n",
      "\n",
      "Epoch: 84\n",
      "Test epoch : 84 loss : 0.4654412865638733 Acc : 73.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 85\n",
      "Train epoch : 85 loss : 0.6704034626483917 Acc : 70.83333333333333%\n",
      "\n",
      "Epoch: 85\n",
      "Test epoch : 85 loss : 0.6184550523757935 Acc : 66.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 86\n",
      "Train epoch : 86 loss : 0.7235869963963827 Acc : 68.33333333333333%\n",
      "\n",
      "Epoch: 86\n",
      "Test epoch : 86 loss : 1.3488210439682007 Acc : 30.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 87\n",
      "Train epoch : 87 loss : 0.7872900446256001 Acc : 64.58333333333333%\n",
      "\n",
      "Epoch: 87\n",
      "Test epoch : 87 loss : 0.6215303838253021 Acc : 73.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 88\n",
      "Train epoch : 88 loss : 0.7272597968578338 Acc : 67.5%\n",
      "\n",
      "Epoch: 88\n",
      "Test epoch : 88 loss : 0.5092274248600006 Acc : 76.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 89\n",
      "Train epoch : 89 loss : 0.5535058438777923 Acc : 79.58333333333333%\n",
      "\n",
      "Epoch: 89\n",
      "Test epoch : 89 loss : 0.596794605255127 Acc : 63.333333333333336%\n",
      "100.0\n",
      "\n",
      "Epoch: 90\n",
      "Train epoch : 90 loss : 0.571365108092626 Acc : 78.75%\n",
      "\n",
      "Epoch: 90\n",
      "Test epoch : 90 loss : 1.0143213868141174 Acc : 43.333333333333336%\n",
      "100.0\n",
      "\n",
      "Epoch: 91\n",
      "Train epoch : 91 loss : 0.5361733476320902 Acc : 76.66666666666667%\n",
      "\n",
      "Epoch: 91\n",
      "Test epoch : 91 loss : 0.5296974778175354 Acc : 73.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 92\n",
      "Train epoch : 92 loss : 0.6683272838592529 Acc : 71.66666666666667%\n",
      "\n",
      "Epoch: 92\n",
      "Test epoch : 92 loss : 0.29056455194950104 Acc : 90.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 93\n",
      "Train epoch : 93 loss : 0.5960737804571787 Acc : 74.16666666666667%\n",
      "\n",
      "Epoch: 93\n",
      "Test epoch : 93 loss : 0.3134141191840172 Acc : 93.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 94\n",
      "Train epoch : 94 loss : 0.5415676613648732 Acc : 77.5%\n",
      "\n",
      "Epoch: 94\n",
      "Test epoch : 94 loss : 0.20812075585126877 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 95\n",
      "Train epoch : 95 loss : 0.6713426053524018 Acc : 75.41666666666667%\n",
      "\n",
      "Epoch: 95\n",
      "Test epoch : 95 loss : 0.19282393902540207 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 96\n",
      "Train epoch : 96 loss : 0.64070250193278 Acc : 73.33333333333333%\n",
      "\n",
      "Epoch: 96\n",
      "Test epoch : 96 loss : 3.183601140975952 Acc : 43.333333333333336%\n",
      "100.0\n",
      "\n",
      "Epoch: 97\n",
      "Train epoch : 97 loss : 0.5023434847593308 Acc : 81.66666666666667%\n",
      "\n",
      "Epoch: 97\n",
      "Test epoch : 97 loss : 0.24422112852334976 Acc : 90.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 98\n",
      "Train epoch : 98 loss : 0.48011532028516135 Acc : 78.75%\n",
      "\n",
      "Epoch: 98\n",
      "Test epoch : 98 loss : 0.47255586087703705 Acc : 80.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 99\n",
      "Train epoch : 99 loss : 0.6613001088301341 Acc : 71.66666666666667%\n",
      "\n",
      "Epoch: 99\n",
      "Test epoch : 99 loss : 0.3384317383170128 Acc : 90.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 100\n",
      "Train epoch : 100 loss : 0.5850285112857818 Acc : 75.83333333333333%\n",
      "\n",
      "Epoch: 100\n",
      "Test epoch : 100 loss : 0.33969807624816895 Acc : 86.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 101\n",
      "Train epoch : 101 loss : 0.5136452297369639 Acc : 82.08333333333333%\n",
      "\n",
      "Epoch: 101\n",
      "Test epoch : 101 loss : 1.457015872001648 Acc : 30.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 102\n",
      "Train epoch : 102 loss : 0.48971155683199563 Acc : 78.33333333333333%\n",
      "\n",
      "Epoch: 102\n",
      "Test epoch : 102 loss : 0.7565400898456573 Acc : 60.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 103\n",
      "Train epoch : 103 loss : 0.5756960332393646 Acc : 78.33333333333333%\n",
      "\n",
      "Epoch: 103\n",
      "Test epoch : 103 loss : 1.2960579991340637 Acc : 43.333333333333336%\n",
      "100.0\n",
      "\n",
      "Epoch: 104\n",
      "Train epoch : 104 loss : 0.5674141804377238 Acc : 75.0%\n",
      "\n",
      "Epoch: 104\n",
      "Test epoch : 104 loss : 0.21743521839380264 Acc : 93.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 105\n",
      "Train epoch : 105 loss : 0.45436310668786367 Acc : 80.41666666666667%\n",
      "\n",
      "Epoch: 105\n",
      "Test epoch : 105 loss : 0.4744741916656494 Acc : 76.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 106\n",
      "Train epoch : 106 loss : 0.6051602840423584 Acc : 74.58333333333333%\n",
      "\n",
      "Epoch: 106\n",
      "Test epoch : 106 loss : 0.22843559086322784 Acc : 93.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 107\n",
      "Train epoch : 107 loss : 0.5236424326896667 Acc : 78.33333333333333%\n",
      "\n",
      "Epoch: 107\n",
      "Test epoch : 107 loss : 0.4968854784965515 Acc : 66.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 108\n",
      "Train epoch : 108 loss : 0.512839271624883 Acc : 79.58333333333333%\n",
      "\n",
      "Epoch: 108\n",
      "Test epoch : 108 loss : 0.48478394746780396 Acc : 76.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 109\n",
      "Train epoch : 109 loss : 0.5180285573005676 Acc : 77.91666666666667%\n",
      "\n",
      "Epoch: 109\n",
      "Test epoch : 109 loss : 0.3083431124687195 Acc : 90.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 110\n",
      "Train epoch : 110 loss : 0.41660711765289304 Acc : 83.33333333333333%\n",
      "\n",
      "Epoch: 110\n",
      "Test epoch : 110 loss : 0.2964162677526474 Acc : 90.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 111\n",
      "Train epoch : 111 loss : 0.4715611696243286 Acc : 77.5%\n",
      "\n",
      "Epoch: 111\n",
      "Test epoch : 111 loss : 0.12784062325954437 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 112\n",
      "Train epoch : 112 loss : 0.47424513697624204 Acc : 79.16666666666667%\n",
      "\n",
      "Epoch: 112\n",
      "Test epoch : 112 loss : 1.0193998515605927 Acc : 36.666666666666664%\n",
      "100.0\n",
      "\n",
      "Epoch: 113\n",
      "Train epoch : 113 loss : 0.4766538321971893 Acc : 79.58333333333333%\n",
      "\n",
      "Epoch: 113\n",
      "Test epoch : 113 loss : 0.14759359508752823 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 114\n",
      "Train epoch : 114 loss : 0.4417569041252136 Acc : 82.08333333333333%\n",
      "\n",
      "Epoch: 114\n",
      "Test epoch : 114 loss : 0.19148605316877365 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 115\n",
      "Train epoch : 115 loss : 0.43905923068523406 Acc : 82.91666666666667%\n",
      "\n",
      "Epoch: 115\n",
      "Test epoch : 115 loss : 0.3842415362596512 Acc : 80.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 116\n",
      "Train epoch : 116 loss : 0.41896488269170123 Acc : 85.41666666666667%\n",
      "\n",
      "Epoch: 116\n",
      "Test epoch : 116 loss : 0.38813264667987823 Acc : 80.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 117\n",
      "Train epoch : 117 loss : 0.48846711913744606 Acc : 80.83333333333333%\n",
      "\n",
      "Epoch: 117\n",
      "Test epoch : 117 loss : 0.13937991484999657 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 118\n",
      "Train epoch : 118 loss : 0.39415917893250785 Acc : 83.75%\n",
      "\n",
      "Epoch: 118\n",
      "Test epoch : 118 loss : 0.4011083096265793 Acc : 76.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 119\n",
      "Train epoch : 119 loss : 0.4741944471995036 Acc : 79.58333333333333%\n",
      "\n",
      "Epoch: 119\n",
      "Test epoch : 119 loss : 1.1876817047595978 Acc : 46.666666666666664%\n",
      "100.0\n",
      "\n",
      "Epoch: 120\n",
      "Train epoch : 120 loss : 0.5676149348417918 Acc : 80.0%\n",
      "\n",
      "Epoch: 120\n",
      "Test epoch : 120 loss : 0.3935750871896744 Acc : 83.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 121\n",
      "Train epoch : 121 loss : 0.4194425642490387 Acc : 84.58333333333333%\n",
      "\n",
      "Epoch: 121\n",
      "Test epoch : 121 loss : 0.322175107896328 Acc : 86.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 122\n",
      "Train epoch : 122 loss : 0.4350447098414103 Acc : 80.41666666666667%\n",
      "\n",
      "Epoch: 122\n",
      "Test epoch : 122 loss : 1.755275547504425 Acc : 30.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 123\n",
      "Train epoch : 123 loss : 0.4420434276262919 Acc : 83.33333333333333%\n",
      "\n",
      "Epoch: 123\n",
      "Test epoch : 123 loss : 0.1273319348692894 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 124\n",
      "Train epoch : 124 loss : 0.3759476761023203 Acc : 84.58333333333333%\n",
      "\n",
      "Epoch: 124\n",
      "Test epoch : 124 loss : 0.12309569492936134 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 125\n",
      "Train epoch : 125 loss : 0.4247646391391754 Acc : 84.58333333333333%\n",
      "\n",
      "Epoch: 125\n",
      "Test epoch : 125 loss : 0.19549956172704697 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 126\n",
      "Train epoch : 126 loss : 0.3702611356973648 Acc : 85.41666666666667%\n",
      "\n",
      "Epoch: 126\n",
      "Test epoch : 126 loss : 0.12239208817481995 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 127\n",
      "Train epoch : 127 loss : 0.4288196007410685 Acc : 82.5%\n",
      "\n",
      "Epoch: 127\n",
      "Test epoch : 127 loss : 0.11181572824716568 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 128\n",
      "Train epoch : 128 loss : 0.34958830873171487 Acc : 85.41666666666667%\n",
      "\n",
      "Epoch: 128\n",
      "Test epoch : 128 loss : 0.12743841111660004 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 129\n",
      "Train epoch : 129 loss : 0.3634138951698939 Acc : 87.91666666666667%\n",
      "\n",
      "Epoch: 129\n",
      "Test epoch : 129 loss : 0.13508719950914383 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 130\n",
      "Train epoch : 130 loss : 0.39746792217095694 Acc : 82.91666666666667%\n",
      "\n",
      "Epoch: 130\n",
      "Test epoch : 130 loss : 1.665769338607788 Acc : 30.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 131\n",
      "Train epoch : 131 loss : 0.30741861363252004 Acc : 87.91666666666667%\n",
      "\n",
      "Epoch: 131\n",
      "Test epoch : 131 loss : 0.23827606439590454 Acc : 90.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 132\n",
      "Train epoch : 132 loss : 0.3222076912720998 Acc : 87.5%\n",
      "\n",
      "Epoch: 132\n",
      "Test epoch : 132 loss : 0.6833317577838898 Acc : 63.333333333333336%\n",
      "100.0\n",
      "\n",
      "Epoch: 133\n",
      "Train epoch : 133 loss : 0.42790607213973997 Acc : 82.08333333333333%\n",
      "\n",
      "Epoch: 133\n",
      "Test epoch : 133 loss : 0.20973241329193115 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 134\n",
      "Train epoch : 134 loss : 0.4095990300178528 Acc : 83.75%\n",
      "\n",
      "Epoch: 134\n",
      "Test epoch : 134 loss : 0.5803198516368866 Acc : 66.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 135\n",
      "Train epoch : 135 loss : 0.3951945722103119 Acc : 85.83333333333333%\n",
      "\n",
      "Epoch: 135\n",
      "Test epoch : 135 loss : 0.11973997578024864 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 136\n",
      "Train epoch : 136 loss : 0.4288585881392161 Acc : 82.91666666666667%\n",
      "\n",
      "Epoch: 136\n",
      "Test epoch : 136 loss : 0.07637322880327702 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 137\n",
      "Train epoch : 137 loss : 0.3579370160897573 Acc : 87.91666666666667%\n",
      "\n",
      "Epoch: 137\n",
      "Test epoch : 137 loss : 0.10227602161467075 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 138\n",
      "Train epoch : 138 loss : 0.4054573883612951 Acc : 83.33333333333333%\n",
      "\n",
      "Epoch: 138\n",
      "Test epoch : 138 loss : 0.11621807515621185 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 139\n",
      "Train epoch : 139 loss : 0.4239761958519618 Acc : 82.08333333333333%\n",
      "\n",
      "Epoch: 139\n",
      "Test epoch : 139 loss : 0.18141839653253555 Acc : 93.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 140\n",
      "Train epoch : 140 loss : 0.31905842423439024 Acc : 90.41666666666667%\n",
      "\n",
      "Epoch: 140\n",
      "Test epoch : 140 loss : 0.31276798993349075 Acc : 83.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 141\n",
      "Train epoch : 141 loss : 0.4052329440911611 Acc : 80.41666666666667%\n",
      "\n",
      "Epoch: 141\n",
      "Test epoch : 141 loss : 0.0880979485809803 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 142\n",
      "Train epoch : 142 loss : 0.3048478841781616 Acc : 88.75%\n",
      "\n",
      "Epoch: 142\n",
      "Test epoch : 142 loss : 0.2895371988415718 Acc : 83.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 143\n",
      "Train epoch : 143 loss : 0.32617647051811216 Acc : 87.08333333333333%\n",
      "\n",
      "Epoch: 143\n",
      "Test epoch : 143 loss : 0.11553188785910606 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 144\n",
      "Train epoch : 144 loss : 0.3975897451241811 Acc : 82.08333333333333%\n",
      "\n",
      "Epoch: 144\n",
      "Test epoch : 144 loss : 0.34922491014003754 Acc : 83.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 145\n",
      "Train epoch : 145 loss : 0.32172765135765075 Acc : 91.25%\n",
      "\n",
      "Epoch: 145\n",
      "Test epoch : 145 loss : 0.24283681064844131 Acc : 90.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 146\n",
      "Train epoch : 146 loss : 0.3741594135761261 Acc : 83.33333333333333%\n",
      "\n",
      "Epoch: 146\n",
      "Test epoch : 146 loss : 0.06847863085567951 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 147\n",
      "Train epoch : 147 loss : 0.39898339807987215 Acc : 83.33333333333333%\n",
      "\n",
      "Epoch: 147\n",
      "Test epoch : 147 loss : 0.07163158990442753 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 148\n",
      "Train epoch : 148 loss : 0.36959538559118904 Acc : 86.25%\n",
      "\n",
      "Epoch: 148\n",
      "Test epoch : 148 loss : 0.05506545305252075 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 149\n",
      "Train epoch : 149 loss : 0.3433809608221054 Acc : 87.5%\n",
      "\n",
      "Epoch: 149\n",
      "Test epoch : 149 loss : 1.233045518398285 Acc : 60.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 150\n",
      "Train epoch : 150 loss : 0.35870637198289235 Acc : 84.58333333333333%\n",
      "\n",
      "Epoch: 150\n",
      "Test epoch : 150 loss : 0.2569114714860916 Acc : 90.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 151\n",
      "Train epoch : 151 loss : 0.286507718761762 Acc : 90.41666666666667%\n",
      "\n",
      "Epoch: 151\n",
      "Test epoch : 151 loss : 0.7801180481910706 Acc : 63.333333333333336%\n",
      "100.0\n",
      "\n",
      "Epoch: 152\n",
      "Train epoch : 152 loss : 0.38894590760270753 Acc : 83.33333333333333%\n",
      "\n",
      "Epoch: 152\n",
      "Test epoch : 152 loss : 1.8550122380256653 Acc : 36.666666666666664%\n",
      "100.0\n",
      "\n",
      "Epoch: 153\n",
      "Train epoch : 153 loss : 0.27660168906052907 Acc : 90.83333333333333%\n",
      "\n",
      "Epoch: 153\n",
      "Test epoch : 153 loss : 1.3250585794448853 Acc : 56.666666666666664%\n",
      "100.0\n",
      "\n",
      "Epoch: 154\n",
      "Train epoch : 154 loss : 0.36761891742547353 Acc : 86.66666666666667%\n",
      "\n",
      "Epoch: 154\n",
      "Test epoch : 154 loss : 0.19819523394107819 Acc : 90.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 155\n",
      "Train epoch : 155 loss : 0.3502248247464498 Acc : 87.91666666666667%\n",
      "\n",
      "Epoch: 155\n",
      "Test epoch : 155 loss : 0.9419377148151398 Acc : 73.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 156\n",
      "Train epoch : 156 loss : 0.3470011830329895 Acc : 87.91666666666667%\n",
      "\n",
      "Epoch: 156\n",
      "Test epoch : 156 loss : 0.1842804104089737 Acc : 90.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 157\n",
      "Train epoch : 157 loss : 0.3245875045657158 Acc : 87.91666666666667%\n",
      "\n",
      "Epoch: 157\n",
      "Test epoch : 157 loss : 0.07314567267894745 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 158\n",
      "Train epoch : 158 loss : 0.33784122864405314 Acc : 87.08333333333333%\n",
      "\n",
      "Epoch: 158\n",
      "Test epoch : 158 loss : 0.1575976051390171 Acc : 93.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 159\n",
      "Train epoch : 159 loss : 0.3742678940296173 Acc : 85.41666666666667%\n",
      "\n",
      "Epoch: 159\n",
      "Test epoch : 159 loss : 0.07374955154955387 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 160\n",
      "Train epoch : 160 loss : 0.3958731989065806 Acc : 84.16666666666667%\n",
      "\n",
      "Epoch: 160\n",
      "Test epoch : 160 loss : 1.666856288909912 Acc : 46.666666666666664%\n",
      "100.0\n",
      "\n",
      "Epoch: 161\n",
      "Train epoch : 161 loss : 0.25143546611070633 Acc : 91.25%\n",
      "\n",
      "Epoch: 161\n",
      "Test epoch : 161 loss : 0.0790691152215004 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 162\n",
      "Train epoch : 162 loss : 0.4116419350107511 Acc : 82.08333333333333%\n",
      "\n",
      "Epoch: 162\n",
      "Test epoch : 162 loss : 0.10927848890423775 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 163\n",
      "Train epoch : 163 loss : 0.3381100838383039 Acc : 88.75%\n",
      "\n",
      "Epoch: 163\n",
      "Test epoch : 163 loss : 1.571333408355713 Acc : 40.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 164\n",
      "Train epoch : 164 loss : 0.2828858544429143 Acc : 87.91666666666667%\n",
      "\n",
      "Epoch: 164\n",
      "Test epoch : 164 loss : 0.1656412072479725 Acc : 93.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 165\n",
      "Train epoch : 165 loss : 0.2944124961892764 Acc : 87.5%\n",
      "\n",
      "Epoch: 165\n",
      "Test epoch : 165 loss : 0.060087017714977264 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 166\n",
      "Train epoch : 166 loss : 0.36873091459274293 Acc : 85.83333333333333%\n",
      "\n",
      "Epoch: 166\n",
      "Test epoch : 166 loss : 0.42258797585964203 Acc : 83.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 167\n",
      "Train epoch : 167 loss : 0.2915690948565801 Acc : 87.91666666666667%\n",
      "\n",
      "Epoch: 167\n",
      "Test epoch : 167 loss : 0.07479312270879745 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 168\n",
      "Train epoch : 168 loss : 0.31512982000907264 Acc : 87.91666666666667%\n",
      "\n",
      "Epoch: 168\n",
      "Test epoch : 168 loss : 0.20876052975654602 Acc : 93.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 169\n",
      "Train epoch : 169 loss : 0.31357325861851376 Acc : 85.83333333333333%\n",
      "\n",
      "Epoch: 169\n",
      "Test epoch : 169 loss : 1.8150975704193115 Acc : 43.333333333333336%\n",
      "100.0\n",
      "\n",
      "Epoch: 170\n",
      "Train epoch : 170 loss : 0.34643844813108443 Acc : 85.41666666666667%\n",
      "\n",
      "Epoch: 170\n",
      "Test epoch : 170 loss : 2.962622046470642 Acc : 40.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 171\n",
      "Train epoch : 171 loss : 0.2790589173634847 Acc : 89.16666666666667%\n",
      "\n",
      "Epoch: 171\n",
      "Test epoch : 171 loss : 0.23437746614217758 Acc : 86.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 172\n",
      "Train epoch : 172 loss : 0.2670188243190447 Acc : 91.66666666666667%\n",
      "\n",
      "Epoch: 172\n",
      "Test epoch : 172 loss : 0.5773457586765289 Acc : 76.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 173\n",
      "Train epoch : 173 loss : 0.3072312648097674 Acc : 90.41666666666667%\n",
      "\n",
      "Epoch: 173\n",
      "Test epoch : 173 loss : 4.9629294872283936 Acc : 50.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 174\n",
      "Train epoch : 174 loss : 0.3696469972531001 Acc : 84.16666666666667%\n",
      "\n",
      "Epoch: 174\n",
      "Test epoch : 174 loss : 0.10703565739095211 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 175\n",
      "Train epoch : 175 loss : 0.3048881307244301 Acc : 89.58333333333333%\n",
      "\n",
      "Epoch: 175\n",
      "Test epoch : 175 loss : 0.6428568661212921 Acc : 73.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 176\n",
      "Train epoch : 176 loss : 0.2570760607719421 Acc : 91.66666666666667%\n",
      "\n",
      "Epoch: 176\n",
      "Test epoch : 176 loss : 0.04292619228363037 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 177\n",
      "Train epoch : 177 loss : 0.36245373884836835 Acc : 85.41666666666667%\n",
      "\n",
      "Epoch: 177\n",
      "Test epoch : 177 loss : 0.062387509271502495 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 178\n",
      "Train epoch : 178 loss : 0.4820707346002261 Acc : 82.5%\n",
      "\n",
      "Epoch: 178\n",
      "Test epoch : 178 loss : 0.05279593728482723 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 179\n",
      "Train epoch : 179 loss : 0.2759947344660759 Acc : 88.75%\n",
      "\n",
      "Epoch: 179\n",
      "Test epoch : 179 loss : 0.047941720113158226 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 180\n",
      "Train epoch : 180 loss : 0.2906414488951365 Acc : 87.5%\n",
      "\n",
      "Epoch: 180\n",
      "Test epoch : 180 loss : 0.048395974561572075 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 181\n",
      "Train epoch : 181 loss : 0.2723790779709816 Acc : 92.08333333333333%\n",
      "\n",
      "Epoch: 181\n",
      "Test epoch : 181 loss : 2.154097080230713 Acc : 43.333333333333336%\n",
      "100.0\n",
      "\n",
      "Epoch: 182\n",
      "Train epoch : 182 loss : 0.2878036389748255 Acc : 88.33333333333333%\n",
      "\n",
      "Epoch: 182\n",
      "Test epoch : 182 loss : 0.12781686708331108 Acc : 93.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 183\n",
      "Train epoch : 183 loss : 0.2845698192715645 Acc : 88.75%\n",
      "\n",
      "Epoch: 183\n",
      "Test epoch : 183 loss : 0.05537228472530842 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 184\n",
      "Train epoch : 184 loss : 0.3517211625973384 Acc : 84.16666666666667%\n",
      "\n",
      "Epoch: 184\n",
      "Test epoch : 184 loss : 0.053378716111183167 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 185\n",
      "Train epoch : 185 loss : 0.24273327191670735 Acc : 90.41666666666667%\n",
      "\n",
      "Epoch: 185\n",
      "Test epoch : 185 loss : 2.4892078638076782 Acc : 46.666666666666664%\n",
      "100.0\n",
      "\n",
      "Epoch: 186\n",
      "Train epoch : 186 loss : 0.30862968663374585 Acc : 89.58333333333333%\n",
      "\n",
      "Epoch: 186\n",
      "Test epoch : 186 loss : 0.9398762285709381 Acc : 50.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 187\n",
      "Train epoch : 187 loss : 0.22941270073254902 Acc : 90.83333333333333%\n",
      "\n",
      "Epoch: 187\n",
      "Test epoch : 187 loss : 0.09545968100428581 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 188\n",
      "Train epoch : 188 loss : 0.20832464893658956 Acc : 92.5%\n",
      "\n",
      "Epoch: 188\n",
      "Test epoch : 188 loss : 0.10597558133304119 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 189\n",
      "Train epoch : 189 loss : 0.31308001031478244 Acc : 89.16666666666667%\n",
      "\n",
      "Epoch: 189\n",
      "Test epoch : 189 loss : 0.06340272352099419 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 190\n",
      "Train epoch : 190 loss : 0.3018503134449323 Acc : 88.75%\n",
      "\n",
      "Epoch: 190\n",
      "Test epoch : 190 loss : 0.08971685729920864 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 191\n",
      "Train epoch : 191 loss : 0.2237614909807841 Acc : 91.66666666666667%\n",
      "\n",
      "Epoch: 191\n",
      "Test epoch : 191 loss : 0.633465439081192 Acc : 70.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 192\n",
      "Train epoch : 192 loss : 0.25486942181984584 Acc : 91.25%\n",
      "\n",
      "Epoch: 192\n",
      "Test epoch : 192 loss : 1.576038658618927 Acc : 60.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 193\n",
      "Train epoch : 193 loss : 0.17561967372894288 Acc : 93.33333333333333%\n",
      "\n",
      "Epoch: 193\n",
      "Test epoch : 193 loss : 0.32559289783239365 Acc : 83.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 194\n",
      "Train epoch : 194 loss : 0.2554085373878479 Acc : 92.08333333333333%\n",
      "\n",
      "Epoch: 194\n",
      "Test epoch : 194 loss : 0.09293730929493904 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 195\n",
      "Train epoch : 195 loss : 0.22827133312821388 Acc : 92.5%\n",
      "\n",
      "Epoch: 195\n",
      "Test epoch : 195 loss : 0.059275850653648376 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 196\n",
      "Train epoch : 196 loss : 0.1997206707795461 Acc : 91.66666666666667%\n",
      "\n",
      "Epoch: 196\n",
      "Test epoch : 196 loss : 0.07922758348286152 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 197\n",
      "Train epoch : 197 loss : 0.20152111599842706 Acc : 92.5%\n",
      "\n",
      "Epoch: 197\n",
      "Test epoch : 197 loss : 0.11959756724536419 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 198\n",
      "Train epoch : 198 loss : 0.3615078866481781 Acc : 83.75%\n",
      "\n",
      "Epoch: 198\n",
      "Test epoch : 198 loss : 0.5321930646896362 Acc : 73.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 199\n",
      "Train epoch : 199 loss : 0.2063188115755717 Acc : 93.75%\n",
      "\n",
      "Epoch: 199\n",
      "Test epoch : 199 loss : 0.15303324908018112 Acc : 93.33333333333333%\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 및 평가\n",
    "BEST_SCORE = 0\n",
    "for epoch in range(epochs):\n",
    "    train(epoch)\n",
    "    test(epoch, valloader)\n",
    "    print(BEST_SCORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: -1\n",
      "{0: 11, 1: 8, 2: 11}\n",
      "{0: 11, 1: 8, 2: 9}\n",
      "Test epoch : -1 loss : 0.2222946584224701 Acc : 93.33333333333333%\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋에서 평가\n",
    "model.load_state_dict(torch.load(os.path.join(save_path, f'teacher.pth')))\n",
    "test(-1, testloader, 'test', True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "run",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (main, Mar 31 2022, 08:41:55) [GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb50cdd79c86e8dce50f207c8be5ca838005251520472ce9347018b25221847d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

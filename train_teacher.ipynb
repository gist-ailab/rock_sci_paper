{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\fskd\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#필요한 라이브러리들 import\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import dataset\n",
    "import model\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각종 path및 하이퍼 파라미터 설정\n",
    "data_path = 'C:\\\\Users\\\\USER\\\\Desktop\\\\GSH_CRP\\\\codes\\\\rock_sci_paper\\\\data\\\\ro_sci_pa'\n",
    "save_path = 'C:\\\\Users\\\\USER\\\\Desktop\\\\GSH_CRP\\\\codes\\\\rock_sci_paper\\\\model_para'\n",
    "epochs = 200\n",
    "batch_size = 16\n",
    "learning_rate = 0.01\n",
    "seed = 0\n",
    "mode = 'hr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 설정\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# device 설정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform 설정\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomAffine((-45, 45), translate=(0.2,0.2)),\n",
    "    transforms.CenterCrop((224,224)),\n",
    "    transforms.ColorJitter(brightness=0.5),\n",
    "    transforms.ColorJitter(contrast=0.5),\n",
    "    transforms.ColorJitter(saturation=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]\n",
    ")\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.CenterCrop((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "18\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "# dataset 설정\n",
    "train_dataset = dataset.RockScissorsPaper(\n",
    "    transform=train_transform,\n",
    "    path = data_path,\n",
    "    mode = 'train'\n",
    ")\n",
    "val_dataset = dataset.RockScissorsPaper(\n",
    "    transform=test_transform,\n",
    "    path = data_path,\n",
    "    mode = 'val'\n",
    ")\n",
    "test_dataset = dataset.RockScissorsPaper(\n",
    "    transform=test_transform,\n",
    "    path = data_path,\n",
    "    mode = 'test'\n",
    ")\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader 설정\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델, 손실함수, 옵티마이저 설정\n",
    "model = model.ResNet18(num_classes=3)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    print('\\nEpoch: %d'%epoch)\n",
    "    # model train mode로 전환\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    total = 0\n",
    "    for (inputs, labels) in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if mode=='lr':\n",
    "            h,w = inputs.shape[-2], inputs.shape[-1]\n",
    "            lr_inputs = F.interpolate(inputs, (h//64, w//64))\n",
    "            lr_inputs = F.interpolate(lr_inputs, (h,w))\n",
    "            outputs, _, _, _, _ = model(lr_inputs)\n",
    "        else:\n",
    "            outputs, _, _, _, _ = model(inputs)\n",
    "            \n",
    "        _, pred = torch.max(outputs, 1)\n",
    "        total += outputs.size(0)\n",
    "        running_acc += (pred == labels).sum().item()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    total_loss = running_loss / len(trainloader)\n",
    "    total_acc = 100 * running_acc / total\n",
    "    print(f'Train epoch : {epoch} loss : {total_loss} Acc : {total_acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, loader, mode='val'):\n",
    "    print('\\nEpoch: %d'%epoch)\n",
    "    # model eval mode로 전환\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    total = 0\n",
    "    label_dict = {0:0, 1:0, 2:0}\n",
    "    correct_dict = {0:0, 1:0, 2:0}\n",
    "    global BEST_SCORE\n",
    "    with torch.no_grad():\n",
    "        for (inputs, labels) in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            if mode=='lr':\n",
    "                h,w = inputs.shape[-2], inputs.shape[-1]\n",
    "                lr_inputs = F.interpolate(inputs, (h//32, w//32))\n",
    "                lr_inputs = F.interpolate(lr_inputs, (h,w))\n",
    "                outputs, _, _, _, _ = model(lr_inputs)\n",
    "            else:\n",
    "                outputs, _, _, _, _ = model(inputs)\n",
    "\n",
    "            _, pred = torch.max(outputs, 1)\n",
    "            \n",
    "            total += outputs.size(0)\n",
    "            running_acc += (pred == labels).sum().item()\n",
    "            \n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                label_dict[label.item()] += 1\n",
    "                if (pred==labels)[i]:\n",
    "                    correct_dict[label.item()] += 1\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "        total_loss = running_loss / len(loader)\n",
    "        total_acc = 100 * running_acc / total\n",
    "        # print(label_dict)\n",
    "        # print(correct_dict)\n",
    "        if total_acc > BEST_SCORE and not mode=='test':\n",
    "            path = os.path.join(save_path, f'teacher.pth')\n",
    "            torch.save(model.state_dict(), path)\n",
    "            BEST_SCORE = total_acc\n",
    "        print(f'Test epoch : {epoch} loss : {total_loss} Acc : {total_acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "Train epoch : 0 loss : 1.183347225189209 Acc : 32.638888888888886%\n",
      "\n",
      "Epoch: 0\n",
      "Test epoch : 0 loss : 1.1429925560951233 Acc : 16.666666666666668%\n",
      "16.666666666666668\n",
      "\n",
      "Epoch: 1\n",
      "Train epoch : 1 loss : 1.2332109146647983 Acc : 34.02777777777778%\n",
      "\n",
      "Epoch: 1\n",
      "Test epoch : 1 loss : 1.1686627268791199 Acc : 33.333333333333336%\n",
      "33.333333333333336\n",
      "\n",
      "Epoch: 2\n",
      "Train epoch : 2 loss : 1.1642847458521526 Acc : 36.80555555555556%\n",
      "\n",
      "Epoch: 2\n",
      "Test epoch : 2 loss : 1.1348689198493958 Acc : 16.666666666666668%\n",
      "33.333333333333336\n",
      "\n",
      "Epoch: 3\n",
      "Train epoch : 3 loss : 1.1590954860051472 Acc : 29.86111111111111%\n",
      "\n",
      "Epoch: 3\n",
      "Test epoch : 3 loss : 1.1097714006900787 Acc : 16.666666666666668%\n",
      "33.333333333333336\n",
      "\n",
      "Epoch: 4\n",
      "Train epoch : 4 loss : 1.1525616645812988 Acc : 37.5%\n",
      "\n",
      "Epoch: 4\n",
      "Test epoch : 4 loss : 1.257366120815277 Acc : 16.666666666666668%\n",
      "33.333333333333336\n",
      "\n",
      "Epoch: 5\n",
      "Train epoch : 5 loss : 1.1437664694256253 Acc : 34.02777777777778%\n",
      "\n",
      "Epoch: 5\n",
      "Test epoch : 5 loss : 1.2431547045707703 Acc : 16.666666666666668%\n",
      "33.333333333333336\n",
      "\n",
      "Epoch: 6\n",
      "Train epoch : 6 loss : 1.1354289054870605 Acc : 35.416666666666664%\n",
      "\n",
      "Epoch: 6\n",
      "Test epoch : 6 loss : 1.9340682625770569 Acc : 16.666666666666668%\n",
      "33.333333333333336\n",
      "\n",
      "Epoch: 7\n",
      "Train epoch : 7 loss : 1.171464165051778 Acc : 32.638888888888886%\n",
      "\n",
      "Epoch: 7\n",
      "Test epoch : 7 loss : 1.0919132828712463 Acc : 16.666666666666668%\n",
      "33.333333333333336\n",
      "\n",
      "Epoch: 8\n",
      "Train epoch : 8 loss : 1.164875904719035 Acc : 27.083333333333332%\n",
      "\n",
      "Epoch: 8\n",
      "Test epoch : 8 loss : 1.1752545833587646 Acc : 44.44444444444444%\n",
      "44.44444444444444\n",
      "\n",
      "Epoch: 9\n",
      "Train epoch : 9 loss : 1.1347559690475464 Acc : 35.416666666666664%\n",
      "\n",
      "Epoch: 9\n",
      "Test epoch : 9 loss : 1.2686561942100525 Acc : 50.0%\n",
      "50.0\n",
      "\n",
      "Epoch: 10\n",
      "Train epoch : 10 loss : 1.2186644474665325 Acc : 32.638888888888886%\n",
      "\n",
      "Epoch: 10\n",
      "Test epoch : 10 loss : 1.022274911403656 Acc : 38.888888888888886%\n",
      "50.0\n",
      "\n",
      "Epoch: 11\n",
      "Train epoch : 11 loss : 1.1554711328612433 Acc : 32.638888888888886%\n",
      "\n",
      "Epoch: 11\n",
      "Test epoch : 11 loss : 1.3609842658042908 Acc : 33.333333333333336%\n",
      "50.0\n",
      "\n",
      "Epoch: 12\n",
      "Train epoch : 12 loss : 1.1675266159905329 Acc : 31.25%\n",
      "\n",
      "Epoch: 12\n",
      "Test epoch : 12 loss : 1.321995496749878 Acc : 50.0%\n",
      "50.0\n",
      "\n",
      "Epoch: 13\n",
      "Train epoch : 13 loss : 1.1835406488842435 Acc : 27.083333333333332%\n",
      "\n",
      "Epoch: 13\n",
      "Test epoch : 13 loss : 1.3988577127456665 Acc : 33.333333333333336%\n",
      "50.0\n",
      "\n",
      "Epoch: 14\n",
      "Train epoch : 14 loss : 1.233077261182997 Acc : 29.166666666666668%\n",
      "\n",
      "Epoch: 14\n",
      "Test epoch : 14 loss : 1.2812647819519043 Acc : 66.66666666666667%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 15\n",
      "Train epoch : 15 loss : 1.1681928369734023 Acc : 32.638888888888886%\n",
      "\n",
      "Epoch: 15\n",
      "Test epoch : 15 loss : 1.100068211555481 Acc : 33.333333333333336%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 16\n",
      "Train epoch : 16 loss : 1.1370214091406927 Acc : 31.944444444444443%\n",
      "\n",
      "Epoch: 16\n",
      "Test epoch : 16 loss : 1.3295276463031769 Acc : 50.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 17\n",
      "Train epoch : 17 loss : 1.1813201771842108 Acc : 33.333333333333336%\n",
      "\n",
      "Epoch: 17\n",
      "Test epoch : 17 loss : 1.208834707736969 Acc : 50.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 18\n",
      "Train epoch : 18 loss : 1.1787940793567233 Acc : 32.638888888888886%\n",
      "\n",
      "Epoch: 18\n",
      "Test epoch : 18 loss : 1.215584933757782 Acc : 50.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 19\n",
      "Train epoch : 19 loss : 1.1485079526901245 Acc : 34.02777777777778%\n",
      "\n",
      "Epoch: 19\n",
      "Test epoch : 19 loss : 1.322502076625824 Acc : 50.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 20\n",
      "Train epoch : 20 loss : 1.1415243479940627 Acc : 28.47222222222222%\n",
      "\n",
      "Epoch: 20\n",
      "Test epoch : 20 loss : 1.0506399869918823 Acc : 50.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 21\n",
      "Train epoch : 21 loss : 1.1429881850878398 Acc : 34.02777777777778%\n",
      "\n",
      "Epoch: 21\n",
      "Test epoch : 21 loss : 1.7077139019966125 Acc : 38.888888888888886%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 22\n",
      "Train epoch : 22 loss : 1.1661361588372126 Acc : 36.111111111111114%\n",
      "\n",
      "Epoch: 22\n",
      "Test epoch : 22 loss : 1.1995866298675537 Acc : 16.666666666666668%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 23\n",
      "Train epoch : 23 loss : 1.1403548452589247 Acc : 31.25%\n",
      "\n",
      "Epoch: 23\n",
      "Test epoch : 23 loss : 1.234784722328186 Acc : 16.666666666666668%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 24\n",
      "Train epoch : 24 loss : 1.1287281513214111 Acc : 37.5%\n",
      "\n",
      "Epoch: 24\n",
      "Test epoch : 24 loss : 0.9839774370193481 Acc : 50.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 25\n",
      "Train epoch : 25 loss : 1.1523851421144273 Acc : 36.111111111111114%\n",
      "\n",
      "Epoch: 25\n",
      "Test epoch : 25 loss : 1.230358064174652 Acc : 44.44444444444444%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 26\n",
      "Train epoch : 26 loss : 1.12639229827457 Acc : 30.555555555555557%\n",
      "\n",
      "Epoch: 26\n",
      "Test epoch : 26 loss : 1.262312114238739 Acc : 33.333333333333336%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 27\n",
      "Train epoch : 27 loss : 1.146512336201138 Acc : 32.638888888888886%\n",
      "\n",
      "Epoch: 27\n",
      "Test epoch : 27 loss : 0.9745166897773743 Acc : 33.333333333333336%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 28\n",
      "Train epoch : 28 loss : 1.1772978835635715 Acc : 29.86111111111111%\n",
      "\n",
      "Epoch: 28\n",
      "Test epoch : 28 loss : 1.011570692062378 Acc : 55.55555555555556%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 29\n",
      "Train epoch : 29 loss : 1.1308370298809476 Acc : 36.111111111111114%\n",
      "\n",
      "Epoch: 29\n",
      "Test epoch : 29 loss : 1.300242006778717 Acc : 33.333333333333336%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 30\n",
      "Train epoch : 30 loss : 1.1626391145918105 Acc : 31.944444444444443%\n",
      "\n",
      "Epoch: 30\n",
      "Test epoch : 30 loss : 1.1191360652446747 Acc : 50.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 31\n",
      "Train epoch : 31 loss : 1.1594414048724704 Acc : 34.72222222222222%\n",
      "\n",
      "Epoch: 31\n",
      "Test epoch : 31 loss : 0.9551863670349121 Acc : 50.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 32\n",
      "Train epoch : 32 loss : 1.1357062922583685 Acc : 34.02777777777778%\n",
      "\n",
      "Epoch: 32\n",
      "Test epoch : 32 loss : 1.329469621181488 Acc : 16.666666666666668%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 33\n",
      "Train epoch : 33 loss : 1.139331082503001 Acc : 31.25%\n",
      "\n",
      "Epoch: 33\n",
      "Test epoch : 33 loss : 1.3133477568626404 Acc : 27.77777777777778%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 34\n",
      "Train epoch : 34 loss : 1.1758146550920274 Acc : 29.86111111111111%\n",
      "\n",
      "Epoch: 34\n",
      "Test epoch : 34 loss : 1.0832144021987915 Acc : 50.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 35\n",
      "Train epoch : 35 loss : 1.1267862584855821 Acc : 32.638888888888886%\n",
      "\n",
      "Epoch: 35\n",
      "Test epoch : 35 loss : 1.1266787648200989 Acc : 16.666666666666668%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 36\n",
      "Train epoch : 36 loss : 1.1290942562950983 Acc : 36.111111111111114%\n",
      "\n",
      "Epoch: 36\n",
      "Test epoch : 36 loss : 1.4995121359825134 Acc : 16.666666666666668%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 37\n",
      "Train epoch : 37 loss : 1.203667336040073 Acc : 27.083333333333332%\n",
      "\n",
      "Epoch: 37\n",
      "Test epoch : 37 loss : 1.4405187368392944 Acc : 16.666666666666668%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 38\n",
      "Train epoch : 38 loss : 1.1005311012268066 Acc : 38.19444444444444%\n",
      "\n",
      "Epoch: 38\n",
      "Test epoch : 38 loss : 1.1232848167419434 Acc : 55.55555555555556%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 39\n",
      "Train epoch : 39 loss : 1.1227978600396051 Acc : 34.72222222222222%\n",
      "\n",
      "Epoch: 39\n",
      "Test epoch : 39 loss : 1.1292211413383484 Acc : 16.666666666666668%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 40\n",
      "Train epoch : 40 loss : 1.1317585839165583 Acc : 34.02777777777778%\n",
      "\n",
      "Epoch: 40\n",
      "Test epoch : 40 loss : 1.001701295375824 Acc : 61.111111111111114%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 41\n",
      "Train epoch : 41 loss : 1.1343222194247775 Acc : 31.25%\n",
      "\n",
      "Epoch: 41\n",
      "Test epoch : 41 loss : 1.278114378452301 Acc : 16.666666666666668%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 42\n",
      "Train epoch : 42 loss : 1.0903098848130968 Acc : 40.97222222222222%\n",
      "\n",
      "Epoch: 42\n",
      "Test epoch : 42 loss : 1.0587372183799744 Acc : 50.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 43\n",
      "Train epoch : 43 loss : 1.1407934029897053 Acc : 36.111111111111114%\n",
      "\n",
      "Epoch: 43\n",
      "Test epoch : 43 loss : 0.8586300611495972 Acc : 50.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 44\n",
      "Train epoch : 44 loss : 1.1089939541286893 Acc : 37.5%\n",
      "\n",
      "Epoch: 44\n",
      "Test epoch : 44 loss : 1.2435894012451172 Acc : 38.888888888888886%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 45\n",
      "Train epoch : 45 loss : 1.1348451375961304 Acc : 31.944444444444443%\n",
      "\n",
      "Epoch: 45\n",
      "Test epoch : 45 loss : 0.9718440771102905 Acc : 55.55555555555556%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 46\n",
      "Train epoch : 46 loss : 1.0954322285122342 Acc : 36.80555555555556%\n",
      "\n",
      "Epoch: 46\n",
      "Test epoch : 46 loss : 1.0123410522937775 Acc : 38.888888888888886%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 47\n",
      "Train epoch : 47 loss : 1.1508574883143108 Acc : 34.02777777777778%\n",
      "\n",
      "Epoch: 47\n",
      "Test epoch : 47 loss : 1.1591578125953674 Acc : 33.333333333333336%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 48\n",
      "Train epoch : 48 loss : 1.0807443658510845 Acc : 47.22222222222222%\n",
      "\n",
      "Epoch: 48\n",
      "Test epoch : 48 loss : 0.9679370522499084 Acc : 55.55555555555556%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 49\n",
      "Train epoch : 49 loss : 1.132118476761712 Acc : 35.416666666666664%\n",
      "\n",
      "Epoch: 49\n",
      "Test epoch : 49 loss : 1.2653566002845764 Acc : 22.22222222222222%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 50\n",
      "Train epoch : 50 loss : 1.1434207889768813 Acc : 39.583333333333336%\n",
      "\n",
      "Epoch: 50\n",
      "Test epoch : 50 loss : 1.308338224887848 Acc : 33.333333333333336%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 51\n",
      "Train epoch : 51 loss : 1.1032527950074937 Acc : 40.27777777777778%\n",
      "\n",
      "Epoch: 51\n",
      "Test epoch : 51 loss : 1.25933375954628 Acc : 50.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 52\n",
      "Train epoch : 52 loss : 1.0612030426661174 Acc : 39.583333333333336%\n",
      "\n",
      "Epoch: 52\n",
      "Test epoch : 52 loss : 1.2583403587341309 Acc : 22.22222222222222%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 53\n",
      "Train epoch : 53 loss : 1.0692031449741788 Acc : 37.5%\n",
      "\n",
      "Epoch: 53\n",
      "Test epoch : 53 loss : 1.3173641860485077 Acc : 55.55555555555556%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 54\n",
      "Train epoch : 54 loss : 1.0507309701707628 Acc : 45.833333333333336%\n",
      "\n",
      "Epoch: 54\n",
      "Test epoch : 54 loss : 3.6692839860916138 Acc : 50.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 55\n",
      "Train epoch : 55 loss : 1.096118734942542 Acc : 42.361111111111114%\n",
      "\n",
      "Epoch: 55\n",
      "Test epoch : 55 loss : 1.3986350297927856 Acc : 11.11111111111111%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 56\n",
      "Train epoch : 56 loss : 1.0421200460857816 Acc : 50.0%\n",
      "\n",
      "Epoch: 56\n",
      "Test epoch : 56 loss : 0.8720135986804962 Acc : 50.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 57\n",
      "Train epoch : 57 loss : 1.0327090223630269 Acc : 43.05555555555556%\n",
      "\n",
      "Epoch: 57\n",
      "Test epoch : 57 loss : 0.9013113975524902 Acc : 50.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 58\n",
      "Train epoch : 58 loss : 1.0551482505268521 Acc : 44.44444444444444%\n",
      "\n",
      "Epoch: 58\n",
      "Test epoch : 58 loss : 0.7699072659015656 Acc : 61.111111111111114%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 59\n",
      "Train epoch : 59 loss : 1.0446166197458904 Acc : 50.0%\n",
      "\n",
      "Epoch: 59\n",
      "Test epoch : 59 loss : 1.2916684970259666 Acc : 50.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 60\n",
      "Train epoch : 60 loss : 1.1012787024180095 Acc : 37.5%\n",
      "\n",
      "Epoch: 60\n",
      "Test epoch : 60 loss : 1.247485339641571 Acc : 16.666666666666668%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 61\n",
      "Train epoch : 61 loss : 1.0364938378334045 Acc : 49.30555555555556%\n",
      "\n",
      "Epoch: 61\n",
      "Test epoch : 61 loss : 1.0409221351146698 Acc : 50.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 62\n",
      "Train epoch : 62 loss : 1.0586670438448589 Acc : 40.27777777777778%\n",
      "\n",
      "Epoch: 62\n",
      "Test epoch : 62 loss : 1.2559219598770142 Acc : 38.888888888888886%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 63\n",
      "Train epoch : 63 loss : 1.048733611901601 Acc : 40.27777777777778%\n",
      "\n",
      "Epoch: 63\n",
      "Test epoch : 63 loss : 1.0489380359649658 Acc : 50.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 64\n",
      "Train epoch : 64 loss : 1.0748451087209914 Acc : 40.97222222222222%\n",
      "\n",
      "Epoch: 64\n",
      "Test epoch : 64 loss : 1.308383733034134 Acc : 50.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 65\n",
      "Train epoch : 65 loss : 1.028562307357788 Acc : 43.75%\n",
      "\n",
      "Epoch: 65\n",
      "Test epoch : 65 loss : 0.9866873323917389 Acc : 50.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 66\n",
      "Train epoch : 66 loss : 1.0177747673458524 Acc : 43.75%\n",
      "\n",
      "Epoch: 66\n",
      "Test epoch : 66 loss : 0.9288269877433777 Acc : 50.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 67\n",
      "Train epoch : 67 loss : 1.0349397990438673 Acc : 42.361111111111114%\n",
      "\n",
      "Epoch: 67\n",
      "Test epoch : 67 loss : 1.0187207460403442 Acc : 55.55555555555556%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 68\n",
      "Train epoch : 68 loss : 1.021222213904063 Acc : 45.833333333333336%\n",
      "\n",
      "Epoch: 68\n",
      "Test epoch : 68 loss : 1.069469928741455 Acc : 55.55555555555556%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 69\n",
      "Train epoch : 69 loss : 1.01006504562166 Acc : 46.52777777777778%\n",
      "\n",
      "Epoch: 69\n",
      "Test epoch : 69 loss : 1.737907350063324 Acc : 16.666666666666668%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 70\n",
      "Train epoch : 70 loss : 1.0034263332684834 Acc : 48.611111111111114%\n",
      "\n",
      "Epoch: 70\n",
      "Test epoch : 70 loss : 1.3001503348350525 Acc : 16.666666666666668%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 71\n",
      "Train epoch : 71 loss : 1.0167650977770488 Acc : 45.138888888888886%\n",
      "\n",
      "Epoch: 71\n",
      "Test epoch : 71 loss : 0.9820683598518372 Acc : 27.77777777777778%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 72\n",
      "Train epoch : 72 loss : 0.9771419366200765 Acc : 51.388888888888886%\n",
      "\n",
      "Epoch: 72\n",
      "Test epoch : 72 loss : 1.4063379764556885 Acc : 16.666666666666668%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 73\n",
      "Train epoch : 73 loss : 0.9308886726697286 Acc : 52.77777777777778%\n",
      "\n",
      "Epoch: 73\n",
      "Test epoch : 73 loss : 1.0688623189926147 Acc : 50.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 74\n",
      "Train epoch : 74 loss : 0.9835229317347208 Acc : 50.0%\n",
      "\n",
      "Epoch: 74\n",
      "Test epoch : 74 loss : 1.894326627254486 Acc : 50.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 75\n",
      "Train epoch : 75 loss : 1.0634300642543368 Acc : 39.583333333333336%\n",
      "\n",
      "Epoch: 75\n",
      "Test epoch : 75 loss : 1.0367216169834137 Acc : 22.22222222222222%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 76\n",
      "Train epoch : 76 loss : 0.9201788571145799 Acc : 60.416666666666664%\n",
      "\n",
      "Epoch: 76\n",
      "Test epoch : 76 loss : 0.9319683611392975 Acc : 55.55555555555556%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 77\n",
      "Train epoch : 77 loss : 1.0061643256081476 Acc : 47.22222222222222%\n",
      "\n",
      "Epoch: 77\n",
      "Test epoch : 77 loss : 1.0029207468032837 Acc : 55.55555555555556%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 78\n",
      "Train epoch : 78 loss : 0.9708647661738925 Acc : 49.30555555555556%\n",
      "\n",
      "Epoch: 78\n",
      "Test epoch : 78 loss : 1.0312577784061432 Acc : 33.333333333333336%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 79\n",
      "Train epoch : 79 loss : 0.9940894709693061 Acc : 45.138888888888886%\n",
      "\n",
      "Epoch: 79\n",
      "Test epoch : 79 loss : 1.672052264213562 Acc : 50.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 80\n",
      "Train epoch : 80 loss : 0.9418657686975267 Acc : 51.388888888888886%\n",
      "\n",
      "Epoch: 80\n",
      "Test epoch : 80 loss : 3.7174244781635934 Acc : 50.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 81\n",
      "Train epoch : 81 loss : 1.084880789120992 Acc : 47.22222222222222%\n",
      "\n",
      "Epoch: 81\n",
      "Test epoch : 81 loss : 1.8778511881828308 Acc : 27.77777777777778%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 82\n",
      "Train epoch : 82 loss : 0.9890063073900011 Acc : 52.083333333333336%\n",
      "\n",
      "Epoch: 82\n",
      "Test epoch : 82 loss : 0.7236879169940948 Acc : 61.111111111111114%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 83\n",
      "Train epoch : 83 loss : 0.8911505076620314 Acc : 59.02777777777778%\n",
      "\n",
      "Epoch: 83\n",
      "Test epoch : 83 loss : 0.7595038115978241 Acc : 50.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 84\n",
      "Train epoch : 84 loss : 0.897026002407074 Acc : 58.333333333333336%\n",
      "\n",
      "Epoch: 84\n",
      "Test epoch : 84 loss : 1.1821732223033905 Acc : 44.44444444444444%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 85\n",
      "Train epoch : 85 loss : 0.9595754146575928 Acc : 49.30555555555556%\n",
      "\n",
      "Epoch: 85\n",
      "Test epoch : 85 loss : 2.0946834087371826 Acc : 16.666666666666668%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 86\n",
      "Train epoch : 86 loss : 0.9485700461599562 Acc : 56.25%\n",
      "\n",
      "Epoch: 86\n",
      "Test epoch : 86 loss : 1.1334513425827026 Acc : 55.55555555555556%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 87\n",
      "Train epoch : 87 loss : 1.0079216824637518 Acc : 46.52777777777778%\n",
      "\n",
      "Epoch: 87\n",
      "Test epoch : 87 loss : 0.5948740542517044 Acc : 55.55555555555556%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 88\n",
      "Train epoch : 88 loss : 0.8698823518223233 Acc : 59.72222222222222%\n",
      "\n",
      "Epoch: 88\n",
      "Test epoch : 88 loss : 0.5406743586063385 Acc : 66.66666666666667%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 89\n",
      "Train epoch : 89 loss : 0.9169743259747823 Acc : 56.94444444444444%\n",
      "\n",
      "Epoch: 89\n",
      "Test epoch : 89 loss : 0.5449836850166321 Acc : 55.55555555555556%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 90\n",
      "Train epoch : 90 loss : 0.9528057045406766 Acc : 54.861111111111114%\n",
      "\n",
      "Epoch: 90\n",
      "Test epoch : 90 loss : 1.456328809261322 Acc : 44.44444444444444%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 91\n",
      "Train epoch : 91 loss : 0.8830266329977248 Acc : 59.72222222222222%\n",
      "\n",
      "Epoch: 91\n",
      "Test epoch : 91 loss : 1.8204339146614075 Acc : 22.22222222222222%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 92\n",
      "Train epoch : 92 loss : 0.9007908569441901 Acc : 54.861111111111114%\n",
      "\n",
      "Epoch: 92\n",
      "Test epoch : 92 loss : 0.4402571842074394 Acc : 66.66666666666667%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 93\n",
      "Train epoch : 93 loss : 0.8445044822163053 Acc : 59.02777777777778%\n",
      "\n",
      "Epoch: 93\n",
      "Test epoch : 93 loss : 1.0610048472881317 Acc : 55.55555555555556%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 94\n",
      "Train epoch : 94 loss : 0.8830734027756585 Acc : 59.72222222222222%\n",
      "\n",
      "Epoch: 94\n",
      "Test epoch : 94 loss : 1.5335715413093567 Acc : 50.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 95\n",
      "Train epoch : 95 loss : 0.8043936292330424 Acc : 60.416666666666664%\n",
      "\n",
      "Epoch: 95\n",
      "Test epoch : 95 loss : 1.2029459774494171 Acc : 55.55555555555556%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 96\n",
      "Train epoch : 96 loss : 0.9045708510610793 Acc : 55.55555555555556%\n",
      "\n",
      "Epoch: 96\n",
      "Test epoch : 96 loss : 0.8200097978115082 Acc : 27.77777777777778%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 97\n",
      "Train epoch : 97 loss : 0.8319337301784091 Acc : 59.02777777777778%\n",
      "\n",
      "Epoch: 97\n",
      "Test epoch : 97 loss : 1.7078887820243835 Acc : 27.77777777777778%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 98\n",
      "Train epoch : 98 loss : 0.9552773038546244 Acc : 53.47222222222222%\n",
      "\n",
      "Epoch: 98\n",
      "Test epoch : 98 loss : 1.663852421566844 Acc : 50.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 99\n",
      "Train epoch : 99 loss : 0.960944758521186 Acc : 54.861111111111114%\n",
      "\n",
      "Epoch: 99\n",
      "Test epoch : 99 loss : 0.46901100128889084 Acc : 66.66666666666667%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 100\n",
      "Train epoch : 100 loss : 0.7811448772748312 Acc : 63.888888888888886%\n",
      "\n",
      "Epoch: 100\n",
      "Test epoch : 100 loss : 0.6407915651798248 Acc : 77.77777777777777%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 101\n",
      "Train epoch : 101 loss : 0.7807248102294074 Acc : 64.58333333333333%\n",
      "\n",
      "Epoch: 101\n",
      "Test epoch : 101 loss : 0.6137043014168739 Acc : 44.44444444444444%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 102\n",
      "Train epoch : 102 loss : 0.9867339067988925 Acc : 55.55555555555556%\n",
      "\n",
      "Epoch: 102\n",
      "Test epoch : 102 loss : 0.5608656406402588 Acc : 61.111111111111114%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 103\n",
      "Train epoch : 103 loss : 0.8192667431301541 Acc : 63.19444444444444%\n",
      "\n",
      "Epoch: 103\n",
      "Test epoch : 103 loss : 0.9015660285949707 Acc : 33.333333333333336%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 104\n",
      "Train epoch : 104 loss : 0.8547196785608927 Acc : 62.5%\n",
      "\n",
      "Epoch: 104\n",
      "Test epoch : 104 loss : 0.5752136409282684 Acc : 66.66666666666667%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 105\n",
      "Train epoch : 105 loss : 0.78411822186576 Acc : 65.97222222222223%\n",
      "\n",
      "Epoch: 105\n",
      "Test epoch : 105 loss : 0.5384229198098183 Acc : 66.66666666666667%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 106\n",
      "Train epoch : 106 loss : 0.8267467419306437 Acc : 63.19444444444444%\n",
      "\n",
      "Epoch: 106\n",
      "Test epoch : 106 loss : 1.0117304921150208 Acc : 50.0%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 107\n",
      "Train epoch : 107 loss : 0.8230885532167223 Acc : 61.111111111111114%\n",
      "\n",
      "Epoch: 107\n",
      "Test epoch : 107 loss : 0.6384724453091621 Acc : 50.0%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 108\n",
      "Train epoch : 108 loss : 0.8063602414396074 Acc : 64.58333333333333%\n",
      "\n",
      "Epoch: 108\n",
      "Test epoch : 108 loss : 4.584512948989868 Acc : 16.666666666666668%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 109\n",
      "Train epoch : 109 loss : 0.7416530085934533 Acc : 63.19444444444444%\n",
      "\n",
      "Epoch: 109\n",
      "Test epoch : 109 loss : 1.717700719833374 Acc : 27.77777777777778%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 110\n",
      "Train epoch : 110 loss : 0.8240289886792501 Acc : 59.72222222222222%\n",
      "\n",
      "Epoch: 110\n",
      "Test epoch : 110 loss : 0.49711447209119797 Acc : 55.55555555555556%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 111\n",
      "Train epoch : 111 loss : 0.8227401640680101 Acc : 62.5%\n",
      "\n",
      "Epoch: 111\n",
      "Test epoch : 111 loss : 1.0673823952674866 Acc : 61.111111111111114%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 112\n",
      "Train epoch : 112 loss : 0.777762750784556 Acc : 63.888888888888886%\n",
      "\n",
      "Epoch: 112\n",
      "Test epoch : 112 loss : 0.7236468985211104 Acc : 50.0%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 113\n",
      "Train epoch : 113 loss : 0.7723773982789781 Acc : 61.80555555555556%\n",
      "\n",
      "Epoch: 113\n",
      "Test epoch : 113 loss : 0.43636150658130646 Acc : 61.111111111111114%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 114\n",
      "Train epoch : 114 loss : 0.8413622246848212 Acc : 54.861111111111114%\n",
      "\n",
      "Epoch: 114\n",
      "Test epoch : 114 loss : 1.057969182729721 Acc : 55.55555555555556%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 115\n",
      "Train epoch : 115 loss : 0.8587236139509413 Acc : 59.02777777777778%\n",
      "\n",
      "Epoch: 115\n",
      "Test epoch : 115 loss : 1.0590865015983582 Acc : 38.888888888888886%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 116\n",
      "Train epoch : 116 loss : 0.9414475825097826 Acc : 56.25%\n",
      "\n",
      "Epoch: 116\n",
      "Test epoch : 116 loss : 3.3307833671569824 Acc : 16.666666666666668%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 117\n",
      "Train epoch : 117 loss : 0.9335340526368883 Acc : 56.94444444444444%\n",
      "\n",
      "Epoch: 117\n",
      "Test epoch : 117 loss : 1.3995012640953064 Acc : 33.333333333333336%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 118\n",
      "Train epoch : 118 loss : 0.8068428304460313 Acc : 63.888888888888886%\n",
      "\n",
      "Epoch: 118\n",
      "Test epoch : 118 loss : 0.49639859050512314 Acc : 66.66666666666667%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 119\n",
      "Train epoch : 119 loss : 0.7860068678855896 Acc : 59.72222222222222%\n",
      "\n",
      "Epoch: 119\n",
      "Test epoch : 119 loss : 0.725679337978363 Acc : 55.55555555555556%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 120\n",
      "Train epoch : 120 loss : 0.780798057715098 Acc : 63.19444444444444%\n",
      "\n",
      "Epoch: 120\n",
      "Test epoch : 120 loss : 0.44645966589450836 Acc : 66.66666666666667%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 121\n",
      "Train epoch : 121 loss : 0.7863839202457004 Acc : 65.97222222222223%\n",
      "\n",
      "Epoch: 121\n",
      "Test epoch : 121 loss : 3.480194330215454 Acc : 16.666666666666668%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 122\n",
      "Train epoch : 122 loss : 0.7545121510823568 Acc : 62.5%\n",
      "\n",
      "Epoch: 122\n",
      "Test epoch : 122 loss : 1.16555255651474 Acc : 61.111111111111114%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 123\n",
      "Train epoch : 123 loss : 0.8647307621108161 Acc : 65.97222222222223%\n",
      "\n",
      "Epoch: 123\n",
      "Test epoch : 123 loss : 2.8884129524230957 Acc : 50.0%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 124\n",
      "Train epoch : 124 loss : 0.7537703116734823 Acc : 65.27777777777777%\n",
      "\n",
      "Epoch: 124\n",
      "Test epoch : 124 loss : 1.5306100845336914 Acc : 50.0%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 125\n",
      "Train epoch : 125 loss : 0.8298000031047397 Acc : 59.02777777777778%\n",
      "\n",
      "Epoch: 125\n",
      "Test epoch : 125 loss : 0.7145888209342957 Acc : 77.77777777777777%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 126\n",
      "Train epoch : 126 loss : 0.795361664560106 Acc : 61.80555555555556%\n",
      "\n",
      "Epoch: 126\n",
      "Test epoch : 126 loss : 0.47361332178115845 Acc : 77.77777777777777%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 127\n",
      "Train epoch : 127 loss : 0.8112877011299133 Acc : 63.888888888888886%\n",
      "\n",
      "Epoch: 127\n",
      "Test epoch : 127 loss : 1.1334976851940155 Acc : 55.55555555555556%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 128\n",
      "Train epoch : 128 loss : 0.8539164861043295 Acc : 53.47222222222222%\n",
      "\n",
      "Epoch: 128\n",
      "Test epoch : 128 loss : 0.46908649802207947 Acc : 83.33333333333333%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 129\n",
      "Train epoch : 129 loss : 0.8209667404492696 Acc : 61.111111111111114%\n",
      "\n",
      "Epoch: 129\n",
      "Test epoch : 129 loss : 0.8875147104263306 Acc : 50.0%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 130\n",
      "Train epoch : 130 loss : 0.7117889589733548 Acc : 64.58333333333333%\n",
      "\n",
      "Epoch: 130\n",
      "Test epoch : 130 loss : 0.8155185878276825 Acc : 72.22222222222223%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 131\n",
      "Train epoch : 131 loss : 0.7714174720976088 Acc : 63.888888888888886%\n",
      "\n",
      "Epoch: 131\n",
      "Test epoch : 131 loss : 1.7003930807113647 Acc : 38.888888888888886%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 132\n",
      "Train epoch : 132 loss : 0.798626164595286 Acc : 61.111111111111114%\n",
      "\n",
      "Epoch: 132\n",
      "Test epoch : 132 loss : 0.4911852478981018 Acc : 66.66666666666667%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 133\n",
      "Train epoch : 133 loss : 0.7180483672353957 Acc : 68.05555555555556%\n",
      "\n",
      "Epoch: 133\n",
      "Test epoch : 133 loss : 0.6157535314559937 Acc : 66.66666666666667%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 134\n",
      "Train epoch : 134 loss : 0.8330062826474508 Acc : 60.416666666666664%\n",
      "\n",
      "Epoch: 134\n",
      "Test epoch : 134 loss : 0.8245886862277985 Acc : 61.111111111111114%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 135\n",
      "Train epoch : 135 loss : 0.7242726749844022 Acc : 73.61111111111111%\n",
      "\n",
      "Epoch: 135\n",
      "Test epoch : 135 loss : 0.5925357639789581 Acc : 66.66666666666667%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 136\n",
      "Train epoch : 136 loss : 0.6693343586391873 Acc : 70.83333333333333%\n",
      "\n",
      "Epoch: 136\n",
      "Test epoch : 136 loss : 2.6381417512893677 Acc : 22.22222222222222%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 137\n",
      "Train epoch : 137 loss : 0.722180618180169 Acc : 60.416666666666664%\n",
      "\n",
      "Epoch: 137\n",
      "Test epoch : 137 loss : 0.6526436358690262 Acc : 77.77777777777777%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 138\n",
      "Train epoch : 138 loss : 0.6626774171988169 Acc : 75.0%\n",
      "\n",
      "Epoch: 138\n",
      "Test epoch : 138 loss : 0.47733616828918457 Acc : 72.22222222222223%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 139\n",
      "Train epoch : 139 loss : 0.5906064543459151 Acc : 75.0%\n",
      "\n",
      "Epoch: 139\n",
      "Test epoch : 139 loss : 0.44460628926754 Acc : 72.22222222222223%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 140\n",
      "Train epoch : 140 loss : 0.7173984514342414 Acc : 65.27777777777777%\n",
      "\n",
      "Epoch: 140\n",
      "Test epoch : 140 loss : 1.0532967150211334 Acc : 66.66666666666667%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 141\n",
      "Train epoch : 141 loss : 0.87771166033215 Acc : 57.638888888888886%\n",
      "\n",
      "Epoch: 141\n",
      "Test epoch : 141 loss : 0.5800240933895111 Acc : 55.55555555555556%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 142\n",
      "Train epoch : 142 loss : 0.9022088448206583 Acc : 56.94444444444444%\n",
      "\n",
      "Epoch: 142\n",
      "Test epoch : 142 loss : 0.5210066437721252 Acc : 83.33333333333333%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 143\n",
      "Train epoch : 143 loss : 0.6565140419536166 Acc : 68.05555555555556%\n",
      "\n",
      "Epoch: 143\n",
      "Test epoch : 143 loss : 0.5922276079654694 Acc : 72.22222222222223%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 144\n",
      "Train epoch : 144 loss : 0.6215667592154609 Acc : 72.22222222222223%\n",
      "\n",
      "Epoch: 144\n",
      "Test epoch : 144 loss : 0.981166273355484 Acc : 44.44444444444444%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 145\n",
      "Train epoch : 145 loss : 0.7386805680063036 Acc : 68.05555555555556%\n",
      "\n",
      "Epoch: 145\n",
      "Test epoch : 145 loss : 0.9247332960367203 Acc : 55.55555555555556%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 146\n",
      "Train epoch : 146 loss : 0.7391802668571472 Acc : 68.05555555555556%\n",
      "\n",
      "Epoch: 146\n",
      "Test epoch : 146 loss : 0.6162095963954926 Acc : 66.66666666666667%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 147\n",
      "Train epoch : 147 loss : 0.6938676039377848 Acc : 64.58333333333333%\n",
      "\n",
      "Epoch: 147\n",
      "Test epoch : 147 loss : 1.3845535516738892 Acc : 33.333333333333336%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 148\n",
      "Train epoch : 148 loss : 0.6720984644360013 Acc : 70.83333333333333%\n",
      "\n",
      "Epoch: 148\n",
      "Test epoch : 148 loss : 0.8233147263526917 Acc : 44.44444444444444%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 149\n",
      "Train epoch : 149 loss : 0.6610302726427714 Acc : 73.61111111111111%\n",
      "\n",
      "Epoch: 149\n",
      "Test epoch : 149 loss : 0.9980272054672241 Acc : 66.66666666666667%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 150\n",
      "Train epoch : 150 loss : 0.6556835571924845 Acc : 69.44444444444444%\n",
      "\n",
      "Epoch: 150\n",
      "Test epoch : 150 loss : 1.2431848347187042 Acc : 66.66666666666667%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 151\n",
      "Train epoch : 151 loss : 0.7245496312777201 Acc : 63.888888888888886%\n",
      "\n",
      "Epoch: 151\n",
      "Test epoch : 151 loss : 0.6182769387960434 Acc : 66.66666666666667%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 152\n",
      "Train epoch : 152 loss : 0.6624276207553016 Acc : 65.97222222222223%\n",
      "\n",
      "Epoch: 152\n",
      "Test epoch : 152 loss : 0.9416724145412445 Acc : 50.0%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 153\n",
      "Train epoch : 153 loss : 0.8024185631010268 Acc : 71.52777777777777%\n",
      "\n",
      "Epoch: 153\n",
      "Test epoch : 153 loss : 2.4786256551742554 Acc : 16.666666666666668%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 154\n",
      "Train epoch : 154 loss : 0.7613972425460815 Acc : 66.66666666666667%\n",
      "\n",
      "Epoch: 154\n",
      "Test epoch : 154 loss : 1.226794272661209 Acc : 50.0%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 155\n",
      "Train epoch : 155 loss : 0.6595206293794844 Acc : 70.13888888888889%\n",
      "\n",
      "Epoch: 155\n",
      "Test epoch : 155 loss : 0.6774330958724022 Acc : 50.0%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 156\n",
      "Train epoch : 156 loss : 0.6165350013309054 Acc : 71.52777777777777%\n",
      "\n",
      "Epoch: 156\n",
      "Test epoch : 156 loss : 1.071277916431427 Acc : 50.0%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 157\n",
      "Train epoch : 157 loss : 0.6355044543743134 Acc : 68.75%\n",
      "\n",
      "Epoch: 157\n",
      "Test epoch : 157 loss : 0.49615099281072617 Acc : 72.22222222222223%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 158\n",
      "Train epoch : 158 loss : 0.6493263410197364 Acc : 69.44444444444444%\n",
      "\n",
      "Epoch: 158\n",
      "Test epoch : 158 loss : 0.6797913908958435 Acc : 61.111111111111114%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 159\n",
      "Train epoch : 159 loss : 0.7406168977419535 Acc : 68.05555555555556%\n",
      "\n",
      "Epoch: 159\n",
      "Test epoch : 159 loss : 0.4919128194451332 Acc : 66.66666666666667%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 160\n",
      "Train epoch : 160 loss : 0.7004891236623129 Acc : 70.83333333333333%\n",
      "\n",
      "Epoch: 160\n",
      "Test epoch : 160 loss : 0.9265571236610413 Acc : 66.66666666666667%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 161\n",
      "Train epoch : 161 loss : 0.6338348554240333 Acc : 73.61111111111111%\n",
      "\n",
      "Epoch: 161\n",
      "Test epoch : 161 loss : 1.9317076802253723 Acc : 44.44444444444444%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 162\n",
      "Train epoch : 162 loss : 0.812862926059299 Acc : 68.05555555555556%\n",
      "\n",
      "Epoch: 162\n",
      "Test epoch : 162 loss : 1.6008454378461465 Acc : 50.0%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 163\n",
      "Train epoch : 163 loss : 0.7831482026312087 Acc : 64.58333333333333%\n",
      "\n",
      "Epoch: 163\n",
      "Test epoch : 163 loss : 2.0020536184310913 Acc : 44.44444444444444%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 164\n",
      "Train epoch : 164 loss : 0.6611372331778208 Acc : 70.83333333333333%\n",
      "\n",
      "Epoch: 164\n",
      "Test epoch : 164 loss : 0.47512488067150116 Acc : 72.22222222222223%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 165\n",
      "Train epoch : 165 loss : 0.7405405011441972 Acc : 65.27777777777777%\n",
      "\n",
      "Epoch: 165\n",
      "Test epoch : 165 loss : 0.7457267045974731 Acc : 55.55555555555556%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 166\n",
      "Train epoch : 166 loss : 0.6545285781224569 Acc : 75.0%\n",
      "\n",
      "Epoch: 166\n",
      "Test epoch : 166 loss : 2.2902316451072693 Acc : 27.77777777777778%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 167\n",
      "Train epoch : 167 loss : 0.5969739357630411 Acc : 76.38888888888889%\n",
      "\n",
      "Epoch: 167\n",
      "Test epoch : 167 loss : 1.1048552691936493 Acc : 55.55555555555556%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 168\n",
      "Train epoch : 168 loss : 0.6647687918610043 Acc : 72.91666666666667%\n",
      "\n",
      "Epoch: 168\n",
      "Test epoch : 168 loss : 0.6940961182117462 Acc : 50.0%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 169\n",
      "Train epoch : 169 loss : 0.6216767860783471 Acc : 74.30555555555556%\n",
      "\n",
      "Epoch: 169\n",
      "Test epoch : 169 loss : 0.8459360599517822 Acc : 50.0%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 170\n",
      "Train epoch : 170 loss : 0.5839148627387153 Acc : 77.08333333333333%\n",
      "\n",
      "Epoch: 170\n",
      "Test epoch : 170 loss : 0.5296311378479004 Acc : 61.111111111111114%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 171\n",
      "Train epoch : 171 loss : 0.6316973368326823 Acc : 70.13888888888889%\n",
      "\n",
      "Epoch: 171\n",
      "Test epoch : 171 loss : 1.4650558233261108 Acc : 38.888888888888886%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 172\n",
      "Train epoch : 172 loss : 0.6463831663131714 Acc : 72.91666666666667%\n",
      "\n",
      "Epoch: 172\n",
      "Test epoch : 172 loss : 0.9096148312091827 Acc : 66.66666666666667%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 173\n",
      "Train epoch : 173 loss : 0.6850831641091241 Acc : 66.66666666666667%\n",
      "\n",
      "Epoch: 173\n",
      "Test epoch : 173 loss : 0.4937295988202095 Acc : 55.55555555555556%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 174\n",
      "Train epoch : 174 loss : 0.596382843123542 Acc : 75.69444444444444%\n",
      "\n",
      "Epoch: 174\n",
      "Test epoch : 174 loss : 1.4249335527420044 Acc : 38.888888888888886%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 175\n",
      "Train epoch : 175 loss : 0.6625328097078536 Acc : 72.22222222222223%\n",
      "\n",
      "Epoch: 175\n",
      "Test epoch : 175 loss : 1.697066307067871 Acc : 27.77777777777778%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 176\n",
      "Train epoch : 176 loss : 0.7432797882292006 Acc : 67.36111111111111%\n",
      "\n",
      "Epoch: 176\n",
      "Test epoch : 176 loss : 0.4338276833295822 Acc : 61.111111111111114%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 177\n",
      "Train epoch : 177 loss : 0.5917568239900801 Acc : 72.22222222222223%\n",
      "\n",
      "Epoch: 177\n",
      "Test epoch : 177 loss : 1.8734744787216187 Acc : 44.44444444444444%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 178\n",
      "Train epoch : 178 loss : 0.6206157803535461 Acc : 74.30555555555556%\n",
      "\n",
      "Epoch: 178\n",
      "Test epoch : 178 loss : 0.65212382376194 Acc : 55.55555555555556%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 179\n",
      "Train epoch : 179 loss : 0.5910296671920352 Acc : 72.22222222222223%\n",
      "\n",
      "Epoch: 179\n",
      "Test epoch : 179 loss : 0.9806932210922241 Acc : 55.55555555555556%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 180\n",
      "Train epoch : 180 loss : 0.5691809952259064 Acc : 75.0%\n",
      "\n",
      "Epoch: 180\n",
      "Test epoch : 180 loss : 0.6971029043197632 Acc : 66.66666666666667%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 181\n",
      "Train epoch : 181 loss : 0.6288463837570615 Acc : 72.91666666666667%\n",
      "\n",
      "Epoch: 181\n",
      "Test epoch : 181 loss : 0.9838986992835999 Acc : 38.888888888888886%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 182\n",
      "Train epoch : 182 loss : 0.654887232515547 Acc : 72.91666666666667%\n",
      "\n",
      "Epoch: 182\n",
      "Test epoch : 182 loss : 1.2824974656105042 Acc : 38.888888888888886%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 183\n",
      "Train epoch : 183 loss : 0.6124646398756239 Acc : 70.83333333333333%\n",
      "\n",
      "Epoch: 183\n",
      "Test epoch : 183 loss : 0.34801407903432846 Acc : 66.66666666666667%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 184\n",
      "Train epoch : 184 loss : 0.6144473221566942 Acc : 72.22222222222223%\n",
      "\n",
      "Epoch: 184\n",
      "Test epoch : 184 loss : 1.118624639697373 Acc : 33.333333333333336%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 185\n",
      "Train epoch : 185 loss : 0.6441609197192721 Acc : 68.75%\n",
      "\n",
      "Epoch: 185\n",
      "Test epoch : 185 loss : 2.9176278114318848 Acc : 27.77777777777778%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 186\n",
      "Train epoch : 186 loss : 0.6076255076461368 Acc : 78.47222222222223%\n",
      "\n",
      "Epoch: 186\n",
      "Test epoch : 186 loss : 0.4881003797054291 Acc : 72.22222222222223%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 187\n",
      "Train epoch : 187 loss : 0.6307753026485443 Acc : 71.52777777777777%\n",
      "\n",
      "Epoch: 187\n",
      "Test epoch : 187 loss : 2.1607375741004944 Acc : 27.77777777777778%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 188\n",
      "Train epoch : 188 loss : 1.0413888560401068 Acc : 58.333333333333336%\n",
      "\n",
      "Epoch: 188\n",
      "Test epoch : 188 loss : 0.5735867395997047 Acc : 66.66666666666667%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 189\n",
      "Train epoch : 189 loss : 0.6635225978162553 Acc : 67.36111111111111%\n",
      "\n",
      "Epoch: 189\n",
      "Test epoch : 189 loss : 0.6868915855884552 Acc : 50.0%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 190\n",
      "Train epoch : 190 loss : 0.6674293047851987 Acc : 71.52777777777777%\n",
      "\n",
      "Epoch: 190\n",
      "Test epoch : 190 loss : 1.562679648399353 Acc : 50.0%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 191\n",
      "Train epoch : 191 loss : 0.7025447686513265 Acc : 68.05555555555556%\n",
      "\n",
      "Epoch: 191\n",
      "Test epoch : 191 loss : 1.5448407530784607 Acc : 55.55555555555556%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 192\n",
      "Train epoch : 192 loss : 0.7258184419737922 Acc : 65.27777777777777%\n",
      "\n",
      "Epoch: 192\n",
      "Test epoch : 192 loss : 0.7331176251173019 Acc : 66.66666666666667%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 193\n",
      "Train epoch : 193 loss : 0.7673003772894541 Acc : 62.5%\n",
      "\n",
      "Epoch: 193\n",
      "Test epoch : 193 loss : 1.8523588180541992 Acc : 50.0%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 194\n",
      "Train epoch : 194 loss : 0.5986282096968757 Acc : 70.13888888888889%\n",
      "\n",
      "Epoch: 194\n",
      "Test epoch : 194 loss : 0.6329730153083801 Acc : 61.111111111111114%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 195\n",
      "Train epoch : 195 loss : 0.7158117294311523 Acc : 70.83333333333333%\n",
      "\n",
      "Epoch: 195\n",
      "Test epoch : 195 loss : 1.0167335867881775 Acc : 66.66666666666667%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 196\n",
      "Train epoch : 196 loss : 0.5798125333256192 Acc : 74.30555555555556%\n",
      "\n",
      "Epoch: 196\n",
      "Test epoch : 196 loss : 1.2927205562591553 Acc : 33.333333333333336%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 197\n",
      "Train epoch : 197 loss : 0.5991962949434916 Acc : 72.22222222222223%\n",
      "\n",
      "Epoch: 197\n",
      "Test epoch : 197 loss : 1.2356551885604858 Acc : 44.44444444444444%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 198\n",
      "Train epoch : 198 loss : 0.5825723740789626 Acc : 75.0%\n",
      "\n",
      "Epoch: 198\n",
      "Test epoch : 198 loss : 0.3922410160303116 Acc : 77.77777777777777%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 199\n",
      "Train epoch : 199 loss : 0.61896879474322 Acc : 70.13888888888889%\n",
      "\n",
      "Epoch: 199\n",
      "Test epoch : 199 loss : 0.555187851190567 Acc : 61.111111111111114%\n",
      "83.33333333333333\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 및 평가\n",
    "BEST_SCORE = 0\n",
    "for epoch in range(epochs):\n",
    "    train(epoch)\n",
    "    test(epoch, valloader)\n",
    "    print(BEST_SCORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: -1\n",
      "Test epoch : -1 loss : 0.7279956638813019 Acc : 61.111111111111114%\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋에서 평가\n",
    "model.load_state_dict(torch.load(os.path.join(save_path, f'teacher.pth')))\n",
    "test(-1, testloader, 'test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fskd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

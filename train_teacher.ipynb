{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colab에서 드라이브 내 폴더 사용 위해 마운트\n",
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폴더까지의 경로\n",
    "# cd '/content/drive/MyDrive/GSA_Creative_Resarch/rock_sci_paper'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폴더 이동 확인\n",
    "# ! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\fskd\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#필요한 라이브러리들 import\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import dataset\n",
    "import model\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각종 path및 하이퍼 파라미터 설정\n",
    "data_path = 'C:\\\\Users\\\\USER\\\\Desktop\\\\GSH_CRP\\\\codes\\\\rock_sci_paper\\\\data\\\\ro_sci_pa_heo'\n",
    "save_path = 'C:\\\\Users\\\\USER\\\\Desktop\\\\GSH_CRP\\\\codes\\\\rock_sci_paper\\\\model_para'\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "learning_rate = 0.01\n",
    "seed = 2023\n",
    "mode = 'lr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 설정\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# device 설정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform 설정\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # transforms.RandomAffine((-45, 45), translate=(0.2,0.2)),\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ColorJitter(brightness=0.3),\n",
    "    transforms.ColorJitter(contrast=0.3),\n",
    "    transforms.ColorJitter(saturation=0.3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]\n",
    ")\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n",
      "30\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "# dataset 설정\n",
    "train_dataset = dataset.RockScissorsPaper(\n",
    "    transform=train_transform,\n",
    "    path = data_path,\n",
    "    mode = 'train'\n",
    ")\n",
    "val_dataset = dataset.RockScissorsPaper(\n",
    "    transform=test_transform,\n",
    "    path = data_path,\n",
    "    mode = 'val'\n",
    ")\n",
    "test_dataset = dataset.RockScissorsPaper(\n",
    "    transform=test_transform,\n",
    "    path = data_path,\n",
    "    mode = 'test'\n",
    ")\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader 설정\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델, 손실함수, 옵티마이저 설정\n",
    "model = model.ResNet10(num_classes=3)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    print('\\nEpoch: %d'%epoch)\n",
    "    # model train mode로 전환\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    total = 0\n",
    "    for (inputs, labels) in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if mode=='lr':\n",
    "            h,w = inputs.shape[-2], inputs.shape[-1]\n",
    "            lr_inputs = F.interpolate(inputs, (h//8, w//8), mode='bilinear')\n",
    "            lr_inputs = F.interpolate(lr_inputs, (h,w), mode='bilinear')\n",
    "            outputs, _, _, _, _ = model(lr_inputs)\n",
    "        else:\n",
    "            outputs, _, _, _, _ = model(inputs)\n",
    "            \n",
    "        _, pred = torch.max(outputs, 1)\n",
    "        total += outputs.size(0)\n",
    "        running_acc += (pred == labels).sum().item()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    total_loss = running_loss / len(trainloader)\n",
    "    total_acc = 100 * running_acc / total\n",
    "    print(f'Train epoch : {epoch} loss : {total_loss} Acc : {total_acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, loader, test_mode='val', mode2=False):\n",
    "    print('\\nEpoch: %d'%epoch)\n",
    "    # model eval mode로 전환\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    total = 0\n",
    "    label_dict = {0:0, 1:0, 2:0}\n",
    "    correct_dict = {0:0, 1:0, 2:0}\n",
    "    global BEST_SCORE\n",
    "    with torch.no_grad():\n",
    "        for (inputs, labels) in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            if mode=='lr':\n",
    "                h,w = inputs.shape[-2], inputs.shape[-1]\n",
    "                lr_inputs = F.interpolate(inputs, (h//8, w//8), mode='bilinear')\n",
    "                lr_inputs = F.interpolate(lr_inputs, (h,w), mode='bilinear')\n",
    "                outputs, _, _, _, _ = model(lr_inputs)\n",
    "            else:\n",
    "                outputs, _, _, _, _ = model(inputs)\n",
    "\n",
    "            _, pred = torch.max(outputs, 1)\n",
    "            \n",
    "            total += outputs.size(0)\n",
    "            running_acc += (pred == labels).sum().item()\n",
    "            \n",
    "            if mode2:\n",
    "                for i in range(len(labels)):\n",
    "                    label = labels[i]\n",
    "                    label_dict[label.item()] += 1\n",
    "                    if (pred==labels)[i]:\n",
    "                        correct_dict[label.item()] += 1\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "        total_loss = running_loss / len(loader)\n",
    "        total_acc = 100 * running_acc / total\n",
    "        if mode2:\n",
    "            print(label_dict)\n",
    "            print(correct_dict)\n",
    "        if total_acc >= BEST_SCORE and not test_mode=='test':\n",
    "            if not mode=='lr':\n",
    "                path = os.path.join(save_path, f'teacher.pth')\n",
    "                torch.save(model.state_dict(), path)\n",
    "            BEST_SCORE = total_acc\n",
    "        print(f'Test epoch : {epoch} loss : {total_loss} Acc : {total_acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\fskd\\lib\\site-packages\\torch\\nn\\functional.py:3455: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch : 0 loss : 1.1408794482549032 Acc : 34.583333333333336%\n",
      "\n",
      "Epoch: 0\n",
      "Test epoch : 0 loss : 1.0973454713821411 Acc : 26.666666666666668%\n",
      "26.666666666666668\n",
      "\n",
      "Epoch: 1\n",
      "Train epoch : 1 loss : 1.1563758293787638 Acc : 31.25%\n",
      "\n",
      "Epoch: 1\n",
      "Test epoch : 1 loss : 1.0780337452888489 Acc : 43.333333333333336%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 2\n",
      "Train epoch : 2 loss : 1.1323805014292398 Acc : 29.583333333333332%\n",
      "\n",
      "Epoch: 2\n",
      "Test epoch : 2 loss : 1.0758558511734009 Acc : 43.333333333333336%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 3\n",
      "Train epoch : 3 loss : 1.1371555248896281 Acc : 29.166666666666668%\n",
      "\n",
      "Epoch: 3\n",
      "Test epoch : 3 loss : 1.0977599024772644 Acc : 43.333333333333336%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 4\n",
      "Train epoch : 4 loss : 1.1178844213485717 Acc : 36.25%\n",
      "\n",
      "Epoch: 4\n",
      "Test epoch : 4 loss : 1.0889223217964172 Acc : 43.333333333333336%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 5\n",
      "Train epoch : 5 loss : 1.1111196915308634 Acc : 34.583333333333336%\n",
      "\n",
      "Epoch: 5\n",
      "Test epoch : 5 loss : 1.0736825466156006 Acc : 43.333333333333336%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 6\n",
      "Train epoch : 6 loss : 1.1317349672317505 Acc : 33.75%\n",
      "\n",
      "Epoch: 6\n",
      "Test epoch : 6 loss : 1.2617108225822449 Acc : 30.0%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 7\n",
      "Train epoch : 7 loss : 1.1233497540156046 Acc : 36.666666666666664%\n",
      "\n",
      "Epoch: 7\n",
      "Test epoch : 7 loss : 1.079114556312561 Acc : 50.0%\n",
      "50.0\n",
      "\n",
      "Epoch: 8\n",
      "Train epoch : 8 loss : 1.0872078736623128 Acc : 40.416666666666664%\n",
      "\n",
      "Epoch: 8\n",
      "Test epoch : 8 loss : 1.0651010274887085 Acc : 50.0%\n",
      "50.0\n",
      "\n",
      "Epoch: 9\n",
      "Train epoch : 9 loss : 1.1164231856664022 Acc : 36.25%\n",
      "\n",
      "Epoch: 9\n",
      "Test epoch : 9 loss : 1.1121514439582825 Acc : 33.333333333333336%\n",
      "50.0\n",
      "\n",
      "Epoch: 10\n",
      "Train epoch : 10 loss : 1.1085150559743246 Acc : 35.416666666666664%\n",
      "\n",
      "Epoch: 10\n",
      "Test epoch : 10 loss : 1.1472468376159668 Acc : 26.666666666666668%\n",
      "50.0\n",
      "\n",
      "Epoch: 11\n",
      "Train epoch : 11 loss : 1.0803272326787312 Acc : 40.0%\n",
      "\n",
      "Epoch: 11\n",
      "Test epoch : 11 loss : 0.9913370609283447 Acc : 43.333333333333336%\n",
      "50.0\n",
      "\n",
      "Epoch: 12\n",
      "Train epoch : 12 loss : 1.0913759787877402 Acc : 42.083333333333336%\n",
      "\n",
      "Epoch: 12\n",
      "Test epoch : 12 loss : 1.0634324550628662 Acc : 33.333333333333336%\n",
      "50.0\n",
      "\n",
      "Epoch: 13\n",
      "Train epoch : 13 loss : 1.0964930613835653 Acc : 37.916666666666664%\n",
      "\n",
      "Epoch: 13\n",
      "Test epoch : 13 loss : 1.0428313612937927 Acc : 40.0%\n",
      "50.0\n",
      "\n",
      "Epoch: 14\n",
      "Train epoch : 14 loss : 1.081497025489807 Acc : 42.5%\n",
      "\n",
      "Epoch: 14\n",
      "Test epoch : 14 loss : 1.105696976184845 Acc : 43.333333333333336%\n",
      "50.0\n",
      "\n",
      "Epoch: 15\n",
      "Train epoch : 15 loss : 1.0725948214530945 Acc : 42.5%\n",
      "\n",
      "Epoch: 15\n",
      "Test epoch : 15 loss : 1.1076400876045227 Acc : 43.333333333333336%\n",
      "50.0\n",
      "\n",
      "Epoch: 16\n",
      "Train epoch : 16 loss : 1.0843526403109232 Acc : 35.833333333333336%\n",
      "\n",
      "Epoch: 16\n",
      "Test epoch : 16 loss : 1.1264314651489258 Acc : 26.666666666666668%\n",
      "50.0\n",
      "\n",
      "Epoch: 17\n",
      "Train epoch : 17 loss : 1.077493703365326 Acc : 38.75%\n",
      "\n",
      "Epoch: 17\n",
      "Test epoch : 17 loss : 1.0449774265289307 Acc : 40.0%\n",
      "50.0\n",
      "\n",
      "Epoch: 18\n",
      "Train epoch : 18 loss : 1.0457420587539672 Acc : 42.5%\n",
      "\n",
      "Epoch: 18\n",
      "Test epoch : 18 loss : 1.0292891263961792 Acc : 40.0%\n",
      "50.0\n",
      "\n",
      "Epoch: 19\n",
      "Train epoch : 19 loss : 1.0465744654337565 Acc : 43.333333333333336%\n",
      "\n",
      "Epoch: 19\n",
      "Test epoch : 19 loss : 0.935111790895462 Acc : 56.666666666666664%\n",
      "56.666666666666664\n",
      "\n",
      "Epoch: 20\n",
      "Train epoch : 20 loss : 1.0342772960662843 Acc : 45.833333333333336%\n",
      "\n",
      "Epoch: 20\n",
      "Test epoch : 20 loss : 0.9337028563022614 Acc : 53.333333333333336%\n",
      "56.666666666666664\n",
      "\n",
      "Epoch: 21\n",
      "Train epoch : 21 loss : 1.0471641103426614 Acc : 42.5%\n",
      "\n",
      "Epoch: 21\n",
      "Test epoch : 21 loss : 1.0021199584007263 Acc : 36.666666666666664%\n",
      "56.666666666666664\n",
      "\n",
      "Epoch: 22\n",
      "Train epoch : 22 loss : 1.0004818042119343 Acc : 51.25%\n",
      "\n",
      "Epoch: 22\n",
      "Test epoch : 22 loss : 0.8383281528949738 Acc : 70.0%\n",
      "70.0\n",
      "\n",
      "Epoch: 23\n",
      "Train epoch : 23 loss : 0.9997752785682679 Acc : 51.25%\n",
      "\n",
      "Epoch: 23\n",
      "Test epoch : 23 loss : 1.0729041695594788 Acc : 40.0%\n",
      "70.0\n",
      "\n",
      "Epoch: 24\n",
      "Train epoch : 24 loss : 1.0097163955370585 Acc : 47.5%\n",
      "\n",
      "Epoch: 24\n",
      "Test epoch : 24 loss : 0.8347475528717041 Acc : 66.66666666666667%\n",
      "70.0\n",
      "\n",
      "Epoch: 25\n",
      "Train epoch : 25 loss : 1.05363130569458 Acc : 45.833333333333336%\n",
      "\n",
      "Epoch: 25\n",
      "Test epoch : 25 loss : 0.8975518345832825 Acc : 63.333333333333336%\n",
      "70.0\n",
      "\n",
      "Epoch: 26\n",
      "Train epoch : 26 loss : 0.9992278496424357 Acc : 47.083333333333336%\n",
      "\n",
      "Epoch: 26\n",
      "Test epoch : 26 loss : 0.9388627409934998 Acc : 43.333333333333336%\n",
      "70.0\n",
      "\n",
      "Epoch: 27\n",
      "Train epoch : 27 loss : 0.9861654361089071 Acc : 52.5%\n",
      "\n",
      "Epoch: 27\n",
      "Test epoch : 27 loss : 0.9290097057819366 Acc : 36.666666666666664%\n",
      "70.0\n",
      "\n",
      "Epoch: 28\n",
      "Train epoch : 28 loss : 1.0149191935857138 Acc : 47.083333333333336%\n",
      "\n",
      "Epoch: 28\n",
      "Test epoch : 28 loss : 1.1716933250427246 Acc : 36.666666666666664%\n",
      "70.0\n",
      "\n",
      "Epoch: 29\n",
      "Train epoch : 29 loss : 0.9932978868484497 Acc : 47.5%\n",
      "\n",
      "Epoch: 29\n",
      "Test epoch : 29 loss : 1.5224144458770752 Acc : 30.0%\n",
      "70.0\n",
      "\n",
      "Epoch: 30\n",
      "Train epoch : 30 loss : 1.008027195930481 Acc : 43.75%\n",
      "\n",
      "Epoch: 30\n",
      "Test epoch : 30 loss : 1.0432668626308441 Acc : 40.0%\n",
      "70.0\n",
      "\n",
      "Epoch: 31\n",
      "Train epoch : 31 loss : 0.9628069758415222 Acc : 50.0%\n",
      "\n",
      "Epoch: 31\n",
      "Test epoch : 31 loss : 1.1592211723327637 Acc : 43.333333333333336%\n",
      "70.0\n",
      "\n",
      "Epoch: 32\n",
      "Train epoch : 32 loss : 1.0895336866378784 Acc : 46.666666666666664%\n",
      "\n",
      "Epoch: 32\n",
      "Test epoch : 32 loss : 1.153249979019165 Acc : 36.666666666666664%\n",
      "70.0\n",
      "\n",
      "Epoch: 33\n",
      "Train epoch : 33 loss : 0.9941022117932637 Acc : 47.083333333333336%\n",
      "\n",
      "Epoch: 33\n",
      "Test epoch : 33 loss : 1.0414280593395233 Acc : 43.333333333333336%\n",
      "70.0\n",
      "\n",
      "Epoch: 34\n",
      "Train epoch : 34 loss : 0.9772667566935221 Acc : 49.166666666666664%\n",
      "\n",
      "Epoch: 34\n",
      "Test epoch : 34 loss : 1.135815978050232 Acc : 43.333333333333336%\n",
      "70.0\n",
      "\n",
      "Epoch: 35\n",
      "Train epoch : 35 loss : 0.9627855499585469 Acc : 50.833333333333336%\n",
      "\n",
      "Epoch: 35\n",
      "Test epoch : 35 loss : 0.859712541103363 Acc : 60.0%\n",
      "70.0\n",
      "\n",
      "Epoch: 36\n",
      "Train epoch : 36 loss : 1.0167346040407816 Acc : 47.916666666666664%\n",
      "\n",
      "Epoch: 36\n",
      "Test epoch : 36 loss : 1.2856846451759338 Acc : 30.0%\n",
      "70.0\n",
      "\n",
      "Epoch: 37\n",
      "Train epoch : 37 loss : 0.9879746715227763 Acc : 45.833333333333336%\n",
      "\n",
      "Epoch: 37\n",
      "Test epoch : 37 loss : 0.9311525225639343 Acc : 50.0%\n",
      "70.0\n",
      "\n",
      "Epoch: 38\n",
      "Train epoch : 38 loss : 0.9914732217788697 Acc : 49.166666666666664%\n",
      "\n",
      "Epoch: 38\n",
      "Test epoch : 38 loss : 0.7482798993587494 Acc : 73.33333333333333%\n",
      "73.33333333333333\n",
      "\n",
      "Epoch: 39\n",
      "Train epoch : 39 loss : 0.9464953859647115 Acc : 50.833333333333336%\n",
      "\n",
      "Epoch: 39\n",
      "Test epoch : 39 loss : 0.8305485248565674 Acc : 66.66666666666667%\n",
      "73.33333333333333\n",
      "\n",
      "Epoch: 40\n",
      "Train epoch : 40 loss : 0.9518388827641805 Acc : 52.916666666666664%\n",
      "\n",
      "Epoch: 40\n",
      "Test epoch : 40 loss : 0.8425361812114716 Acc : 66.66666666666667%\n",
      "73.33333333333333\n",
      "\n",
      "Epoch: 41\n",
      "Train epoch : 41 loss : 0.9439093629519145 Acc : 55.833333333333336%\n",
      "\n",
      "Epoch: 41\n",
      "Test epoch : 41 loss : 0.7979131042957306 Acc : 66.66666666666667%\n",
      "73.33333333333333\n",
      "\n",
      "Epoch: 42\n",
      "Train epoch : 42 loss : 0.9410844127337138 Acc : 55.0%\n",
      "\n",
      "Epoch: 42\n",
      "Test epoch : 42 loss : 0.7458558976650238 Acc : 63.333333333333336%\n",
      "73.33333333333333\n",
      "\n",
      "Epoch: 43\n",
      "Train epoch : 43 loss : 0.9210552136103313 Acc : 52.083333333333336%\n",
      "\n",
      "Epoch: 43\n",
      "Test epoch : 43 loss : 0.8272364437580109 Acc : 66.66666666666667%\n",
      "73.33333333333333\n",
      "\n",
      "Epoch: 44\n",
      "Train epoch : 44 loss : 0.9823934396107992 Acc : 50.833333333333336%\n",
      "\n",
      "Epoch: 44\n",
      "Test epoch : 44 loss : 1.538744330406189 Acc : 30.0%\n",
      "73.33333333333333\n",
      "\n",
      "Epoch: 45\n",
      "Train epoch : 45 loss : 0.9509003639221192 Acc : 47.916666666666664%\n",
      "\n",
      "Epoch: 45\n",
      "Test epoch : 45 loss : 0.7479853630065918 Acc : 66.66666666666667%\n",
      "73.33333333333333\n",
      "\n",
      "Epoch: 46\n",
      "Train epoch : 46 loss : 0.9275174856185913 Acc : 52.5%\n",
      "\n",
      "Epoch: 46\n",
      "Test epoch : 46 loss : 1.046844333410263 Acc : 43.333333333333336%\n",
      "73.33333333333333\n",
      "\n",
      "Epoch: 47\n",
      "Train epoch : 47 loss : 0.9047914981842041 Acc : 56.666666666666664%\n",
      "\n",
      "Epoch: 47\n",
      "Test epoch : 47 loss : 0.8056087493896484 Acc : 70.0%\n",
      "73.33333333333333\n",
      "\n",
      "Epoch: 48\n",
      "Train epoch : 48 loss : 0.9863614519437154 Acc : 50.0%\n",
      "\n",
      "Epoch: 48\n",
      "Test epoch : 48 loss : 0.8617560863494873 Acc : 46.666666666666664%\n",
      "73.33333333333333\n",
      "\n",
      "Epoch: 49\n",
      "Train epoch : 49 loss : 0.9535246928532918 Acc : 54.583333333333336%\n",
      "\n",
      "Epoch: 49\n",
      "Test epoch : 49 loss : 0.8173708617687225 Acc : 60.0%\n",
      "73.33333333333333\n",
      "\n",
      "Epoch: 50\n",
      "Train epoch : 50 loss : 0.9367045919100444 Acc : 52.5%\n",
      "\n",
      "Epoch: 50\n",
      "Test epoch : 50 loss : 0.7993357181549072 Acc : 66.66666666666667%\n",
      "73.33333333333333\n",
      "\n",
      "Epoch: 51\n",
      "Train epoch : 51 loss : 0.928326936562856 Acc : 53.333333333333336%\n",
      "\n",
      "Epoch: 51\n",
      "Test epoch : 51 loss : 0.7124432623386383 Acc : 66.66666666666667%\n",
      "73.33333333333333\n",
      "\n",
      "Epoch: 52\n",
      "Train epoch : 52 loss : 0.9100678046544393 Acc : 54.583333333333336%\n",
      "\n",
      "Epoch: 52\n",
      "Test epoch : 52 loss : 0.9597823917865753 Acc : 63.333333333333336%\n",
      "73.33333333333333\n",
      "\n",
      "Epoch: 53\n",
      "Train epoch : 53 loss : 0.9403333544731141 Acc : 50.833333333333336%\n",
      "\n",
      "Epoch: 53\n",
      "Test epoch : 53 loss : 0.7842940986156464 Acc : 63.333333333333336%\n",
      "73.33333333333333\n",
      "\n",
      "Epoch: 54\n",
      "Train epoch : 54 loss : 0.8798378467559814 Acc : 56.25%\n",
      "\n",
      "Epoch: 54\n",
      "Test epoch : 54 loss : 0.7014263868331909 Acc : 80.0%\n",
      "80.0\n",
      "\n",
      "Epoch: 55\n",
      "Train epoch : 55 loss : 0.8560114582379659 Acc : 57.083333333333336%\n",
      "\n",
      "Epoch: 55\n",
      "Test epoch : 55 loss : 0.7667513191699982 Acc : 70.0%\n",
      "80.0\n",
      "\n",
      "Epoch: 56\n",
      "Train epoch : 56 loss : 0.9336870948473612 Acc : 53.75%\n",
      "\n",
      "Epoch: 56\n",
      "Test epoch : 56 loss : 0.7198955714702606 Acc : 73.33333333333333%\n",
      "80.0\n",
      "\n",
      "Epoch: 57\n",
      "Train epoch : 57 loss : 0.9002870321273804 Acc : 54.166666666666664%\n",
      "\n",
      "Epoch: 57\n",
      "Test epoch : 57 loss : 0.8964836895465851 Acc : 50.0%\n",
      "80.0\n",
      "\n",
      "Epoch: 58\n",
      "Train epoch : 58 loss : 0.9576592087745667 Acc : 55.0%\n",
      "\n",
      "Epoch: 58\n",
      "Test epoch : 58 loss : 0.7448808550834656 Acc : 70.0%\n",
      "80.0\n",
      "\n",
      "Epoch: 59\n",
      "Train epoch : 59 loss : 0.8258877158164978 Acc : 60.833333333333336%\n",
      "\n",
      "Epoch: 59\n",
      "Test epoch : 59 loss : 0.9668137729167938 Acc : 43.333333333333336%\n",
      "80.0\n",
      "\n",
      "Epoch: 60\n",
      "Train epoch : 60 loss : 0.8325669646263123 Acc : 60.416666666666664%\n",
      "\n",
      "Epoch: 60\n",
      "Test epoch : 60 loss : 0.7551976144313812 Acc : 60.0%\n",
      "80.0\n",
      "\n",
      "Epoch: 61\n",
      "Train epoch : 61 loss : 0.7953453818957011 Acc : 63.75%\n",
      "\n",
      "Epoch: 61\n",
      "Test epoch : 61 loss : 0.8590927124023438 Acc : 50.0%\n",
      "80.0\n",
      "\n",
      "Epoch: 62\n",
      "Train epoch : 62 loss : 0.8572356263796489 Acc : 55.416666666666664%\n",
      "\n",
      "Epoch: 62\n",
      "Test epoch : 62 loss : 0.6268512010574341 Acc : 73.33333333333333%\n",
      "80.0\n",
      "\n",
      "Epoch: 63\n",
      "Train epoch : 63 loss : 0.8232754429181417 Acc : 62.083333333333336%\n",
      "\n",
      "Epoch: 63\n",
      "Test epoch : 63 loss : 0.7262628376483917 Acc : 66.66666666666667%\n",
      "80.0\n",
      "\n",
      "Epoch: 64\n",
      "Train epoch : 64 loss : 0.8467727303504944 Acc : 61.666666666666664%\n",
      "\n",
      "Epoch: 64\n",
      "Test epoch : 64 loss : 0.6034526526927948 Acc : 86.66666666666667%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 65\n",
      "Train epoch : 65 loss : 0.822357447942098 Acc : 58.75%\n",
      "\n",
      "Epoch: 65\n",
      "Test epoch : 65 loss : 0.8570944666862488 Acc : 53.333333333333336%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 66\n",
      "Train epoch : 66 loss : 0.9235557476679485 Acc : 50.416666666666664%\n",
      "\n",
      "Epoch: 66\n",
      "Test epoch : 66 loss : 0.6054058223962784 Acc : 73.33333333333333%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 67\n",
      "Train epoch : 67 loss : 0.8128246466318766 Acc : 65.0%\n",
      "\n",
      "Epoch: 67\n",
      "Test epoch : 67 loss : 0.8902144134044647 Acc : 56.666666666666664%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 68\n",
      "Train epoch : 68 loss : 0.8218241492907207 Acc : 62.5%\n",
      "\n",
      "Epoch: 68\n",
      "Test epoch : 68 loss : 0.6599075496196747 Acc : 76.66666666666667%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 69\n",
      "Train epoch : 69 loss : 0.745797606309255 Acc : 68.75%\n",
      "\n",
      "Epoch: 69\n",
      "Test epoch : 69 loss : 1.1435466408729553 Acc : 40.0%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 70\n",
      "Train epoch : 70 loss : 0.7633863548437755 Acc : 63.75%\n",
      "\n",
      "Epoch: 70\n",
      "Test epoch : 70 loss : 0.6248310208320618 Acc : 80.0%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 71\n",
      "Train epoch : 71 loss : 0.7833558718363444 Acc : 64.16666666666667%\n",
      "\n",
      "Epoch: 71\n",
      "Test epoch : 71 loss : 1.6029223799705505 Acc : 36.666666666666664%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 72\n",
      "Train epoch : 72 loss : 0.7509534239768982 Acc : 64.58333333333333%\n",
      "\n",
      "Epoch: 72\n",
      "Test epoch : 72 loss : 0.9201601147651672 Acc : 43.333333333333336%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 73\n",
      "Train epoch : 73 loss : 0.7254807074864705 Acc : 65.0%\n",
      "\n",
      "Epoch: 73\n",
      "Test epoch : 73 loss : 0.6550926864147186 Acc : 83.33333333333333%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 74\n",
      "Train epoch : 74 loss : 0.7119533141454061 Acc : 68.33333333333333%\n",
      "\n",
      "Epoch: 74\n",
      "Test epoch : 74 loss : 0.582851767539978 Acc : 70.0%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 75\n",
      "Train epoch : 75 loss : 0.7248976190884908 Acc : 62.916666666666664%\n",
      "\n",
      "Epoch: 75\n",
      "Test epoch : 75 loss : 0.5181765258312225 Acc : 86.66666666666667%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 76\n",
      "Train epoch : 76 loss : 0.6683467308680217 Acc : 73.33333333333333%\n",
      "\n",
      "Epoch: 76\n",
      "Test epoch : 76 loss : 1.2754419445991516 Acc : 30.0%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 77\n",
      "Train epoch : 77 loss : 1.0563607931137085 Acc : 52.916666666666664%\n",
      "\n",
      "Epoch: 77\n",
      "Test epoch : 77 loss : 0.6228708326816559 Acc : 73.33333333333333%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 78\n",
      "Train epoch : 78 loss : 0.7955358266830445 Acc : 62.916666666666664%\n",
      "\n",
      "Epoch: 78\n",
      "Test epoch : 78 loss : 1.1320986151695251 Acc : 40.0%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 79\n",
      "Train epoch : 79 loss : 0.7180230816205343 Acc : 69.16666666666667%\n",
      "\n",
      "Epoch: 79\n",
      "Test epoch : 79 loss : 0.6330108940601349 Acc : 76.66666666666667%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 80\n",
      "Train epoch : 80 loss : 0.7492398222287496 Acc : 70.83333333333333%\n",
      "\n",
      "Epoch: 80\n",
      "Test epoch : 80 loss : 0.7296271920204163 Acc : 73.33333333333333%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 81\n",
      "Train epoch : 81 loss : 0.7326932191848755 Acc : 64.58333333333333%\n",
      "\n",
      "Epoch: 81\n",
      "Test epoch : 81 loss : 0.9824699759483337 Acc : 46.666666666666664%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 82\n",
      "Train epoch : 82 loss : 0.670127135515213 Acc : 71.25%\n",
      "\n",
      "Epoch: 82\n",
      "Test epoch : 82 loss : 0.4636792987585068 Acc : 86.66666666666667%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 83\n",
      "Train epoch : 83 loss : 0.6982888102531433 Acc : 71.25%\n",
      "\n",
      "Epoch: 83\n",
      "Test epoch : 83 loss : 0.7178715914487839 Acc : 66.66666666666667%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 84\n",
      "Train epoch : 84 loss : 0.641966434319814 Acc : 73.33333333333333%\n",
      "\n",
      "Epoch: 84\n",
      "Test epoch : 84 loss : 0.5227790176868439 Acc : 73.33333333333333%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 85\n",
      "Train epoch : 85 loss : 0.659223182996114 Acc : 70.83333333333333%\n",
      "\n",
      "Epoch: 85\n",
      "Test epoch : 85 loss : 1.1324031054973602 Acc : 33.333333333333336%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 86\n",
      "Train epoch : 86 loss : 0.5880781948566437 Acc : 75.0%\n",
      "\n",
      "Epoch: 86\n",
      "Test epoch : 86 loss : 0.4547828137874603 Acc : 83.33333333333333%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 87\n",
      "Train epoch : 87 loss : 0.6201627075672149 Acc : 77.91666666666667%\n",
      "\n",
      "Epoch: 87\n",
      "Test epoch : 87 loss : 0.43990232050418854 Acc : 90.0%\n",
      "90.0\n",
      "\n",
      "Epoch: 88\n",
      "Train epoch : 88 loss : 0.606530511379242 Acc : 76.66666666666667%\n",
      "\n",
      "Epoch: 88\n",
      "Test epoch : 88 loss : 0.800776869058609 Acc : 50.0%\n",
      "90.0\n",
      "\n",
      "Epoch: 89\n",
      "Train epoch : 89 loss : 0.6088318705558777 Acc : 72.5%\n",
      "\n",
      "Epoch: 89\n",
      "Test epoch : 89 loss : 0.4682258665561676 Acc : 90.0%\n",
      "90.0\n",
      "\n",
      "Epoch: 90\n",
      "Train epoch : 90 loss : 0.580681174993515 Acc : 75.83333333333333%\n",
      "\n",
      "Epoch: 90\n",
      "Test epoch : 90 loss : 0.5249939560890198 Acc : 70.0%\n",
      "90.0\n",
      "\n",
      "Epoch: 91\n",
      "Train epoch : 91 loss : 0.6291853288809458 Acc : 70.83333333333333%\n",
      "\n",
      "Epoch: 91\n",
      "Test epoch : 91 loss : 0.3913509398698807 Acc : 93.33333333333333%\n",
      "93.33333333333333\n",
      "\n",
      "Epoch: 92\n",
      "Train epoch : 92 loss : 0.609882632891337 Acc : 74.58333333333333%\n",
      "\n",
      "Epoch: 92\n",
      "Test epoch : 92 loss : 0.7593564093112946 Acc : 60.0%\n",
      "93.33333333333333\n",
      "\n",
      "Epoch: 93\n",
      "Train epoch : 93 loss : 0.624415789047877 Acc : 72.08333333333333%\n",
      "\n",
      "Epoch: 93\n",
      "Test epoch : 93 loss : 0.4909312278032303 Acc : 76.66666666666667%\n",
      "93.33333333333333\n",
      "\n",
      "Epoch: 94\n",
      "Train epoch : 94 loss : 0.6181575318177541 Acc : 72.08333333333333%\n",
      "\n",
      "Epoch: 94\n",
      "Test epoch : 94 loss : 0.5588968992233276 Acc : 63.333333333333336%\n",
      "93.33333333333333\n",
      "\n",
      "Epoch: 95\n",
      "Train epoch : 95 loss : 0.5514415800571442 Acc : 83.33333333333333%\n",
      "\n",
      "Epoch: 95\n",
      "Test epoch : 95 loss : 0.8510957062244415 Acc : 56.666666666666664%\n",
      "93.33333333333333\n",
      "\n",
      "Epoch: 96\n",
      "Train epoch : 96 loss : 0.5136718571186065 Acc : 83.33333333333333%\n",
      "\n",
      "Epoch: 96\n",
      "Test epoch : 96 loss : 0.5241507738828659 Acc : 80.0%\n",
      "93.33333333333333\n",
      "\n",
      "Epoch: 97\n",
      "Train epoch : 97 loss : 0.6122421145439148 Acc : 72.91666666666667%\n",
      "\n",
      "Epoch: 97\n",
      "Test epoch : 97 loss : 1.8250373005867004 Acc : 30.0%\n",
      "93.33333333333333\n",
      "\n",
      "Epoch: 98\n",
      "Train epoch : 98 loss : 0.5906154414017996 Acc : 77.91666666666667%\n",
      "\n",
      "Epoch: 98\n",
      "Test epoch : 98 loss : 0.34578168392181396 Acc : 86.66666666666667%\n",
      "93.33333333333333\n",
      "\n",
      "Epoch: 99\n",
      "Train epoch : 99 loss : 0.7047343571980794 Acc : 66.25%\n",
      "\n",
      "Epoch: 99\n",
      "Test epoch : 99 loss : 0.736634224653244 Acc : 66.66666666666667%\n",
      "93.33333333333333\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 및 평가\n",
    "BEST_SCORE = 0\n",
    "for epoch in range(epochs):\n",
    "    train(epoch)\n",
    "    test(epoch, valloader)\n",
    "    print(BEST_SCORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: -1\n",
      "{0: 11, 1: 8, 2: 11}\n",
      "{0: 7, 1: 6, 2: 5}\n",
      "Test epoch : -1 loss : 0.7010462880134583 Acc : 60.0%\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋에서 평가\n",
    "model.load_state_dict(torch.load(os.path.join(save_path, f'teacher.pth')))\n",
    "test(-1, testloader, 'test', True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "run",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb50cdd79c86e8dce50f207c8be5ca838005251520472ce9347018b25221847d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

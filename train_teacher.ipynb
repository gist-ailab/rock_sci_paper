{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colab에서 드라이브 내 폴더 사용 위해 마운트\n",
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폴더까지의 경로\n",
    "# cd '/content/drive/MyDrive/GSA_Creative_Resarch/rock_sci_paper'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폴더 이동 확인\n",
    "# ! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\fskd\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#필요한 라이브러리들 import\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import dataset\n",
    "import model\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각종 path및 하이퍼 파라미터 설정\n",
    "data_path = 'C:\\\\Users\\\\USER\\\\Desktop\\\\GSH_CRP\\\\codes\\\\rock_sci_paper\\\\data\\pic128'\n",
    "save_path = 'C:\\\\Users\\\\USER\\\\Desktop\\\\GSH_CRP\\\\codes\\\\rock_sci_paper\\\\model_para'\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "learning_rate = 0.01\n",
    "seed = 2023\n",
    "mode = 'lr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 설정\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# device 설정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform 설정\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # transforms.RandomAffine((-45, 45), translate=(0.2,0.2)),\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ColorJitter(brightness=0.3),\n",
    "    transforms.ColorJitter(contrast=0.3),\n",
    "    transforms.ColorJitter(saturation=0.3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]\n",
    ")\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n",
      "30\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "# dataset 설정\n",
    "train_dataset = dataset.RockScissorsPaper(\n",
    "    transform=train_transform,\n",
    "    path = data_path,\n",
    "    mode = 'train'\n",
    ")\n",
    "val_dataset = dataset.RockScissorsPaper(\n",
    "    transform=test_transform,\n",
    "    path = data_path,\n",
    "    mode = 'val'\n",
    ")\n",
    "test_dataset = dataset.RockScissorsPaper(\n",
    "    transform=test_transform,\n",
    "    path = data_path,\n",
    "    mode = 'test'\n",
    ")\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader 설정\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델, 손실함수, 옵티마이저 설정\n",
    "model = model.ResNet10(num_classes=3)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    print('\\nEpoch: %d'%epoch)\n",
    "    # model train mode로 전환\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    total = 0\n",
    "    for (inputs, labels) in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if mode=='lr':\n",
    "            h,w = inputs.shape[-2], inputs.shape[-1]\n",
    "            lr_inputs = F.interpolate(inputs, (h//4, w//4), mode='bilinear')\n",
    "            lr_inputs = F.interpolate(lr_inputs, (h,w), mode='bilinear')\n",
    "            outputs, _, _, _, _ = model(lr_inputs)\n",
    "        else:\n",
    "            outputs, _, _, _, _ = model(inputs)\n",
    "            \n",
    "        _, pred = torch.max(outputs, 1)\n",
    "        total += outputs.size(0)\n",
    "        running_acc += (pred == labels).sum().item()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    total_loss = running_loss / len(trainloader)\n",
    "    total_acc = 100 * running_acc / total\n",
    "    print(f'Train epoch : {epoch} loss : {total_loss} Acc : {total_acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, loader, test_mode='val', mode2=False):\n",
    "    print('\\nEpoch: %d'%epoch)\n",
    "    # model eval mode로 전환\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    total = 0\n",
    "    label_dict = {0:0, 1:0, 2:0}\n",
    "    correct_dict = {0:0, 1:0, 2:0}\n",
    "    global BEST_SCORE\n",
    "    with torch.no_grad():\n",
    "        for (inputs, labels) in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            if mode=='lr':\n",
    "                h,w = inputs.shape[-2], inputs.shape[-1]\n",
    "                lr_inputs = F.interpolate(inputs, (h//4, w//4), mode='bilinear')\n",
    "                lr_inputs = F.interpolate(lr_inputs, (h,w), mode='bilinear')\n",
    "                outputs, _, _, _, _ = model(lr_inputs)\n",
    "            else:\n",
    "                outputs, _, _, _, _ = model(inputs)\n",
    "\n",
    "            _, pred = torch.max(outputs, 1)\n",
    "            \n",
    "            total += outputs.size(0)\n",
    "            running_acc += (pred == labels).sum().item()\n",
    "            \n",
    "            if mode2:\n",
    "                for i in range(len(labels)):\n",
    "                    label = labels[i]\n",
    "                    label_dict[label.item()] += 1\n",
    "                    if (pred==labels)[i]:\n",
    "                        correct_dict[label.item()] += 1\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "        total_loss = running_loss / len(loader)\n",
    "        total_acc = 100 * running_acc / total\n",
    "        if mode2:\n",
    "            print(label_dict)\n",
    "            print(correct_dict)\n",
    "        if total_acc >= BEST_SCORE and not test_mode=='test':\n",
    "            if not mode=='lr':\n",
    "                path = os.path.join(save_path, f'teacher.pth')\n",
    "                torch.save(model.state_dict(), path)\n",
    "            BEST_SCORE = total_acc\n",
    "        print(f'Test epoch : {epoch} loss : {total_loss} Acc : {total_acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\fskd\\lib\\site-packages\\torch\\nn\\functional.py:3455: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch : 0 loss : 1.1136944770812989 Acc : 40.833333333333336%\n",
      "\n",
      "Epoch: 0\n",
      "Test epoch : 0 loss : 1.0906015634536743 Acc : 43.333333333333336%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 1\n",
      "Train epoch : 1 loss : 1.0989525159200033 Acc : 40.416666666666664%\n",
      "\n",
      "Epoch: 1\n",
      "Test epoch : 1 loss : 1.0380252003669739 Acc : 43.333333333333336%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 2\n",
      "Train epoch : 2 loss : 1.0315659125645955 Acc : 45.0%\n",
      "\n",
      "Epoch: 2\n",
      "Test epoch : 2 loss : 0.9086534082889557 Acc : 70.0%\n",
      "70.0\n",
      "\n",
      "Epoch: 3\n",
      "Train epoch : 3 loss : 0.9838323831558228 Acc : 47.5%\n",
      "\n",
      "Epoch: 3\n",
      "Test epoch : 3 loss : 0.8110978901386261 Acc : 70.0%\n",
      "70.0\n",
      "\n",
      "Epoch: 4\n",
      "Train epoch : 4 loss : 0.9638475735982259 Acc : 49.583333333333336%\n",
      "\n",
      "Epoch: 4\n",
      "Test epoch : 4 loss : 0.7623769640922546 Acc : 70.0%\n",
      "70.0\n",
      "\n",
      "Epoch: 5\n",
      "Train epoch : 5 loss : 0.9102033774058024 Acc : 55.416666666666664%\n",
      "\n",
      "Epoch: 5\n",
      "Test epoch : 5 loss : 0.6896511614322662 Acc : 76.66666666666667%\n",
      "76.66666666666667\n",
      "\n",
      "Epoch: 6\n",
      "Train epoch : 6 loss : 0.9338047345479329 Acc : 53.75%\n",
      "\n",
      "Epoch: 6\n",
      "Test epoch : 6 loss : 1.3758013844490051 Acc : 33.333333333333336%\n",
      "76.66666666666667\n",
      "\n",
      "Epoch: 7\n",
      "Train epoch : 7 loss : 0.8803374449412028 Acc : 61.666666666666664%\n",
      "\n",
      "Epoch: 7\n",
      "Test epoch : 7 loss : 0.6937563717365265 Acc : 76.66666666666667%\n",
      "76.66666666666667\n",
      "\n",
      "Epoch: 8\n",
      "Train epoch : 8 loss : 0.7812247534592947 Acc : 65.83333333333333%\n",
      "\n",
      "Epoch: 8\n",
      "Test epoch : 8 loss : 0.6376819014549255 Acc : 73.33333333333333%\n",
      "76.66666666666667\n",
      "\n",
      "Epoch: 9\n",
      "Train epoch : 9 loss : 0.8717646320660909 Acc : 60.416666666666664%\n",
      "\n",
      "Epoch: 9\n",
      "Test epoch : 9 loss : 0.6208354830741882 Acc : 63.333333333333336%\n",
      "76.66666666666667\n",
      "\n",
      "Epoch: 10\n",
      "Train epoch : 10 loss : 0.788726003964742 Acc : 61.25%\n",
      "\n",
      "Epoch: 10\n",
      "Test epoch : 10 loss : 1.5040255188941956 Acc : 43.333333333333336%\n",
      "76.66666666666667\n",
      "\n",
      "Epoch: 11\n",
      "Train epoch : 11 loss : 0.7583723862965902 Acc : 62.083333333333336%\n",
      "\n",
      "Epoch: 11\n",
      "Test epoch : 11 loss : 0.5929637104272842 Acc : 73.33333333333333%\n",
      "76.66666666666667\n",
      "\n",
      "Epoch: 12\n",
      "Train epoch : 12 loss : 0.719679844379425 Acc : 69.58333333333333%\n",
      "\n",
      "Epoch: 12\n",
      "Test epoch : 12 loss : 0.58280149102211 Acc : 73.33333333333333%\n",
      "76.66666666666667\n",
      "\n",
      "Epoch: 13\n",
      "Train epoch : 13 loss : 0.8095396478970845 Acc : 66.25%\n",
      "\n",
      "Epoch: 13\n",
      "Test epoch : 13 loss : 0.4858126938343048 Acc : 76.66666666666667%\n",
      "76.66666666666667\n",
      "\n",
      "Epoch: 14\n",
      "Train epoch : 14 loss : 0.6869446555773417 Acc : 67.91666666666667%\n",
      "\n",
      "Epoch: 14\n",
      "Test epoch : 14 loss : 0.6195887625217438 Acc : 83.33333333333333%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 15\n",
      "Train epoch : 15 loss : 0.6765949944655101 Acc : 70.41666666666667%\n",
      "\n",
      "Epoch: 15\n",
      "Test epoch : 15 loss : 0.41302186250686646 Acc : 86.66666666666667%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 16\n",
      "Train epoch : 16 loss : 0.6962185422579448 Acc : 67.91666666666667%\n",
      "\n",
      "Epoch: 16\n",
      "Test epoch : 16 loss : 0.48082292079925537 Acc : 83.33333333333333%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 17\n",
      "Train epoch : 17 loss : 0.6260530730088552 Acc : 75.41666666666667%\n",
      "\n",
      "Epoch: 17\n",
      "Test epoch : 17 loss : 4.550706267356873 Acc : 43.333333333333336%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 18\n",
      "Train epoch : 18 loss : 0.5607815980911255 Acc : 79.58333333333333%\n",
      "\n",
      "Epoch: 18\n",
      "Test epoch : 18 loss : 1.1184177994728088 Acc : 46.666666666666664%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 19\n",
      "Train epoch : 19 loss : 0.5315630336602529 Acc : 80.0%\n",
      "\n",
      "Epoch: 19\n",
      "Test epoch : 19 loss : 0.5832059383392334 Acc : 70.0%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 20\n",
      "Train epoch : 20 loss : 0.5796738127867381 Acc : 77.08333333333333%\n",
      "\n",
      "Epoch: 20\n",
      "Test epoch : 20 loss : 0.689234733581543 Acc : 66.66666666666667%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 21\n",
      "Train epoch : 21 loss : 0.5773875951766968 Acc : 77.08333333333333%\n",
      "\n",
      "Epoch: 21\n",
      "Test epoch : 21 loss : 1.0290502905845642 Acc : 53.333333333333336%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 22\n",
      "Train epoch : 22 loss : 0.48725899557272595 Acc : 85.0%\n",
      "\n",
      "Epoch: 22\n",
      "Test epoch : 22 loss : 0.2891820818185806 Acc : 93.33333333333333%\n",
      "93.33333333333333\n",
      "\n",
      "Epoch: 23\n",
      "Train epoch : 23 loss : 0.3986144224802653 Acc : 88.33333333333333%\n",
      "\n",
      "Epoch: 23\n",
      "Test epoch : 23 loss : 1.110624372959137 Acc : 50.0%\n",
      "93.33333333333333\n",
      "\n",
      "Epoch: 24\n",
      "Train epoch : 24 loss : 0.42282094260056813 Acc : 87.08333333333333%\n",
      "\n",
      "Epoch: 24\n",
      "Test epoch : 24 loss : 0.7055451571941376 Acc : 56.666666666666664%\n",
      "93.33333333333333\n",
      "\n",
      "Epoch: 25\n",
      "Train epoch : 25 loss : 0.6748362839221954 Acc : 69.16666666666667%\n",
      "\n",
      "Epoch: 25\n",
      "Test epoch : 25 loss : 1.5724928975105286 Acc : 43.333333333333336%\n",
      "93.33333333333333\n",
      "\n",
      "Epoch: 26\n",
      "Train epoch : 26 loss : 0.4420665462811788 Acc : 81.66666666666667%\n",
      "\n",
      "Epoch: 26\n",
      "Test epoch : 26 loss : 0.3550693392753601 Acc : 83.33333333333333%\n",
      "93.33333333333333\n",
      "\n",
      "Epoch: 27\n",
      "Train epoch : 27 loss : 0.4607204844554265 Acc : 83.33333333333333%\n",
      "\n",
      "Epoch: 27\n",
      "Test epoch : 27 loss : 0.5363328009843826 Acc : 66.66666666666667%\n",
      "93.33333333333333\n",
      "\n",
      "Epoch: 28\n",
      "Train epoch : 28 loss : 0.3797497113545736 Acc : 85.83333333333333%\n",
      "\n",
      "Epoch: 28\n",
      "Test epoch : 28 loss : 0.25899988412857056 Acc : 93.33333333333333%\n",
      "93.33333333333333\n",
      "\n",
      "Epoch: 29\n",
      "Train epoch : 29 loss : 0.34760828713576 Acc : 91.25%\n",
      "\n",
      "Epoch: 29\n",
      "Test epoch : 29 loss : 0.2838420048356056 Acc : 90.0%\n",
      "93.33333333333333\n",
      "\n",
      "Epoch: 30\n",
      "Train epoch : 30 loss : 0.34797785580158236 Acc : 89.16666666666667%\n",
      "\n",
      "Epoch: 30\n",
      "Test epoch : 30 loss : 0.23559069633483887 Acc : 90.0%\n",
      "93.33333333333333\n",
      "\n",
      "Epoch: 31\n",
      "Train epoch : 31 loss : 0.4101881871620814 Acc : 83.33333333333333%\n",
      "\n",
      "Epoch: 31\n",
      "Test epoch : 31 loss : 0.6645886600017548 Acc : 63.333333333333336%\n",
      "93.33333333333333\n",
      "\n",
      "Epoch: 32\n",
      "Train epoch : 32 loss : 0.3487424393494924 Acc : 86.66666666666667%\n",
      "\n",
      "Epoch: 32\n",
      "Test epoch : 32 loss : 0.40463799238204956 Acc : 86.66666666666667%\n",
      "93.33333333333333\n",
      "\n",
      "Epoch: 33\n",
      "Train epoch : 33 loss : 0.3401931544144948 Acc : 89.16666666666667%\n",
      "\n",
      "Epoch: 33\n",
      "Test epoch : 33 loss : 0.3537876009941101 Acc : 90.0%\n",
      "93.33333333333333\n",
      "\n",
      "Epoch: 34\n",
      "Train epoch : 34 loss : 0.2950721144676208 Acc : 90.41666666666667%\n",
      "\n",
      "Epoch: 34\n",
      "Test epoch : 34 loss : 0.20861947536468506 Acc : 96.66666666666667%\n",
      "96.66666666666667\n",
      "\n",
      "Epoch: 35\n",
      "Train epoch : 35 loss : 0.35344381431738536 Acc : 87.91666666666667%\n",
      "\n",
      "Epoch: 35\n",
      "Test epoch : 35 loss : 0.7765799760818481 Acc : 70.0%\n",
      "96.66666666666667\n",
      "\n",
      "Epoch: 36\n",
      "Train epoch : 36 loss : 0.3997044603029887 Acc : 85.0%\n",
      "\n",
      "Epoch: 36\n",
      "Test epoch : 36 loss : 0.1689627766609192 Acc : 96.66666666666667%\n",
      "96.66666666666667\n",
      "\n",
      "Epoch: 37\n",
      "Train epoch : 37 loss : 0.38693153063456215 Acc : 85.83333333333333%\n",
      "\n",
      "Epoch: 37\n",
      "Test epoch : 37 loss : 0.1332549713551998 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 38\n",
      "Train epoch : 38 loss : 0.2899160623550415 Acc : 90.41666666666667%\n",
      "\n",
      "Epoch: 38\n",
      "Test epoch : 38 loss : 0.326145701110363 Acc : 83.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 39\n",
      "Train epoch : 39 loss : 0.2749451090892156 Acc : 92.91666666666667%\n",
      "\n",
      "Epoch: 39\n",
      "Test epoch : 39 loss : 0.2638402134180069 Acc : 90.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 40\n",
      "Train epoch : 40 loss : 0.23067948917547862 Acc : 93.75%\n",
      "\n",
      "Epoch: 40\n",
      "Test epoch : 40 loss : 0.19135156273841858 Acc : 90.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 41\n",
      "Train epoch : 41 loss : 0.269644595682621 Acc : 90.41666666666667%\n",
      "\n",
      "Epoch: 41\n",
      "Test epoch : 41 loss : 0.08515812084078789 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 42\n",
      "Train epoch : 42 loss : 0.2588054875532786 Acc : 90.41666666666667%\n",
      "\n",
      "Epoch: 42\n",
      "Test epoch : 42 loss : 0.790494978427887 Acc : 70.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 43\n",
      "Train epoch : 43 loss : 0.2600168466567993 Acc : 89.58333333333333%\n",
      "\n",
      "Epoch: 43\n",
      "Test epoch : 43 loss : 0.2220907360315323 Acc : 86.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 44\n",
      "Train epoch : 44 loss : 0.21717505554358166 Acc : 92.5%\n",
      "\n",
      "Epoch: 44\n",
      "Test epoch : 44 loss : 0.128902405500412 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 45\n",
      "Train epoch : 45 loss : 0.1924026091893514 Acc : 95.41666666666667%\n",
      "\n",
      "Epoch: 45\n",
      "Test epoch : 45 loss : 0.1297110952436924 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 46\n",
      "Train epoch : 46 loss : 0.22218321015437445 Acc : 92.91666666666667%\n",
      "\n",
      "Epoch: 46\n",
      "Test epoch : 46 loss : 0.19552883878350258 Acc : 93.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 47\n",
      "Train epoch : 47 loss : 0.17378536065419514 Acc : 96.66666666666667%\n",
      "\n",
      "Epoch: 47\n",
      "Test epoch : 47 loss : 0.4093226045370102 Acc : 76.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 48\n",
      "Train epoch : 48 loss : 0.21525040765603384 Acc : 93.33333333333333%\n",
      "\n",
      "Epoch: 48\n",
      "Test epoch : 48 loss : 0.10704043135046959 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 49\n",
      "Train epoch : 49 loss : 0.22540702819824218 Acc : 94.16666666666667%\n",
      "\n",
      "Epoch: 49\n",
      "Test epoch : 49 loss : 0.192351795732975 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 50\n",
      "Train epoch : 50 loss : 0.2405250032742818 Acc : 90.83333333333333%\n",
      "\n",
      "Epoch: 50\n",
      "Test epoch : 50 loss : 0.17071619629859924 Acc : 93.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 51\n",
      "Train epoch : 51 loss : 0.22858548065026602 Acc : 94.58333333333333%\n",
      "\n",
      "Epoch: 51\n",
      "Test epoch : 51 loss : 0.11818784847855568 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 52\n",
      "Train epoch : 52 loss : 0.19802792618672052 Acc : 94.16666666666667%\n",
      "\n",
      "Epoch: 52\n",
      "Test epoch : 52 loss : 0.08355995267629623 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 53\n",
      "Train epoch : 53 loss : 0.19334295392036438 Acc : 94.16666666666667%\n",
      "\n",
      "Epoch: 53\n",
      "Test epoch : 53 loss : 0.3463413119316101 Acc : 80.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 54\n",
      "Train epoch : 54 loss : 0.17253323942422866 Acc : 95.83333333333333%\n",
      "\n",
      "Epoch: 54\n",
      "Test epoch : 54 loss : 0.11112874001264572 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 55\n",
      "Train epoch : 55 loss : 0.15061309983332952 Acc : 96.25%\n",
      "\n",
      "Epoch: 55\n",
      "Test epoch : 55 loss : 0.11337562650442123 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 56\n",
      "Train epoch : 56 loss : 0.1547788068652153 Acc : 96.25%\n",
      "\n",
      "Epoch: 56\n",
      "Test epoch : 56 loss : 0.11739806458353996 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 57\n",
      "Train epoch : 57 loss : 0.21285421003897984 Acc : 93.33333333333333%\n",
      "\n",
      "Epoch: 57\n",
      "Test epoch : 57 loss : 0.22095145285129547 Acc : 93.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 58\n",
      "Train epoch : 58 loss : 0.1879259501894315 Acc : 94.58333333333333%\n",
      "\n",
      "Epoch: 58\n",
      "Test epoch : 58 loss : 0.19444305822253227 Acc : 93.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 59\n",
      "Train epoch : 59 loss : 0.13957316329081854 Acc : 97.91666666666667%\n",
      "\n",
      "Epoch: 59\n",
      "Test epoch : 59 loss : 0.14943273924291134 Acc : 90.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 60\n",
      "Train epoch : 60 loss : 0.1598750777542591 Acc : 95.0%\n",
      "\n",
      "Epoch: 60\n",
      "Test epoch : 60 loss : 0.09860597550868988 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 61\n",
      "Train epoch : 61 loss : 0.11814825832843781 Acc : 96.25%\n",
      "\n",
      "Epoch: 61\n",
      "Test epoch : 61 loss : 0.2807201147079468 Acc : 86.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 62\n",
      "Train epoch : 62 loss : 0.1800557183722655 Acc : 94.16666666666667%\n",
      "\n",
      "Epoch: 62\n",
      "Test epoch : 62 loss : 0.13003468792885542 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 63\n",
      "Train epoch : 63 loss : 0.2744824782013893 Acc : 90.0%\n",
      "\n",
      "Epoch: 63\n",
      "Test epoch : 63 loss : 1.5412091612815857 Acc : 60.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 64\n",
      "Train epoch : 64 loss : 0.7361254890759786 Acc : 75.0%\n",
      "\n",
      "Epoch: 64\n",
      "Test epoch : 64 loss : 0.2190769612789154 Acc : 86.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 65\n",
      "Train epoch : 65 loss : 0.18802075684070588 Acc : 95.83333333333333%\n",
      "\n",
      "Epoch: 65\n",
      "Test epoch : 65 loss : 0.14464716240763664 Acc : 93.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 66\n",
      "Train epoch : 66 loss : 0.20601472705602647 Acc : 94.16666666666667%\n",
      "\n",
      "Epoch: 66\n",
      "Test epoch : 66 loss : 0.08372148126363754 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 67\n",
      "Train epoch : 67 loss : 0.1288602242867152 Acc : 97.91666666666667%\n",
      "\n",
      "Epoch: 67\n",
      "Test epoch : 67 loss : 0.11348867416381836 Acc : 93.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 68\n",
      "Train epoch : 68 loss : 0.17868341381351152 Acc : 95.41666666666667%\n",
      "\n",
      "Epoch: 68\n",
      "Test epoch : 68 loss : 0.06168120168149471 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 69\n",
      "Train epoch : 69 loss : 0.14163751552502316 Acc : 95.41666666666667%\n",
      "\n",
      "Epoch: 69\n",
      "Test epoch : 69 loss : 0.0632454240694642 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 70\n",
      "Train epoch : 70 loss : 0.12907028471430143 Acc : 96.25%\n",
      "\n",
      "Epoch: 70\n",
      "Test epoch : 70 loss : 0.06517720781266689 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 71\n",
      "Train epoch : 71 loss : 0.12963066721955935 Acc : 97.91666666666667%\n",
      "\n",
      "Epoch: 71\n",
      "Test epoch : 71 loss : 0.07057542726397514 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 72\n",
      "Train epoch : 72 loss : 0.11363220835725467 Acc : 97.5%\n",
      "\n",
      "Epoch: 72\n",
      "Test epoch : 72 loss : 0.30826493352651596 Acc : 90.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 73\n",
      "Train epoch : 73 loss : 0.11307820876439413 Acc : 97.91666666666667%\n",
      "\n",
      "Epoch: 73\n",
      "Test epoch : 73 loss : 0.05504174157977104 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 74\n",
      "Train epoch : 74 loss : 0.08772943938771884 Acc : 98.75%\n",
      "\n",
      "Epoch: 74\n",
      "Test epoch : 74 loss : 0.044821685180068016 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 75\n",
      "Train epoch : 75 loss : 0.09002045467495919 Acc : 97.5%\n",
      "\n",
      "Epoch: 75\n",
      "Test epoch : 75 loss : 0.06265947036445141 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 76\n",
      "Train epoch : 76 loss : 0.10337834532062212 Acc : 96.66666666666667%\n",
      "\n",
      "Epoch: 76\n",
      "Test epoch : 76 loss : 0.21808403730392456 Acc : 93.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 77\n",
      "Train epoch : 77 loss : 0.0973332591354847 Acc : 98.75%\n",
      "\n",
      "Epoch: 77\n",
      "Test epoch : 77 loss : 0.03922819625586271 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 78\n",
      "Train epoch : 78 loss : 0.07648829246560733 Acc : 98.75%\n",
      "\n",
      "Epoch: 78\n",
      "Test epoch : 78 loss : 0.045036351308226585 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 79\n",
      "Train epoch : 79 loss : 0.05912710651755333 Acc : 99.58333333333333%\n",
      "\n",
      "Epoch: 79\n",
      "Test epoch : 79 loss : 0.04029707703739405 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 80\n",
      "Train epoch : 80 loss : 0.09030579701066017 Acc : 98.75%\n",
      "\n",
      "Epoch: 80\n",
      "Test epoch : 80 loss : 0.1388864517211914 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 81\n",
      "Train epoch : 81 loss : 0.08430795843402544 Acc : 97.91666666666667%\n",
      "\n",
      "Epoch: 81\n",
      "Test epoch : 81 loss : 0.21832240372896194 Acc : 90.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 82\n",
      "Train epoch : 82 loss : 0.09489184953272342 Acc : 98.75%\n",
      "\n",
      "Epoch: 82\n",
      "Test epoch : 82 loss : 0.04357556253671646 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 83\n",
      "Train epoch : 83 loss : 0.12285205076138178 Acc : 97.5%\n",
      "\n",
      "Epoch: 83\n",
      "Test epoch : 83 loss : 0.4132554829120636 Acc : 83.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 84\n",
      "Train epoch : 84 loss : 0.08691750094294548 Acc : 97.08333333333333%\n",
      "\n",
      "Epoch: 84\n",
      "Test epoch : 84 loss : 0.09621207416057587 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 85\n",
      "Train epoch : 85 loss : 0.11070595048367977 Acc : 97.08333333333333%\n",
      "\n",
      "Epoch: 85\n",
      "Test epoch : 85 loss : 0.08800788596272469 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 86\n",
      "Train epoch : 86 loss : 0.0713197814921538 Acc : 97.91666666666667%\n",
      "\n",
      "Epoch: 86\n",
      "Test epoch : 86 loss : 0.04608480352908373 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 87\n",
      "Train epoch : 87 loss : 0.09979006585975488 Acc : 97.5%\n",
      "\n",
      "Epoch: 87\n",
      "Test epoch : 87 loss : 0.06654335372149944 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 88\n",
      "Train epoch : 88 loss : 0.07451914797226587 Acc : 97.91666666666667%\n",
      "\n",
      "Epoch: 88\n",
      "Test epoch : 88 loss : 0.046535592526197433 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 89\n",
      "Train epoch : 89 loss : 0.06427764060596625 Acc : 99.16666666666667%\n",
      "\n",
      "Epoch: 89\n",
      "Test epoch : 89 loss : 0.032486047595739365 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 90\n",
      "Train epoch : 90 loss : 0.0751720936348041 Acc : 98.33333333333333%\n",
      "\n",
      "Epoch: 90\n",
      "Test epoch : 90 loss : 0.771309107542038 Acc : 80.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 91\n",
      "Train epoch : 91 loss : 0.10211352842549483 Acc : 96.66666666666667%\n",
      "\n",
      "Epoch: 91\n",
      "Test epoch : 91 loss : 0.056742011569440365 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 92\n",
      "Train epoch : 92 loss : 0.08523490969091654 Acc : 97.91666666666667%\n",
      "\n",
      "Epoch: 92\n",
      "Test epoch : 92 loss : 0.04810446500778198 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 93\n",
      "Train epoch : 93 loss : 0.14097728778918583 Acc : 95.0%\n",
      "\n",
      "Epoch: 93\n",
      "Test epoch : 93 loss : 0.06951067596673965 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 94\n",
      "Train epoch : 94 loss : 0.10844136755913496 Acc : 97.5%\n",
      "\n",
      "Epoch: 94\n",
      "Test epoch : 94 loss : 0.054512856528162956 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 95\n",
      "Train epoch : 95 loss : 0.08385265587518613 Acc : 98.33333333333333%\n",
      "\n",
      "Epoch: 95\n",
      "Test epoch : 95 loss : 0.12100126594305038 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 96\n",
      "Train epoch : 96 loss : 0.052217814264198144 Acc : 98.33333333333333%\n",
      "\n",
      "Epoch: 96\n",
      "Test epoch : 96 loss : 0.024608642794191837 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 97\n",
      "Train epoch : 97 loss : 0.05202615515639385 Acc : 99.16666666666667%\n",
      "\n",
      "Epoch: 97\n",
      "Test epoch : 97 loss : 0.05836591124534607 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 98\n",
      "Train epoch : 98 loss : 0.1454056054353714 Acc : 95.0%\n",
      "\n",
      "Epoch: 98\n",
      "Test epoch : 98 loss : 0.08180232904851437 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 99\n",
      "Train epoch : 99 loss : 0.1228947808345159 Acc : 96.66666666666667%\n",
      "\n",
      "Epoch: 99\n",
      "Test epoch : 99 loss : 0.12918789684772491 Acc : 96.66666666666667%\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 및 평가\n",
    "BEST_SCORE = 0\n",
    "for epoch in range(epochs):\n",
    "    train(epoch)\n",
    "    test(epoch, valloader)\n",
    "    print(BEST_SCORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: -1\n",
      "{0: 11, 1: 8, 2: 11}\n",
      "{0: 11, 1: 8, 2: 11}\n",
      "Test epoch : -1 loss : 0.14802590757608414 Acc : 100.0%\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋에서 평가\n",
    "model.load_state_dict(torch.load(os.path.join(save_path, f'teacher.pth')))\n",
    "test(-1, testloader, 'test', True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "run",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb50cdd79c86e8dce50f207c8be5ca838005251520472ce9347018b25221847d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

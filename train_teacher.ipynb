{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\fskd\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#필요한 라이브러리들 import\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import dataset\n",
    "import model\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각종 path및 하이퍼 파라미터 설정\n",
    "data_path = 'C:\\\\Users\\\\USER\\\\Desktop\\\\GSH_CRP\\\\codes\\\\rock_sci_paper\\\\data\\\\ro_sci_pa'\n",
    "save_path = 'C:\\\\Users\\\\USER\\\\Desktop\\\\GSH_CRP\\\\codes\\\\rock_sci_paper\\\\model_para'\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "learning_rate = 0.01\n",
    "seed = 2024\n",
    "mode = 'hr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 설정\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# device 설정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform 설정\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.CenterCrop((224,224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation((-90, 90)),\n",
    "    transforms.RandomAffine((-90, 90), translate=(0.2,0.2)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset 설정\n",
    "datasets = dataset.RockScissorsPaper(\n",
    "    transform=transform,\n",
    "    path = data_path\n",
    ")\n",
    "num_data = len(datasets)\n",
    "num_train = int(num_data*0.6)\n",
    "num_val = int(num_data*0.2)\n",
    "num_test = num_data - num_train - num_val\n",
    "\n",
    "train_data, val_data, test_data = torch.utils.data.random_split(datasets, [num_train, num_val, num_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader 설정\n",
    "trainloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "valloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "testloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델, 손실함수, 옵티마이저 설정\n",
    "model = model.ResNet18(num_classes=3)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    print('\\nEpoch: %d'%epoch)\n",
    "    # model train mode로 전환\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    total = 0\n",
    "    for (inputs, labels) in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if mode=='lr':\n",
    "            h,w = inputs.shape[-2], inputs.shape[-1]\n",
    "            lr_inputs = F.interpolate(inputs, (h//64, w//64))\n",
    "            lr_inputs = F.interpolate(lr_inputs, (h,w))\n",
    "            outputs, _, _, _, _ = model(lr_inputs)\n",
    "        else:\n",
    "            outputs, _, _, _, _ = model(inputs)\n",
    "            \n",
    "        _, pred = torch.max(outputs, 1)\n",
    "        total += outputs.size(0)\n",
    "        running_acc += (pred == labels).sum().item()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    total_loss = running_loss / len(trainloader)\n",
    "    total_acc = 100 * running_acc / total\n",
    "    print(f'Train epoch : {epoch} loss : {total_loss} Acc : {total_acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, loader, mode='val'):\n",
    "    print('\\nEpoch: %d'%epoch)\n",
    "    # model eval mode로 전환\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    total = 0\n",
    "    label_dict = {0:0, 1:0, 2:0}\n",
    "    global BEST_SCORE\n",
    "    with torch.no_grad():\n",
    "        for (inputs, labels) in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            if mode=='lr':\n",
    "                h,w = inputs.shape[-2], inputs.shape[-1]\n",
    "                lr_inputs = F.interpolate(inputs, (h//32, w//32))\n",
    "                lr_inputs = F.interpolate(lr_inputs, (h,w))\n",
    "                outputs, _, _, _, _ = model(lr_inputs)\n",
    "            else:\n",
    "                outputs, _, _, _, _ = model(inputs)\n",
    "\n",
    "            _, pred = torch.max(outputs, 1)\n",
    "            for label in labels:\n",
    "                label_dict[label.item()] += 1\n",
    "            total += outputs.size(0)\n",
    "            running_acc += (pred == labels).sum().item()\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "        total_loss = running_loss / len(loader)\n",
    "        total_acc = 100 * running_acc / total\n",
    "        print(label_dict)\n",
    "        if total_acc > BEST_SCORE and not mode=='test':\n",
    "            path = os.path.join(save_path, f'teacher.pth')\n",
    "            torch.save(model.state_dict(), path)\n",
    "            BEST_SCORE = total_acc\n",
    "        print(f'Test epoch : {epoch} loss : {total_loss} Acc : {total_acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "Train epoch : 0 loss : 1.2547118323189872 Acc : 28.703703703703702%\n",
      "\n",
      "Epoch: 0\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 0 loss : 1.0878044366836548 Acc : 30.555555555555557%\n",
      "30.555555555555557\n",
      "\n",
      "Epoch: 1\n",
      "Train epoch : 1 loss : 1.1438394274030412 Acc : 33.333333333333336%\n",
      "\n",
      "Epoch: 1\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 1 loss : 1.1838473081588745 Acc : 30.555555555555557%\n",
      "30.555555555555557\n",
      "\n",
      "Epoch: 2\n",
      "Train epoch : 2 loss : 1.214103443281991 Acc : 31.48148148148148%\n",
      "\n",
      "Epoch: 2\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 2 loss : 1.1755651235580444 Acc : 30.555555555555557%\n",
      "30.555555555555557\n",
      "\n",
      "Epoch: 3\n",
      "Train epoch : 3 loss : 1.1819052696228027 Acc : 37.96296296296296%\n",
      "\n",
      "Epoch: 3\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 3 loss : 1.196570912996928 Acc : 30.555555555555557%\n",
      "30.555555555555557\n",
      "\n",
      "Epoch: 4\n",
      "Train epoch : 4 loss : 1.1365218332835607 Acc : 31.48148148148148%\n",
      "\n",
      "Epoch: 4\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 4 loss : 1.2075746456782024 Acc : 30.555555555555557%\n",
      "30.555555555555557\n",
      "\n",
      "Epoch: 5\n",
      "Train epoch : 5 loss : 1.1006387301853724 Acc : 37.03703703703704%\n",
      "\n",
      "Epoch: 5\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 5 loss : 1.5445247491200764 Acc : 30.555555555555557%\n",
      "30.555555555555557\n",
      "\n",
      "Epoch: 6\n",
      "Train epoch : 6 loss : 1.1786670684814453 Acc : 34.25925925925926%\n",
      "\n",
      "Epoch: 6\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 6 loss : 1.1354646682739258 Acc : 27.77777777777778%\n",
      "30.555555555555557\n",
      "\n",
      "Epoch: 7\n",
      "Train epoch : 7 loss : 1.1327512179102217 Acc : 38.888888888888886%\n",
      "\n",
      "Epoch: 7\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 7 loss : 1.414300004641215 Acc : 30.555555555555557%\n",
      "30.555555555555557\n",
      "\n",
      "Epoch: 8\n",
      "Train epoch : 8 loss : 1.184226666178022 Acc : 35.18518518518518%\n",
      "\n",
      "Epoch: 8\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 8 loss : 1.2121187448501587 Acc : 30.555555555555557%\n",
      "30.555555555555557\n",
      "\n",
      "Epoch: 9\n",
      "Train epoch : 9 loss : 1.0935574514525277 Acc : 38.888888888888886%\n",
      "\n",
      "Epoch: 9\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 9 loss : 1.2731130917867024 Acc : 30.555555555555557%\n",
      "30.555555555555557\n",
      "\n",
      "Epoch: 10\n",
      "Train epoch : 10 loss : 1.1413529430116927 Acc : 32.407407407407405%\n",
      "\n",
      "Epoch: 10\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 10 loss : 1.277815540631612 Acc : 41.666666666666664%\n",
      "41.666666666666664\n",
      "\n",
      "Epoch: 11\n",
      "Train epoch : 11 loss : 1.0978829520089286 Acc : 36.111111111111114%\n",
      "\n",
      "Epoch: 11\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 11 loss : 1.4652434587478638 Acc : 33.333333333333336%\n",
      "41.666666666666664\n",
      "\n",
      "Epoch: 12\n",
      "Train epoch : 12 loss : 1.0763895000730241 Acc : 41.666666666666664%\n",
      "\n",
      "Epoch: 12\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 12 loss : 1.3103581269582112 Acc : 36.111111111111114%\n",
      "41.666666666666664\n",
      "\n",
      "Epoch: 13\n",
      "Train epoch : 13 loss : 1.1982303857803345 Acc : 34.25925925925926%\n",
      "\n",
      "Epoch: 13\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 13 loss : 1.131342609723409 Acc : 38.888888888888886%\n",
      "41.666666666666664\n",
      "\n",
      "Epoch: 14\n",
      "Train epoch : 14 loss : 1.109080970287323 Acc : 43.51851851851852%\n",
      "\n",
      "Epoch: 14\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 14 loss : 1.8639734586079915 Acc : 36.111111111111114%\n",
      "41.666666666666664\n",
      "\n",
      "Epoch: 15\n",
      "Train epoch : 15 loss : 1.142909322466169 Acc : 44.44444444444444%\n",
      "\n",
      "Epoch: 15\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 15 loss : 1.1668410698572795 Acc : 30.555555555555557%\n",
      "41.666666666666664\n",
      "\n",
      "Epoch: 16\n",
      "Train epoch : 16 loss : 1.133458035332816 Acc : 38.888888888888886%\n",
      "\n",
      "Epoch: 16\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 16 loss : 2.0394710302352905 Acc : 36.111111111111114%\n",
      "41.666666666666664\n",
      "\n",
      "Epoch: 17\n",
      "Train epoch : 17 loss : 1.1062654938016618 Acc : 37.96296296296296%\n",
      "\n",
      "Epoch: 17\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 17 loss : 1.2430393695831299 Acc : 33.333333333333336%\n",
      "41.666666666666664\n",
      "\n",
      "Epoch: 18\n",
      "Train epoch : 18 loss : 1.141316567148481 Acc : 34.25925925925926%\n",
      "\n",
      "Epoch: 18\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 18 loss : 1.2816027402877808 Acc : 38.888888888888886%\n",
      "41.666666666666664\n",
      "\n",
      "Epoch: 19\n",
      "Train epoch : 19 loss : 1.078205636569432 Acc : 37.96296296296296%\n",
      "\n",
      "Epoch: 19\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 19 loss : 1.1594143311182659 Acc : 30.555555555555557%\n",
      "41.666666666666664\n",
      "\n",
      "Epoch: 20\n",
      "Train epoch : 20 loss : 1.103229556764875 Acc : 42.592592592592595%\n",
      "\n",
      "Epoch: 20\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 20 loss : 1.375405192375183 Acc : 33.333333333333336%\n",
      "41.666666666666664\n",
      "\n",
      "Epoch: 21\n",
      "Train epoch : 21 loss : 1.0487947293690272 Acc : 40.74074074074074%\n",
      "\n",
      "Epoch: 21\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 21 loss : 1.5487289428710938 Acc : 36.111111111111114%\n",
      "41.666666666666664\n",
      "\n",
      "Epoch: 22\n",
      "Train epoch : 22 loss : 1.0888995443071638 Acc : 41.666666666666664%\n",
      "\n",
      "Epoch: 22\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 22 loss : 1.334716002146403 Acc : 36.111111111111114%\n",
      "41.666666666666664\n",
      "\n",
      "Epoch: 23\n",
      "Train epoch : 23 loss : 1.0681589160646712 Acc : 43.51851851851852%\n",
      "\n",
      "Epoch: 23\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 23 loss : 1.314018964767456 Acc : 27.77777777777778%\n",
      "41.666666666666664\n",
      "\n",
      "Epoch: 24\n",
      "Train epoch : 24 loss : 1.0297776545797075 Acc : 44.44444444444444%\n",
      "\n",
      "Epoch: 24\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 24 loss : 1.5176835854848225 Acc : 22.22222222222222%\n",
      "41.666666666666664\n",
      "\n",
      "Epoch: 25\n",
      "Train epoch : 25 loss : 1.0211914266858781 Acc : 41.666666666666664%\n",
      "\n",
      "Epoch: 25\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 25 loss : 1.110421856244405 Acc : 44.44444444444444%\n",
      "44.44444444444444\n",
      "\n",
      "Epoch: 26\n",
      "Train epoch : 26 loss : 1.0250888126237052 Acc : 45.370370370370374%\n",
      "\n",
      "Epoch: 26\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 26 loss : 1.4809600909550984 Acc : 33.333333333333336%\n",
      "44.44444444444444\n",
      "\n",
      "Epoch: 27\n",
      "Train epoch : 27 loss : 1.0587485517774309 Acc : 41.666666666666664%\n",
      "\n",
      "Epoch: 27\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 27 loss : 1.2104036808013916 Acc : 33.333333333333336%\n",
      "44.44444444444444\n",
      "\n",
      "Epoch: 28\n",
      "Train epoch : 28 loss : 1.023060917854309 Acc : 47.22222222222222%\n",
      "\n",
      "Epoch: 28\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 28 loss : 1.1015243728955586 Acc : 36.111111111111114%\n",
      "44.44444444444444\n",
      "\n",
      "Epoch: 29\n",
      "Train epoch : 29 loss : 0.9916725754737854 Acc : 48.148148148148145%\n",
      "\n",
      "Epoch: 29\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 29 loss : 1.7859716812769573 Acc : 36.111111111111114%\n",
      "44.44444444444444\n",
      "\n",
      "Epoch: 30\n",
      "Train epoch : 30 loss : 1.0599772078650338 Acc : 49.074074074074076%\n",
      "\n",
      "Epoch: 30\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 30 loss : 1.6115155220031738 Acc : 36.111111111111114%\n",
      "44.44444444444444\n",
      "\n",
      "Epoch: 31\n",
      "Train epoch : 31 loss : 1.057109602860042 Acc : 44.44444444444444%\n",
      "\n",
      "Epoch: 31\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 31 loss : 1.2969918251037598 Acc : 30.555555555555557%\n",
      "44.44444444444444\n",
      "\n",
      "Epoch: 32\n",
      "Train epoch : 32 loss : 0.976260883467538 Acc : 52.77777777777778%\n",
      "\n",
      "Epoch: 32\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 32 loss : 1.6082163254419963 Acc : 38.888888888888886%\n",
      "44.44444444444444\n",
      "\n",
      "Epoch: 33\n",
      "Train epoch : 33 loss : 0.9940610272543771 Acc : 50.925925925925924%\n",
      "\n",
      "Epoch: 33\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 33 loss : 1.1956451336542766 Acc : 41.666666666666664%\n",
      "44.44444444444444\n",
      "\n",
      "Epoch: 34\n",
      "Train epoch : 34 loss : 0.9929210373333522 Acc : 42.592592592592595%\n",
      "\n",
      "Epoch: 34\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 34 loss : 1.0379369457562764 Acc : 44.44444444444444%\n",
      "44.44444444444444\n",
      "\n",
      "Epoch: 35\n",
      "Train epoch : 35 loss : 1.0428001369748796 Acc : 46.2962962962963%\n",
      "\n",
      "Epoch: 35\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 35 loss : 1.0509788592656453 Acc : 44.44444444444444%\n",
      "44.44444444444444\n",
      "\n",
      "Epoch: 36\n",
      "Train epoch : 36 loss : 0.873414899621691 Acc : 53.7037037037037%\n",
      "\n",
      "Epoch: 36\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 36 loss : 1.3249608278274536 Acc : 36.111111111111114%\n",
      "44.44444444444444\n",
      "\n",
      "Epoch: 37\n",
      "Train epoch : 37 loss : 1.0115695425442286 Acc : 43.51851851851852%\n",
      "\n",
      "Epoch: 37\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 37 loss : 0.9528030753135681 Acc : 47.22222222222222%\n",
      "47.22222222222222\n",
      "\n",
      "Epoch: 38\n",
      "Train epoch : 38 loss : 1.0012386441230774 Acc : 41.666666666666664%\n",
      "\n",
      "Epoch: 38\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 38 loss : 1.0005396008491516 Acc : 47.22222222222222%\n",
      "47.22222222222222\n",
      "\n",
      "Epoch: 39\n",
      "Train epoch : 39 loss : 0.9044082590511867 Acc : 52.77777777777778%\n",
      "\n",
      "Epoch: 39\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 39 loss : 1.2626066207885742 Acc : 36.111111111111114%\n",
      "47.22222222222222\n",
      "\n",
      "Epoch: 40\n",
      "Train epoch : 40 loss : 0.9218136412756783 Acc : 55.55555555555556%\n",
      "\n",
      "Epoch: 40\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 40 loss : 1.043451984723409 Acc : 47.22222222222222%\n",
      "47.22222222222222\n",
      "\n",
      "Epoch: 41\n",
      "Train epoch : 41 loss : 0.9358918837138585 Acc : 54.629629629629626%\n",
      "\n",
      "Epoch: 41\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 41 loss : 1.3407103617986043 Acc : 41.666666666666664%\n",
      "47.22222222222222\n",
      "\n",
      "Epoch: 42\n",
      "Train epoch : 42 loss : 0.9408633964402335 Acc : 52.77777777777778%\n",
      "\n",
      "Epoch: 42\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 42 loss : 0.9860514005025228 Acc : 58.333333333333336%\n",
      "58.333333333333336\n",
      "\n",
      "Epoch: 43\n",
      "Train epoch : 43 loss : 0.8795853342328753 Acc : 51.851851851851855%\n",
      "\n",
      "Epoch: 43\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 43 loss : 1.6197183926900227 Acc : 41.666666666666664%\n",
      "58.333333333333336\n",
      "\n",
      "Epoch: 44\n",
      "Train epoch : 44 loss : 0.9754586815834045 Acc : 50.925925925925924%\n",
      "\n",
      "Epoch: 44\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 44 loss : 1.0058054129282634 Acc : 38.888888888888886%\n",
      "58.333333333333336\n",
      "\n",
      "Epoch: 45\n",
      "Train epoch : 45 loss : 0.7944040894508362 Acc : 62.96296296296296%\n",
      "\n",
      "Epoch: 45\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 45 loss : 1.0152623057365417 Acc : 58.333333333333336%\n",
      "58.333333333333336\n",
      "\n",
      "Epoch: 46\n",
      "Train epoch : 46 loss : 0.8773365105901446 Acc : 61.111111111111114%\n",
      "\n",
      "Epoch: 46\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 46 loss : 1.0145268837610881 Acc : 52.77777777777778%\n",
      "58.333333333333336\n",
      "\n",
      "Epoch: 47\n",
      "Train epoch : 47 loss : 0.784772949559348 Acc : 64.81481481481481%\n",
      "\n",
      "Epoch: 47\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 47 loss : 0.9290511210759481 Acc : 55.55555555555556%\n",
      "58.333333333333336\n",
      "\n",
      "Epoch: 48\n",
      "Train epoch : 48 loss : 0.8709236894335065 Acc : 58.333333333333336%\n",
      "\n",
      "Epoch: 48\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 48 loss : 1.3885432879130046 Acc : 41.666666666666664%\n",
      "58.333333333333336\n",
      "\n",
      "Epoch: 49\n",
      "Train epoch : 49 loss : 0.8308697598321098 Acc : 63.888888888888886%\n",
      "\n",
      "Epoch: 49\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 49 loss : 7.266195138295491 Acc : 36.111111111111114%\n",
      "58.333333333333336\n",
      "\n",
      "Epoch: 50\n",
      "Train epoch : 50 loss : 0.974879937512534 Acc : 55.55555555555556%\n",
      "\n",
      "Epoch: 50\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 50 loss : 1.332147757212321 Acc : 36.111111111111114%\n",
      "58.333333333333336\n",
      "\n",
      "Epoch: 51\n",
      "Train epoch : 51 loss : 0.7448463099343436 Acc : 63.888888888888886%\n",
      "\n",
      "Epoch: 51\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 51 loss : 1.9616940816243489 Acc : 33.333333333333336%\n",
      "58.333333333333336\n",
      "\n",
      "Epoch: 52\n",
      "Train epoch : 52 loss : 0.8297637275287083 Acc : 53.7037037037037%\n",
      "\n",
      "Epoch: 52\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 52 loss : 1.0065401991208394 Acc : 44.44444444444444%\n",
      "58.333333333333336\n",
      "\n",
      "Epoch: 53\n",
      "Train epoch : 53 loss : 0.9019949947084699 Acc : 56.48148148148148%\n",
      "\n",
      "Epoch: 53\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 53 loss : 1.0436208645502727 Acc : 52.77777777777778%\n",
      "58.333333333333336\n",
      "\n",
      "Epoch: 54\n",
      "Train epoch : 54 loss : 0.7177332299096244 Acc : 67.5925925925926%\n",
      "\n",
      "Epoch: 54\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 54 loss : 0.9324323733647665 Acc : 52.77777777777778%\n",
      "58.333333333333336\n",
      "\n",
      "Epoch: 55\n",
      "Train epoch : 55 loss : 0.7484781316348484 Acc : 67.5925925925926%\n",
      "\n",
      "Epoch: 55\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 55 loss : 0.9996688241759936 Acc : 52.77777777777778%\n",
      "58.333333333333336\n",
      "\n",
      "Epoch: 56\n",
      "Train epoch : 56 loss : 0.8121352366038731 Acc : 55.55555555555556%\n",
      "\n",
      "Epoch: 56\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 56 loss : 0.962822953859965 Acc : 50.0%\n",
      "58.333333333333336\n",
      "\n",
      "Epoch: 57\n",
      "Train epoch : 57 loss : 0.6686178530965533 Acc : 67.5925925925926%\n",
      "\n",
      "Epoch: 57\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 57 loss : 1.2331983645757039 Acc : 55.55555555555556%\n",
      "58.333333333333336\n",
      "\n",
      "Epoch: 58\n",
      "Train epoch : 58 loss : 0.7641885876655579 Acc : 62.96296296296296%\n",
      "\n",
      "Epoch: 58\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 58 loss : 1.6903351942698162 Acc : 36.111111111111114%\n",
      "58.333333333333336\n",
      "\n",
      "Epoch: 59\n",
      "Train epoch : 59 loss : 0.7894522207123893 Acc : 55.55555555555556%\n",
      "\n",
      "Epoch: 59\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 59 loss : 0.8615585565567017 Acc : 47.22222222222222%\n",
      "58.333333333333336\n",
      "\n",
      "Epoch: 60\n",
      "Train epoch : 60 loss : 0.6540873306138175 Acc : 71.29629629629629%\n",
      "\n",
      "Epoch: 60\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 60 loss : 4.121447722117106 Acc : 36.111111111111114%\n",
      "58.333333333333336\n",
      "\n",
      "Epoch: 61\n",
      "Train epoch : 61 loss : 0.6745556167193821 Acc : 70.37037037037037%\n",
      "\n",
      "Epoch: 61\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 61 loss : 0.7435475091139475 Acc : 55.55555555555556%\n",
      "58.333333333333336\n",
      "\n",
      "Epoch: 62\n",
      "Train epoch : 62 loss : 0.5996983562197004 Acc : 75.0%\n",
      "\n",
      "Epoch: 62\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 62 loss : 2.291318337122599 Acc : 36.111111111111114%\n",
      "58.333333333333336\n",
      "\n",
      "Epoch: 63\n",
      "Train epoch : 63 loss : 0.8069484915052142 Acc : 62.03703703703704%\n",
      "\n",
      "Epoch: 63\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 63 loss : 10.987942934036255 Acc : 36.111111111111114%\n",
      "58.333333333333336\n",
      "\n",
      "Epoch: 64\n",
      "Train epoch : 64 loss : 0.805295501436506 Acc : 67.5925925925926%\n",
      "\n",
      "Epoch: 64\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 64 loss : 1.325186292330424 Acc : 52.77777777777778%\n",
      "58.333333333333336\n",
      "\n",
      "Epoch: 65\n",
      "Train epoch : 65 loss : 0.6626043915748596 Acc : 67.5925925925926%\n",
      "\n",
      "Epoch: 65\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 65 loss : 1.3516754110654194 Acc : 50.0%\n",
      "58.333333333333336\n",
      "\n",
      "Epoch: 66\n",
      "Train epoch : 66 loss : 0.7279197318213326 Acc : 67.5925925925926%\n",
      "\n",
      "Epoch: 66\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 66 loss : 1.285471240679423 Acc : 50.0%\n",
      "58.333333333333336\n",
      "\n",
      "Epoch: 67\n",
      "Train epoch : 67 loss : 0.6890575630324227 Acc : 65.74074074074075%\n",
      "\n",
      "Epoch: 67\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 67 loss : 8.978567918141684 Acc : 36.111111111111114%\n",
      "58.333333333333336\n",
      "\n",
      "Epoch: 68\n",
      "Train epoch : 68 loss : 0.6319567731448582 Acc : 74.07407407407408%\n",
      "\n",
      "Epoch: 68\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 68 loss : 0.7892389496167501 Acc : 44.44444444444444%\n",
      "58.333333333333336\n",
      "\n",
      "Epoch: 69\n",
      "Train epoch : 69 loss : 0.6950876755373818 Acc : 68.51851851851852%\n",
      "\n",
      "Epoch: 69\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 69 loss : 0.8863644599914551 Acc : 63.888888888888886%\n",
      "63.888888888888886\n",
      "\n",
      "Epoch: 70\n",
      "Train epoch : 70 loss : 0.7047633315835681 Acc : 65.74074074074075%\n",
      "\n",
      "Epoch: 70\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 70 loss : 0.7059527238210043 Acc : 63.888888888888886%\n",
      "63.888888888888886\n",
      "\n",
      "Epoch: 71\n",
      "Train epoch : 71 loss : 0.5913972982338497 Acc : 75.0%\n",
      "\n",
      "Epoch: 71\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 71 loss : 1.3904629349708557 Acc : 47.22222222222222%\n",
      "63.888888888888886\n",
      "\n",
      "Epoch: 72\n",
      "Train epoch : 72 loss : 0.707177358014243 Acc : 67.5925925925926%\n",
      "\n",
      "Epoch: 72\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 72 loss : 2.1646531025568643 Acc : 30.555555555555557%\n",
      "63.888888888888886\n",
      "\n",
      "Epoch: 73\n",
      "Train epoch : 73 loss : 1.1248965178217207 Acc : 45.370370370370374%\n",
      "\n",
      "Epoch: 73\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 73 loss : 1.318017065525055 Acc : 38.888888888888886%\n",
      "63.888888888888886\n",
      "\n",
      "Epoch: 74\n",
      "Train epoch : 74 loss : 0.7294718027114868 Acc : 65.74074074074075%\n",
      "\n",
      "Epoch: 74\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 74 loss : 0.630594328045845 Acc : 63.888888888888886%\n",
      "63.888888888888886\n",
      "\n",
      "Epoch: 75\n",
      "Train epoch : 75 loss : 0.7120130317551749 Acc : 63.888888888888886%\n",
      "\n",
      "Epoch: 75\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 75 loss : 0.7525004545847574 Acc : 52.77777777777778%\n",
      "63.888888888888886\n",
      "\n",
      "Epoch: 76\n",
      "Train epoch : 76 loss : 0.6767323357718331 Acc : 71.29629629629629%\n",
      "\n",
      "Epoch: 76\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 76 loss : 0.9979573686917623 Acc : 47.22222222222222%\n",
      "63.888888888888886\n",
      "\n",
      "Epoch: 77\n",
      "Train epoch : 77 loss : 0.6513102012021201 Acc : 71.29629629629629%\n",
      "\n",
      "Epoch: 77\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 77 loss : 0.9162767926851908 Acc : 47.22222222222222%\n",
      "63.888888888888886\n",
      "\n",
      "Epoch: 78\n",
      "Train epoch : 78 loss : 0.6642704861504691 Acc : 71.29629629629629%\n",
      "\n",
      "Epoch: 78\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 78 loss : 0.8909691770871481 Acc : 55.55555555555556%\n",
      "63.888888888888886\n",
      "\n",
      "Epoch: 79\n",
      "Train epoch : 79 loss : 0.615179751600538 Acc : 75.92592592592592%\n",
      "\n",
      "Epoch: 79\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 79 loss : 0.7076794505119324 Acc : 66.66666666666667%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 80\n",
      "Train epoch : 80 loss : 0.5491124902452741 Acc : 76.85185185185185%\n",
      "\n",
      "Epoch: 80\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 80 loss : 0.9085596005121866 Acc : 61.111111111111114%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 81\n",
      "Train epoch : 81 loss : 0.5761504173278809 Acc : 75.0%\n",
      "\n",
      "Epoch: 81\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 81 loss : 0.8747259378433228 Acc : 55.55555555555556%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 82\n",
      "Train epoch : 82 loss : 0.49393890159470694 Acc : 82.4074074074074%\n",
      "\n",
      "Epoch: 82\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 82 loss : 1.0028920769691467 Acc : 52.77777777777778%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 83\n",
      "Train epoch : 83 loss : 0.5309529559952872 Acc : 80.55555555555556%\n",
      "\n",
      "Epoch: 83\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 83 loss : 1.3060376048088074 Acc : 55.55555555555556%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 84\n",
      "Train epoch : 84 loss : 0.5211375270571027 Acc : 78.70370370370371%\n",
      "\n",
      "Epoch: 84\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 84 loss : 0.911881705125173 Acc : 61.111111111111114%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 85\n",
      "Train epoch : 85 loss : 0.5948942218508039 Acc : 74.07407407407408%\n",
      "\n",
      "Epoch: 85\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 85 loss : 1.27151620388031 Acc : 50.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 86\n",
      "Train epoch : 86 loss : 0.4469493201800755 Acc : 85.18518518518519%\n",
      "\n",
      "Epoch: 86\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 86 loss : 0.8570796648661295 Acc : 58.333333333333336%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 87\n",
      "Train epoch : 87 loss : 0.47755807638168335 Acc : 79.62962962962963%\n",
      "\n",
      "Epoch: 87\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 87 loss : 0.8188013434410095 Acc : 66.66666666666667%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 88\n",
      "Train epoch : 88 loss : 0.518435959305082 Acc : 74.07407407407408%\n",
      "\n",
      "Epoch: 88\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 88 loss : 1.070196509361267 Acc : 55.55555555555556%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 89\n",
      "Train epoch : 89 loss : 0.40694732325417654 Acc : 85.18518518518519%\n",
      "\n",
      "Epoch: 89\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 89 loss : 0.3901444474856059 Acc : 75.0%\n",
      "75.0\n",
      "\n",
      "Epoch: 90\n",
      "Train epoch : 90 loss : 0.5223597373281207 Acc : 79.62962962962963%\n",
      "\n",
      "Epoch: 90\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 90 loss : 0.7187667389710745 Acc : 58.333333333333336%\n",
      "75.0\n",
      "\n",
      "Epoch: 91\n",
      "Train epoch : 91 loss : 0.4462132155895233 Acc : 83.33333333333333%\n",
      "\n",
      "Epoch: 91\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 91 loss : 1.302575131257375 Acc : 50.0%\n",
      "75.0\n",
      "\n",
      "Epoch: 92\n",
      "Train epoch : 92 loss : 0.479436810527529 Acc : 76.85185185185185%\n",
      "\n",
      "Epoch: 92\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 92 loss : 2.4159242312113443 Acc : 33.333333333333336%\n",
      "75.0\n",
      "\n",
      "Epoch: 93\n",
      "Train epoch : 93 loss : 0.6379336033548627 Acc : 69.44444444444444%\n",
      "\n",
      "Epoch: 93\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 93 loss : 1.7910778125127156 Acc : 44.44444444444444%\n",
      "75.0\n",
      "\n",
      "Epoch: 94\n",
      "Train epoch : 94 loss : 0.8124074169567653 Acc : 60.18518518518518%\n",
      "\n",
      "Epoch: 94\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 94 loss : 2.190071781476339 Acc : 47.22222222222222%\n",
      "75.0\n",
      "\n",
      "Epoch: 95\n",
      "Train epoch : 95 loss : 0.46886674421174185 Acc : 85.18518518518519%\n",
      "\n",
      "Epoch: 95\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 95 loss : 1.7102823654810588 Acc : 47.22222222222222%\n",
      "75.0\n",
      "\n",
      "Epoch: 96\n",
      "Train epoch : 96 loss : 0.44512071779796053 Acc : 84.25925925925925%\n",
      "\n",
      "Epoch: 96\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 96 loss : 1.5251521269480388 Acc : 58.333333333333336%\n",
      "75.0\n",
      "\n",
      "Epoch: 97\n",
      "Train epoch : 97 loss : 0.48155226026262554 Acc : 79.62962962962963%\n",
      "\n",
      "Epoch: 97\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 97 loss : 1.7596826553344727 Acc : 50.0%\n",
      "75.0\n",
      "\n",
      "Epoch: 98\n",
      "Train epoch : 98 loss : 0.4337855279445648 Acc : 87.96296296296296%\n",
      "\n",
      "Epoch: 98\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 98 loss : 1.3869483868281047 Acc : 44.44444444444444%\n",
      "75.0\n",
      "\n",
      "Epoch: 99\n",
      "Train epoch : 99 loss : 0.5120721970285688 Acc : 76.85185185185185%\n",
      "\n",
      "Epoch: 99\n",
      "{0: 11, 1: 12, 2: 13}\n",
      "Test epoch : 99 loss : 0.5926973720391592 Acc : 77.77777777777777%\n",
      "77.77777777777777\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 및 평가\n",
    "BEST_SCORE = 0\n",
    "for epoch in range(epochs):\n",
    "    train(epoch)\n",
    "    test(epoch, valloader)\n",
    "    print(BEST_SCORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: -1\n",
      "{0: 13, 1: 11, 2: 12}\n",
      "Test epoch : -1 loss : 0.6049990256627401 Acc : 69.44444444444444%\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋에서 평가\n",
    "model.load_state_dict(torch.load(os.path.join(save_path, f'teacher.pth')))\n",
    "test(-1, testloader, 'test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fskd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

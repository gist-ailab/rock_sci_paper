{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colab에서 드라이브 내 폴더 사용 위해 마운트\n",
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폴더까지의 경로\n",
    "# cd '/content/drive/MyDrive/GSA_Creative_Resarch/rock_sci_paper'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폴더 이동 확인\n",
    "# ! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\fskd\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#필요한 라이브러리들 import\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import dataset\n",
    "import model\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각종 path및 하이퍼 파라미터 설정\n",
    "data_path = 'C:\\\\Users\\\\USER\\\\Desktop\\\\GSH_CRP\\\\codes\\\\rock_sci_paper\\\\data\\\\ro_sci_pa_heo'\n",
    "save_path = 'C:\\\\Users\\\\USER\\\\Desktop\\\\GSH_CRP\\\\codes\\\\rock_sci_paper\\\\model_para'\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "learning_rate = 0.01\n",
    "seed = 0\n",
    "mode = 'lr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 설정\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# device 설정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform 설정\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomAffine((-45, 45), translate=(0.2,0.2)),\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ColorJitter(brightness=0.5),\n",
    "    transforms.ColorJitter(contrast=0.5),\n",
    "    transforms.ColorJitter(saturation=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]\n",
    ")\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n",
      "30\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "# dataset 설정\n",
    "train_dataset = dataset.RockScissorsPaper(\n",
    "    transform=train_transform,\n",
    "    path = data_path,\n",
    "    mode = 'train'\n",
    ")\n",
    "val_dataset = dataset.RockScissorsPaper(\n",
    "    transform=test_transform,\n",
    "    path = data_path,\n",
    "    mode = 'val'\n",
    ")\n",
    "test_dataset = dataset.RockScissorsPaper(\n",
    "    transform=test_transform,\n",
    "    path = data_path,\n",
    "    mode = 'test'\n",
    ")\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader 설정\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델, 손실함수, 옵티마이저 설정\n",
    "model = model.ResNet18(num_classes=3)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    print('\\nEpoch: %d'%epoch)\n",
    "    # model train mode로 전환\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    total = 0\n",
    "    for (inputs, labels) in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if mode=='lr':\n",
    "            h,w = inputs.shape[-2], inputs.shape[-1]\n",
    "            lr_inputs = F.interpolate(inputs, (h//8, w//8))\n",
    "            lr_inputs = F.interpolate(lr_inputs, (h,w))\n",
    "            outputs, _, _, _, _ = model(lr_inputs)\n",
    "        else:\n",
    "            outputs, _, _, _, _ = model(inputs)\n",
    "            \n",
    "        _, pred = torch.max(outputs, 1)\n",
    "        total += outputs.size(0)\n",
    "        running_acc += (pred == labels).sum().item()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    total_loss = running_loss / len(trainloader)\n",
    "    total_acc = 100 * running_acc / total\n",
    "    print(f'Train epoch : {epoch} loss : {total_loss} Acc : {total_acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, loader, mode='val', mode2=False):\n",
    "    print('\\nEpoch: %d'%epoch)\n",
    "    # model eval mode로 전환\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    total = 0\n",
    "    label_dict = {0:0, 1:0, 2:0}\n",
    "    correct_dict = {0:0, 1:0, 2:0}\n",
    "    global BEST_SCORE\n",
    "    with torch.no_grad():\n",
    "        for (inputs, labels) in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            if mode=='lr':\n",
    "                h,w = inputs.shape[-2], inputs.shape[-1]\n",
    "                lr_inputs = F.interpolate(inputs, (h//8, w//8))\n",
    "                lr_inputs = F.interpolate(lr_inputs, (h,w))\n",
    "                outputs, _, _, _, _ = model(lr_inputs)\n",
    "            else:\n",
    "                outputs, _, _, _, _ = model(inputs)\n",
    "\n",
    "            _, pred = torch.max(outputs, 1)\n",
    "            \n",
    "            total += outputs.size(0)\n",
    "            running_acc += (pred == labels).sum().item()\n",
    "            \n",
    "            if mode2:\n",
    "                for i in range(len(labels)):\n",
    "                    label = labels[i]\n",
    "                    label_dict[label.item()] += 1\n",
    "                    if (pred==labels)[i]:\n",
    "                        correct_dict[label.item()] += 1\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "        total_loss = running_loss / len(loader)\n",
    "        total_acc = 100 * running_acc / total\n",
    "        if mode2:\n",
    "            print(label_dict)\n",
    "            print(correct_dict)\n",
    "        if total_acc >= BEST_SCORE and not mode=='test':\n",
    "            path = os.path.join(save_path, f'lr_teacher.pth')\n",
    "            torch.save(model.state_dict(), path)\n",
    "            BEST_SCORE = total_acc\n",
    "        print(f'Test epoch : {epoch} loss : {total_loss} Acc : {total_acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "Train epoch : 0 loss : 1.231787101427714 Acc : 36.25%\n",
      "\n",
      "Epoch: 0\n",
      "Test epoch : 0 loss : 1.1886222958564758 Acc : 30.0%\n",
      "30.0\n",
      "\n",
      "Epoch: 1\n",
      "Train epoch : 1 loss : 1.2473631024360656 Acc : 32.5%\n",
      "\n",
      "Epoch: 1\n",
      "Test epoch : 1 loss : 1.1490331888198853 Acc : 30.0%\n",
      "30.0\n",
      "\n",
      "Epoch: 2\n",
      "Train epoch : 2 loss : 1.2114893515904746 Acc : 25.416666666666668%\n",
      "\n",
      "Epoch: 2\n",
      "Test epoch : 2 loss : 1.2050803899765015 Acc : 23.333333333333332%\n",
      "30.0\n",
      "\n",
      "Epoch: 3\n",
      "Train epoch : 3 loss : 1.1644933899243672 Acc : 35.833333333333336%\n",
      "\n",
      "Epoch: 3\n",
      "Test epoch : 3 loss : 1.0993612408638 Acc : 43.333333333333336%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 4\n",
      "Train epoch : 4 loss : 1.1653952201207478 Acc : 34.583333333333336%\n",
      "\n",
      "Epoch: 4\n",
      "Test epoch : 4 loss : 1.1464014053344727 Acc : 23.333333333333332%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 5\n",
      "Train epoch : 5 loss : 1.1283426841100057 Acc : 35.416666666666664%\n",
      "\n",
      "Epoch: 5\n",
      "Test epoch : 5 loss : 1.48000830411911 Acc : 30.0%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 6\n",
      "Train epoch : 6 loss : 1.1504948059717814 Acc : 31.666666666666668%\n",
      "\n",
      "Epoch: 6\n",
      "Test epoch : 6 loss : 1.4211667776107788 Acc : 26.666666666666668%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 7\n",
      "Train epoch : 7 loss : 1.1492552359898884 Acc : 32.5%\n",
      "\n",
      "Epoch: 7\n",
      "Test epoch : 7 loss : 1.1574895977973938 Acc : 30.0%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 8\n",
      "Train epoch : 8 loss : 1.1709171374638876 Acc : 30.416666666666668%\n",
      "\n",
      "Epoch: 8\n",
      "Test epoch : 8 loss : 1.130200207233429 Acc : 26.666666666666668%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 9\n",
      "Train epoch : 9 loss : 1.1927813768386841 Acc : 28.333333333333332%\n",
      "\n",
      "Epoch: 9\n",
      "Test epoch : 9 loss : 1.0926486253738403 Acc : 43.333333333333336%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 10\n",
      "Train epoch : 10 loss : 1.1448671658833822 Acc : 32.5%\n",
      "\n",
      "Epoch: 10\n",
      "Test epoch : 10 loss : 1.0826117992401123 Acc : 43.333333333333336%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 11\n",
      "Train epoch : 11 loss : 1.1423500061035157 Acc : 29.166666666666668%\n",
      "\n",
      "Epoch: 11\n",
      "Test epoch : 11 loss : 1.1395723819732666 Acc : 43.333333333333336%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 12\n",
      "Train epoch : 12 loss : 1.1382253567377727 Acc : 37.083333333333336%\n",
      "\n",
      "Epoch: 12\n",
      "Test epoch : 12 loss : 1.120351493358612 Acc : 30.0%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 13\n",
      "Train epoch : 13 loss : 1.1570161739985148 Acc : 34.583333333333336%\n",
      "\n",
      "Epoch: 13\n",
      "Test epoch : 13 loss : 1.184950053691864 Acc : 30.0%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 14\n",
      "Train epoch : 14 loss : 1.1332754611968994 Acc : 37.5%\n",
      "\n",
      "Epoch: 14\n",
      "Test epoch : 14 loss : 1.2044076323509216 Acc : 26.666666666666668%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 15\n",
      "Train epoch : 15 loss : 1.1114940722783406 Acc : 35.416666666666664%\n",
      "\n",
      "Epoch: 15\n",
      "Test epoch : 15 loss : 1.0893818140029907 Acc : 46.666666666666664%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 16\n",
      "Train epoch : 16 loss : 1.138213324546814 Acc : 34.166666666666664%\n",
      "\n",
      "Epoch: 16\n",
      "Test epoch : 16 loss : 1.2435532808303833 Acc : 26.666666666666668%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 17\n",
      "Train epoch : 17 loss : 1.147093931833903 Acc : 29.166666666666668%\n",
      "\n",
      "Epoch: 17\n",
      "Test epoch : 17 loss : 1.0931308269500732 Acc : 43.333333333333336%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 18\n",
      "Train epoch : 18 loss : 1.1375801801681518 Acc : 36.666666666666664%\n",
      "\n",
      "Epoch: 18\n",
      "Test epoch : 18 loss : 1.105241596698761 Acc : 30.0%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 19\n",
      "Train epoch : 19 loss : 1.1256504615147909 Acc : 31.666666666666668%\n",
      "\n",
      "Epoch: 19\n",
      "Test epoch : 19 loss : 1.0850488543510437 Acc : 43.333333333333336%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 20\n",
      "Train epoch : 20 loss : 1.121941081682841 Acc : 35.416666666666664%\n",
      "\n",
      "Epoch: 20\n",
      "Test epoch : 20 loss : 1.1421896815299988 Acc : 30.0%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 21\n",
      "Train epoch : 21 loss : 1.1258668581644693 Acc : 32.916666666666664%\n",
      "\n",
      "Epoch: 21\n",
      "Test epoch : 21 loss : 1.07564115524292 Acc : 43.333333333333336%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 22\n",
      "Train epoch : 22 loss : 1.161290717124939 Acc : 33.75%\n",
      "\n",
      "Epoch: 22\n",
      "Test epoch : 22 loss : 1.1429933905601501 Acc : 26.666666666666668%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 23\n",
      "Train epoch : 23 loss : 1.140292239189148 Acc : 31.25%\n",
      "\n",
      "Epoch: 23\n",
      "Test epoch : 23 loss : 1.1771606802940369 Acc : 26.666666666666668%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 24\n",
      "Train epoch : 24 loss : 1.1356693903605144 Acc : 35.0%\n",
      "\n",
      "Epoch: 24\n",
      "Test epoch : 24 loss : 1.0903161764144897 Acc : 40.0%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 25\n",
      "Train epoch : 25 loss : 1.1300894737243652 Acc : 32.083333333333336%\n",
      "\n",
      "Epoch: 25\n",
      "Test epoch : 25 loss : 1.1132398843765259 Acc : 30.0%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 26\n",
      "Train epoch : 26 loss : 1.1236951351165771 Acc : 32.916666666666664%\n",
      "\n",
      "Epoch: 26\n",
      "Test epoch : 26 loss : 1.111480176448822 Acc : 23.333333333333332%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 27\n",
      "Train epoch : 27 loss : 1.1449631293614706 Acc : 31.666666666666668%\n",
      "\n",
      "Epoch: 27\n",
      "Test epoch : 27 loss : 1.0940661430358887 Acc : 30.0%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 28\n",
      "Train epoch : 28 loss : 1.131080436706543 Acc : 34.166666666666664%\n",
      "\n",
      "Epoch: 28\n",
      "Test epoch : 28 loss : 1.141408622264862 Acc : 30.0%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 29\n",
      "Train epoch : 29 loss : 1.1326133330663046 Acc : 29.583333333333332%\n",
      "\n",
      "Epoch: 29\n",
      "Test epoch : 29 loss : 1.1197497248649597 Acc : 26.666666666666668%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 30\n",
      "Train epoch : 30 loss : 1.1495400587717692 Acc : 26.666666666666668%\n",
      "\n",
      "Epoch: 30\n",
      "Test epoch : 30 loss : 1.1030794382095337 Acc : 30.0%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 31\n",
      "Train epoch : 31 loss : 1.1229576031366983 Acc : 34.583333333333336%\n",
      "\n",
      "Epoch: 31\n",
      "Test epoch : 31 loss : 1.125124454498291 Acc : 30.0%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 32\n",
      "Train epoch : 32 loss : 1.1324069341023764 Acc : 32.5%\n",
      "\n",
      "Epoch: 32\n",
      "Test epoch : 32 loss : 1.0857636332511902 Acc : 43.333333333333336%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 33\n",
      "Train epoch : 33 loss : 1.1507444302241008 Acc : 25.0%\n",
      "\n",
      "Epoch: 33\n",
      "Test epoch : 33 loss : 1.1265344619750977 Acc : 26.666666666666668%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 34\n",
      "Train epoch : 34 loss : 1.1378953019777933 Acc : 33.333333333333336%\n",
      "\n",
      "Epoch: 34\n",
      "Test epoch : 34 loss : 1.0802506804466248 Acc : 43.333333333333336%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 35\n",
      "Train epoch : 35 loss : 1.121190857887268 Acc : 33.333333333333336%\n",
      "\n",
      "Epoch: 35\n",
      "Test epoch : 35 loss : 1.1015048623085022 Acc : 30.0%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 36\n",
      "Train epoch : 36 loss : 1.1144724369049073 Acc : 35.833333333333336%\n",
      "\n",
      "Epoch: 36\n",
      "Test epoch : 36 loss : 1.1093012690544128 Acc : 30.0%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 37\n",
      "Train epoch : 37 loss : 1.1279955784479776 Acc : 30.833333333333332%\n",
      "\n",
      "Epoch: 37\n",
      "Test epoch : 37 loss : 1.1373202800750732 Acc : 30.0%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 38\n",
      "Train epoch : 38 loss : 1.1302072445551554 Acc : 31.25%\n",
      "\n",
      "Epoch: 38\n",
      "Test epoch : 38 loss : 1.07539701461792 Acc : 43.333333333333336%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 39\n",
      "Train epoch : 39 loss : 1.124153208732605 Acc : 32.083333333333336%\n",
      "\n",
      "Epoch: 39\n",
      "Test epoch : 39 loss : 1.1374564170837402 Acc : 26.666666666666668%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 40\n",
      "Train epoch : 40 loss : 1.1120766003926594 Acc : 31.25%\n",
      "\n",
      "Epoch: 40\n",
      "Test epoch : 40 loss : 1.069801390171051 Acc : 43.333333333333336%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 41\n",
      "Train epoch : 41 loss : 1.1352649370829264 Acc : 34.166666666666664%\n",
      "\n",
      "Epoch: 41\n",
      "Test epoch : 41 loss : 1.081858515739441 Acc : 30.0%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 42\n",
      "Train epoch : 42 loss : 1.1175909121831258 Acc : 31.666666666666668%\n",
      "\n",
      "Epoch: 42\n",
      "Test epoch : 42 loss : 1.0630569458007812 Acc : 43.333333333333336%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 43\n",
      "Train epoch : 43 loss : 1.116664743423462 Acc : 34.166666666666664%\n",
      "\n",
      "Epoch: 43\n",
      "Test epoch : 43 loss : 1.103288173675537 Acc : 26.666666666666668%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 44\n",
      "Train epoch : 44 loss : 1.1104215701421103 Acc : 37.083333333333336%\n",
      "\n",
      "Epoch: 44\n",
      "Test epoch : 44 loss : 1.0990484356880188 Acc : 30.0%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 45\n",
      "Train epoch : 45 loss : 1.1108574390411377 Acc : 36.25%\n",
      "\n",
      "Epoch: 45\n",
      "Test epoch : 45 loss : 1.0885310173034668 Acc : 30.0%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 46\n",
      "Train epoch : 46 loss : 1.1136699755986532 Acc : 36.25%\n",
      "\n",
      "Epoch: 46\n",
      "Test epoch : 46 loss : 1.1449002623558044 Acc : 30.0%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 47\n",
      "Train epoch : 47 loss : 1.109187904993693 Acc : 33.333333333333336%\n",
      "\n",
      "Epoch: 47\n",
      "Test epoch : 47 loss : 1.0911368131637573 Acc : 30.0%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 48\n",
      "Train epoch : 48 loss : 1.1137625773747761 Acc : 35.833333333333336%\n",
      "\n",
      "Epoch: 48\n",
      "Test epoch : 48 loss : 1.0681630373001099 Acc : 40.0%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 49\n",
      "Train epoch : 49 loss : 1.105974555015564 Acc : 35.0%\n",
      "\n",
      "Epoch: 49\n",
      "Test epoch : 49 loss : 1.0900415182113647 Acc : 33.333333333333336%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 50\n",
      "Train epoch : 50 loss : 1.092558201154073 Acc : 34.583333333333336%\n",
      "\n",
      "Epoch: 50\n",
      "Test epoch : 50 loss : 1.0473029911518097 Acc : 43.333333333333336%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 51\n",
      "Train epoch : 51 loss : 1.1014197667439778 Acc : 39.166666666666664%\n",
      "\n",
      "Epoch: 51\n",
      "Test epoch : 51 loss : 1.0645942091941833 Acc : 46.666666666666664%\n",
      "46.666666666666664\n",
      "\n",
      "Epoch: 52\n",
      "Train epoch : 52 loss : 1.0966722170511882 Acc : 36.25%\n",
      "\n",
      "Epoch: 52\n",
      "Test epoch : 52 loss : 0.986240953207016 Acc : 56.666666666666664%\n",
      "56.666666666666664\n",
      "\n",
      "Epoch: 53\n",
      "Train epoch : 53 loss : 1.0854228019714356 Acc : 37.5%\n",
      "\n",
      "Epoch: 53\n",
      "Test epoch : 53 loss : 0.9529317021369934 Acc : 50.0%\n",
      "56.666666666666664\n",
      "\n",
      "Epoch: 54\n",
      "Train epoch : 54 loss : 1.1143203735351563 Acc : 35.416666666666664%\n",
      "\n",
      "Epoch: 54\n",
      "Test epoch : 54 loss : 0.9635519087314606 Acc : 53.333333333333336%\n",
      "56.666666666666664\n",
      "\n",
      "Epoch: 55\n",
      "Train epoch : 55 loss : 1.0485127886136374 Acc : 46.25%\n",
      "\n",
      "Epoch: 55\n",
      "Test epoch : 55 loss : 1.0909501314163208 Acc : 36.666666666666664%\n",
      "56.666666666666664\n",
      "\n",
      "Epoch: 56\n",
      "Train epoch : 56 loss : 1.0884992718696593 Acc : 37.5%\n",
      "\n",
      "Epoch: 56\n",
      "Test epoch : 56 loss : 0.9998146593570709 Acc : 50.0%\n",
      "56.666666666666664\n",
      "\n",
      "Epoch: 57\n",
      "Train epoch : 57 loss : 1.110863196849823 Acc : 36.25%\n",
      "\n",
      "Epoch: 57\n",
      "Test epoch : 57 loss : 1.0362257957458496 Acc : 40.0%\n",
      "56.666666666666664\n",
      "\n",
      "Epoch: 58\n",
      "Train epoch : 58 loss : 1.081408945719401 Acc : 36.666666666666664%\n",
      "\n",
      "Epoch: 58\n",
      "Test epoch : 58 loss : 0.9697529375553131 Acc : 60.0%\n",
      "60.0\n",
      "\n",
      "Epoch: 59\n",
      "Train epoch : 59 loss : 1.074083403746287 Acc : 40.833333333333336%\n",
      "\n",
      "Epoch: 59\n",
      "Test epoch : 59 loss : 1.07583487033844 Acc : 26.666666666666668%\n",
      "60.0\n",
      "\n",
      "Epoch: 60\n",
      "Train epoch : 60 loss : 1.082837208112081 Acc : 39.166666666666664%\n",
      "\n",
      "Epoch: 60\n",
      "Test epoch : 60 loss : 1.0400766730308533 Acc : 36.666666666666664%\n",
      "60.0\n",
      "\n",
      "Epoch: 61\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 및 평가\n",
    "BEST_SCORE = 0\n",
    "for epoch in range(epochs):\n",
    "    train(epoch)\n",
    "    test(epoch, valloader)\n",
    "    print(BEST_SCORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트셋에서 평가\n",
    "model.load_state_dict(torch.load(os.path.join(save_path, f'lr_teacher.pth')))\n",
    "test(-1, testloader, 'test', True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "run",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb50cdd79c86e8dce50f207c8be5ca838005251520472ce9347018b25221847d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

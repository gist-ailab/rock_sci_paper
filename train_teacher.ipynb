{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\fskd\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#필요한 라이브러리들 import\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import dataset\n",
    "import model\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각종 path및 하이퍼 파라미터 설정\n",
    "data_path = 'C:\\\\Users\\\\USER\\\\Desktop\\\\GSH_CRP\\\\codes\\\\rock_sci_paper\\\\data\\\\ro_sci_pa_heo'\n",
    "save_path = 'C:\\\\Users\\\\USER\\\\Desktop\\\\GSH_CRP\\\\codes\\\\rock_sci_paper\\\\model_para'\n",
    "epochs = 200\n",
    "batch_size = 16\n",
    "learning_rate = 0.01\n",
    "seed = 0\n",
    "mode = 'hr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 설정\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# device 설정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform 설정\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomAffine((-45, 45), translate=(0.2,0.2)),\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ColorJitter(brightness=0.5),\n",
    "    transforms.ColorJitter(contrast=0.5),\n",
    "    transforms.ColorJitter(saturation=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]\n",
    ")\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n",
      "30\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "# dataset 설정\n",
    "train_dataset = dataset.RockScissorsPaper(\n",
    "    transform=train_transform,\n",
    "    path = data_path,\n",
    "    mode = 'train'\n",
    ")\n",
    "val_dataset = dataset.RockScissorsPaper(\n",
    "    transform=test_transform,\n",
    "    path = data_path,\n",
    "    mode = 'val'\n",
    ")\n",
    "test_dataset = dataset.RockScissorsPaper(\n",
    "    transform=test_transform,\n",
    "    path = data_path,\n",
    "    mode = 'test'\n",
    ")\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader 설정\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델, 손실함수, 옵티마이저 설정\n",
    "model = model.ResNet18(num_classes=3)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    print('\\nEpoch: %d'%epoch)\n",
    "    # model train mode로 전환\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    total = 0\n",
    "    for (inputs, labels) in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if mode=='lr':\n",
    "            h,w = inputs.shape[-2], inputs.shape[-1]\n",
    "            lr_inputs = F.interpolate(inputs, (h//64, w//64))\n",
    "            lr_inputs = F.interpolate(lr_inputs, (h,w))\n",
    "            outputs, _, _, _, _ = model(lr_inputs)\n",
    "        else:\n",
    "            outputs, _, _, _, _ = model(inputs)\n",
    "            \n",
    "        _, pred = torch.max(outputs, 1)\n",
    "        total += outputs.size(0)\n",
    "        running_acc += (pred == labels).sum().item()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    total_loss = running_loss / len(trainloader)\n",
    "    total_acc = 100 * running_acc / total\n",
    "    print(f'Train epoch : {epoch} loss : {total_loss} Acc : {total_acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, loader, mode='val'):\n",
    "    print('\\nEpoch: %d'%epoch)\n",
    "    # model eval mode로 전환\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    total = 0\n",
    "    label_dict = {0:0, 1:0, 2:0}\n",
    "    correct_dict = {0:0, 1:0, 2:0}\n",
    "    global BEST_SCORE\n",
    "    with torch.no_grad():\n",
    "        for (inputs, labels) in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            if mode=='lr':\n",
    "                h,w = inputs.shape[-2], inputs.shape[-1]\n",
    "                lr_inputs = F.interpolate(inputs, (h//32, w//32))\n",
    "                lr_inputs = F.interpolate(lr_inputs, (h,w))\n",
    "                outputs, _, _, _, _ = model(lr_inputs)\n",
    "            else:\n",
    "                outputs, _, _, _, _ = model(inputs)\n",
    "\n",
    "            _, pred = torch.max(outputs, 1)\n",
    "            \n",
    "            total += outputs.size(0)\n",
    "            running_acc += (pred == labels).sum().item()\n",
    "            \n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                label_dict[label.item()] += 1\n",
    "                if (pred==labels)[i]:\n",
    "                    correct_dict[label.item()] += 1\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "        total_loss = running_loss / len(loader)\n",
    "        total_acc = 100 * running_acc / total\n",
    "        print(label_dict)\n",
    "        print(correct_dict)\n",
    "        if total_acc >= BEST_SCORE and not mode=='test':\n",
    "            path = os.path.join(save_path, f'teacher.pth')\n",
    "            torch.save(model.state_dict(), path)\n",
    "            BEST_SCORE = total_acc\n",
    "        print(f'Test epoch : {epoch} loss : {total_loss} Acc : {total_acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "Train epoch : 0 loss : 1.2237079938252766 Acc : 35.833333333333336%\n",
      "\n",
      "Epoch: 0\n",
      "Test epoch : 0 loss : 1.1918408274650574 Acc : 30.0%\n",
      "30.0\n",
      "\n",
      "Epoch: 1\n",
      "Train epoch : 1 loss : 1.243686596552531 Acc : 32.916666666666664%\n",
      "\n",
      "Epoch: 1\n",
      "Test epoch : 1 loss : 1.1351213455200195 Acc : 30.0%\n",
      "30.0\n",
      "\n",
      "Epoch: 2\n",
      "Train epoch : 2 loss : 1.2130223989486695 Acc : 25.416666666666668%\n",
      "\n",
      "Epoch: 2\n",
      "Test epoch : 2 loss : 1.1990269422531128 Acc : 26.666666666666668%\n",
      "30.0\n",
      "\n",
      "Epoch: 3\n",
      "Train epoch : 3 loss : 1.1584766507148743 Acc : 36.666666666666664%\n",
      "\n",
      "Epoch: 3\n",
      "Test epoch : 3 loss : 1.1053772270679474 Acc : 43.333333333333336%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 4\n",
      "Train epoch : 4 loss : 1.16074534257253 Acc : 36.25%\n",
      "\n",
      "Epoch: 4\n",
      "Test epoch : 4 loss : 1.1287089586257935 Acc : 30.0%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 5\n",
      "Train epoch : 5 loss : 1.129036005338033 Acc : 37.083333333333336%\n",
      "\n",
      "Epoch: 5\n",
      "Test epoch : 5 loss : 1.4824432134628296 Acc : 30.0%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 6\n",
      "Train epoch : 6 loss : 1.1552048921585083 Acc : 30.833333333333332%\n",
      "\n",
      "Epoch: 6\n",
      "Test epoch : 6 loss : 1.6637535691261292 Acc : 26.666666666666668%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 7\n",
      "Train epoch : 7 loss : 1.145454430580139 Acc : 32.5%\n",
      "\n",
      "Epoch: 7\n",
      "Test epoch : 7 loss : 1.1540893912315369 Acc : 30.0%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 8\n",
      "Train epoch : 8 loss : 1.1653528054555258 Acc : 30.833333333333332%\n",
      "\n",
      "Epoch: 8\n",
      "Test epoch : 8 loss : 1.2146402597427368 Acc : 26.666666666666668%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 9\n",
      "Train epoch : 9 loss : 1.191608230272929 Acc : 30.833333333333332%\n",
      "\n",
      "Epoch: 9\n",
      "Test epoch : 9 loss : 1.090859293937683 Acc : 40.0%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 10\n",
      "Train epoch : 10 loss : 1.1383410692214966 Acc : 32.916666666666664%\n",
      "\n",
      "Epoch: 10\n",
      "Test epoch : 10 loss : 1.0982676148414612 Acc : 43.333333333333336%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 11\n",
      "Train epoch : 11 loss : 1.1479761600494385 Acc : 33.333333333333336%\n",
      "\n",
      "Epoch: 11\n",
      "Test epoch : 11 loss : 1.149192452430725 Acc : 26.666666666666668%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 12\n",
      "Train epoch : 12 loss : 1.134136724472046 Acc : 38.75%\n",
      "\n",
      "Epoch: 12\n",
      "Test epoch : 12 loss : 1.1217043995857239 Acc : 30.0%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 13\n",
      "Train epoch : 13 loss : 1.1518630345662435 Acc : 33.75%\n",
      "\n",
      "Epoch: 13\n",
      "Test epoch : 13 loss : 1.1369189620018005 Acc : 30.0%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 14\n",
      "Train epoch : 14 loss : 1.134799353281657 Acc : 35.833333333333336%\n",
      "\n",
      "Epoch: 14\n",
      "Test epoch : 14 loss : 1.1365075707435608 Acc : 26.666666666666668%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 15\n",
      "Train epoch : 15 loss : 1.1217751661936441 Acc : 33.75%\n",
      "\n",
      "Epoch: 15\n",
      "Test epoch : 15 loss : 1.088435709476471 Acc : 36.666666666666664%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 16\n",
      "Train epoch : 16 loss : 1.1388286193211874 Acc : 35.416666666666664%\n",
      "\n",
      "Epoch: 16\n",
      "Test epoch : 16 loss : 1.3095608949661255 Acc : 26.666666666666668%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 17\n",
      "Train epoch : 17 loss : 1.1486673514048258 Acc : 33.75%\n",
      "\n",
      "Epoch: 17\n",
      "Test epoch : 17 loss : 1.0945802330970764 Acc : 43.333333333333336%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 18\n",
      "Train epoch : 18 loss : 1.1310782512029012 Acc : 36.25%\n",
      "\n",
      "Epoch: 18\n",
      "Test epoch : 18 loss : 1.1582459211349487 Acc : 30.0%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 19\n",
      "Train epoch : 19 loss : 1.1240370353062947 Acc : 32.5%\n",
      "\n",
      "Epoch: 19\n",
      "Test epoch : 19 loss : 1.11367267370224 Acc : 30.0%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 20\n",
      "Train epoch : 20 loss : 1.1178340435028076 Acc : 36.666666666666664%\n",
      "\n",
      "Epoch: 20\n",
      "Test epoch : 20 loss : 1.2490835785865784 Acc : 30.0%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 21\n",
      "Train epoch : 21 loss : 1.1271020253499349 Acc : 33.75%\n",
      "\n",
      "Epoch: 21\n",
      "Test epoch : 21 loss : 1.0768613815307617 Acc : 43.333333333333336%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 22\n",
      "Train epoch : 22 loss : 1.1485367695490518 Acc : 32.5%\n",
      "\n",
      "Epoch: 22\n",
      "Test epoch : 22 loss : 1.235280692577362 Acc : 26.666666666666668%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 23\n",
      "Train epoch : 23 loss : 1.1343324422836303 Acc : 32.083333333333336%\n",
      "\n",
      "Epoch: 23\n",
      "Test epoch : 23 loss : 1.2297844886779785 Acc : 26.666666666666668%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 24\n",
      "Train epoch : 24 loss : 1.1259241342544555 Acc : 34.583333333333336%\n",
      "\n",
      "Epoch: 24\n",
      "Test epoch : 24 loss : 1.0891605615615845 Acc : 40.0%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 25\n",
      "Train epoch : 25 loss : 1.1137972354888916 Acc : 35.833333333333336%\n",
      "\n",
      "Epoch: 25\n",
      "Test epoch : 25 loss : 1.0817914605140686 Acc : 40.0%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 26\n",
      "Train epoch : 26 loss : 1.1087694962819417 Acc : 37.083333333333336%\n",
      "\n",
      "Epoch: 26\n",
      "Test epoch : 26 loss : 1.1426472663879395 Acc : 26.666666666666668%\n",
      "43.333333333333336\n",
      "\n",
      "Epoch: 27\n",
      "Train epoch : 27 loss : 1.1368876059850057 Acc : 30.833333333333332%\n",
      "\n",
      "Epoch: 27\n",
      "Test epoch : 27 loss : 1.0031167566776276 Acc : 60.0%\n",
      "60.0\n",
      "\n",
      "Epoch: 28\n",
      "Train epoch : 28 loss : 1.1319705764452617 Acc : 38.333333333333336%\n",
      "\n",
      "Epoch: 28\n",
      "Test epoch : 28 loss : 1.1448070406913757 Acc : 30.0%\n",
      "60.0\n",
      "\n",
      "Epoch: 29\n",
      "Train epoch : 29 loss : 1.1039326349894205 Acc : 38.333333333333336%\n",
      "\n",
      "Epoch: 29\n",
      "Test epoch : 29 loss : 0.993440181016922 Acc : 43.333333333333336%\n",
      "60.0\n",
      "\n",
      "Epoch: 30\n",
      "Train epoch : 30 loss : 1.135258722305298 Acc : 30.416666666666668%\n",
      "\n",
      "Epoch: 30\n",
      "Test epoch : 30 loss : 1.059436857700348 Acc : 36.666666666666664%\n",
      "60.0\n",
      "\n",
      "Epoch: 31\n",
      "Train epoch : 31 loss : 1.091497580210368 Acc : 42.5%\n",
      "\n",
      "Epoch: 31\n",
      "Test epoch : 31 loss : 1.2515708804130554 Acc : 30.0%\n",
      "60.0\n",
      "\n",
      "Epoch: 32\n",
      "Train epoch : 32 loss : 1.0950902263323465 Acc : 41.666666666666664%\n",
      "\n",
      "Epoch: 32\n",
      "Test epoch : 32 loss : 1.1122430562973022 Acc : 50.0%\n",
      "60.0\n",
      "\n",
      "Epoch: 33\n",
      "Train epoch : 33 loss : 1.1350795149803161 Acc : 31.666666666666668%\n",
      "\n",
      "Epoch: 33\n",
      "Test epoch : 33 loss : 1.155896008014679 Acc : 26.666666666666668%\n",
      "60.0\n",
      "\n",
      "Epoch: 34\n",
      "Train epoch : 34 loss : 1.0935514648755391 Acc : 34.166666666666664%\n",
      "\n",
      "Epoch: 34\n",
      "Test epoch : 34 loss : 0.9943592548370361 Acc : 56.666666666666664%\n",
      "60.0\n",
      "\n",
      "Epoch: 35\n",
      "Train epoch : 35 loss : 1.0765888730684916 Acc : 38.333333333333336%\n",
      "\n",
      "Epoch: 35\n",
      "Test epoch : 35 loss : 1.0778671503067017 Acc : 43.333333333333336%\n",
      "60.0\n",
      "\n",
      "Epoch: 36\n",
      "Train epoch : 36 loss : 1.0628154794375102 Acc : 45.0%\n",
      "\n",
      "Epoch: 36\n",
      "Test epoch : 36 loss : 1.0460431575775146 Acc : 36.666666666666664%\n",
      "60.0\n",
      "\n",
      "Epoch: 37\n",
      "Train epoch : 37 loss : 1.0829400102297464 Acc : 39.583333333333336%\n",
      "\n",
      "Epoch: 37\n",
      "Test epoch : 37 loss : 1.067844182252884 Acc : 50.0%\n",
      "60.0\n",
      "\n",
      "Epoch: 38\n",
      "Train epoch : 38 loss : 1.082799788316091 Acc : 37.916666666666664%\n",
      "\n",
      "Epoch: 38\n",
      "Test epoch : 38 loss : 1.1878845691680908 Acc : 43.333333333333336%\n",
      "60.0\n",
      "\n",
      "Epoch: 39\n",
      "Train epoch : 39 loss : 1.0686586260795594 Acc : 38.75%\n",
      "\n",
      "Epoch: 39\n",
      "Test epoch : 39 loss : 1.0804327726364136 Acc : 33.333333333333336%\n",
      "60.0\n",
      "\n",
      "Epoch: 40\n",
      "Train epoch : 40 loss : 1.043823480606079 Acc : 41.666666666666664%\n",
      "\n",
      "Epoch: 40\n",
      "Test epoch : 40 loss : 0.8640750050544739 Acc : 70.0%\n",
      "70.0\n",
      "\n",
      "Epoch: 41\n",
      "Train epoch : 41 loss : 1.0961533228556315 Acc : 38.333333333333336%\n",
      "\n",
      "Epoch: 41\n",
      "Test epoch : 41 loss : 1.2770055532455444 Acc : 30.0%\n",
      "70.0\n",
      "\n",
      "Epoch: 42\n",
      "Train epoch : 42 loss : 1.058424750963847 Acc : 42.083333333333336%\n",
      "\n",
      "Epoch: 42\n",
      "Test epoch : 42 loss : 1.0177026987075806 Acc : 40.0%\n",
      "70.0\n",
      "\n",
      "Epoch: 43\n",
      "Train epoch : 43 loss : 1.0283544619878133 Acc : 43.75%\n",
      "\n",
      "Epoch: 43\n",
      "Test epoch : 43 loss : 1.1736335456371307 Acc : 33.333333333333336%\n",
      "70.0\n",
      "\n",
      "Epoch: 44\n",
      "Train epoch : 44 loss : 1.0393400549888612 Acc : 43.75%\n",
      "\n",
      "Epoch: 44\n",
      "Test epoch : 44 loss : 2.299885630607605 Acc : 43.333333333333336%\n",
      "70.0\n",
      "\n",
      "Epoch: 45\n",
      "Train epoch : 45 loss : 1.0304129799207051 Acc : 43.333333333333336%\n",
      "\n",
      "Epoch: 45\n",
      "Test epoch : 45 loss : 1.1356319785118103 Acc : 33.333333333333336%\n",
      "70.0\n",
      "\n",
      "Epoch: 46\n",
      "Train epoch : 46 loss : 1.0570463180541991 Acc : 41.666666666666664%\n",
      "\n",
      "Epoch: 46\n",
      "Test epoch : 46 loss : 1.2878074049949646 Acc : 33.333333333333336%\n",
      "70.0\n",
      "\n",
      "Epoch: 47\n",
      "Train epoch : 47 loss : 1.0357575376828512 Acc : 41.666666666666664%\n",
      "\n",
      "Epoch: 47\n",
      "Test epoch : 47 loss : 0.7639272212982178 Acc : 73.33333333333333%\n",
      "73.33333333333333\n",
      "\n",
      "Epoch: 48\n",
      "Train epoch : 48 loss : 1.105096705754598 Acc : 41.666666666666664%\n",
      "\n",
      "Epoch: 48\n",
      "Test epoch : 48 loss : 0.8821115791797638 Acc : 66.66666666666667%\n",
      "73.33333333333333\n",
      "\n",
      "Epoch: 49\n",
      "Train epoch : 49 loss : 1.019342025121053 Acc : 47.083333333333336%\n",
      "\n",
      "Epoch: 49\n",
      "Test epoch : 49 loss : 0.8601016104221344 Acc : 63.333333333333336%\n",
      "73.33333333333333\n",
      "\n",
      "Epoch: 50\n",
      "Train epoch : 50 loss : 1.0189207832018534 Acc : 43.75%\n",
      "\n",
      "Epoch: 50\n",
      "Test epoch : 50 loss : 0.7695072889328003 Acc : 70.0%\n",
      "73.33333333333333\n",
      "\n",
      "Epoch: 51\n",
      "Train epoch : 51 loss : 1.0299168984095255 Acc : 45.0%\n",
      "\n",
      "Epoch: 51\n",
      "Test epoch : 51 loss : 1.0576240420341492 Acc : 43.333333333333336%\n",
      "73.33333333333333\n",
      "\n",
      "Epoch: 52\n",
      "Train epoch : 52 loss : 1.0420798500378927 Acc : 44.166666666666664%\n",
      "\n",
      "Epoch: 52\n",
      "Test epoch : 52 loss : 0.9447790384292603 Acc : 63.333333333333336%\n",
      "73.33333333333333\n",
      "\n",
      "Epoch: 53\n",
      "Train epoch : 53 loss : 0.9454412301381429 Acc : 51.25%\n",
      "\n",
      "Epoch: 53\n",
      "Test epoch : 53 loss : 0.7224655747413635 Acc : 83.33333333333333%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 54\n",
      "Train epoch : 54 loss : 0.9438835382461548 Acc : 49.583333333333336%\n",
      "\n",
      "Epoch: 54\n",
      "Test epoch : 54 loss : 0.7358109951019287 Acc : 50.0%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 55\n",
      "Train epoch : 55 loss : 0.9324313044548035 Acc : 56.25%\n",
      "\n",
      "Epoch: 55\n",
      "Test epoch : 55 loss : 0.7712242007255554 Acc : 56.666666666666664%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 56\n",
      "Train epoch : 56 loss : 0.9461100101470947 Acc : 51.666666666666664%\n",
      "\n",
      "Epoch: 56\n",
      "Test epoch : 56 loss : 0.6732078194618225 Acc : 70.0%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 57\n",
      "Train epoch : 57 loss : 0.8692838390668233 Acc : 56.666666666666664%\n",
      "\n",
      "Epoch: 57\n",
      "Test epoch : 57 loss : 0.6021488308906555 Acc : 76.66666666666667%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 58\n",
      "Train epoch : 58 loss : 0.8296616117159525 Acc : 57.5%\n",
      "\n",
      "Epoch: 58\n",
      "Test epoch : 58 loss : 1.7922582030296326 Acc : 43.333333333333336%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 59\n",
      "Train epoch : 59 loss : 0.8350034515062968 Acc : 62.083333333333336%\n",
      "\n",
      "Epoch: 59\n",
      "Test epoch : 59 loss : 1.9526247382164001 Acc : 43.333333333333336%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 60\n",
      "Train epoch : 60 loss : 0.9918516079584757 Acc : 50.0%\n",
      "\n",
      "Epoch: 60\n",
      "Test epoch : 60 loss : 0.5534520149230957 Acc : 70.0%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 61\n",
      "Train epoch : 61 loss : 0.805283518632253 Acc : 60.416666666666664%\n",
      "\n",
      "Epoch: 61\n",
      "Test epoch : 61 loss : 0.9766250550746918 Acc : 36.666666666666664%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 62\n",
      "Train epoch : 62 loss : 0.8325480182965597 Acc : 57.5%\n",
      "\n",
      "Epoch: 62\n",
      "Test epoch : 62 loss : 1.1208847761154175 Acc : 40.0%\n",
      "83.33333333333333\n",
      "\n",
      "Epoch: 63\n",
      "Train epoch : 63 loss : 0.7414061427116394 Acc : 68.33333333333333%\n",
      "\n",
      "Epoch: 63\n",
      "Test epoch : 63 loss : 0.4481048136949539 Acc : 86.66666666666667%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 64\n",
      "Train epoch : 64 loss : 0.7239042441050212 Acc : 67.5%\n",
      "\n",
      "Epoch: 64\n",
      "Test epoch : 64 loss : 0.5477520972490311 Acc : 80.0%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 65\n",
      "Train epoch : 65 loss : 0.7199093282222748 Acc : 68.75%\n",
      "\n",
      "Epoch: 65\n",
      "Test epoch : 65 loss : 0.4542189985513687 Acc : 73.33333333333333%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 66\n",
      "Train epoch : 66 loss : 0.7724120616912842 Acc : 64.16666666666667%\n",
      "\n",
      "Epoch: 66\n",
      "Test epoch : 66 loss : 0.41752059757709503 Acc : 86.66666666666667%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 67\n",
      "Train epoch : 67 loss : 0.6874491214752197 Acc : 67.91666666666667%\n",
      "\n",
      "Epoch: 67\n",
      "Test epoch : 67 loss : 0.6655993461608887 Acc : 70.0%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 68\n",
      "Train epoch : 68 loss : 0.7511872828006745 Acc : 65.83333333333333%\n",
      "\n",
      "Epoch: 68\n",
      "Test epoch : 68 loss : 0.39338211715221405 Acc : 86.66666666666667%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 69\n",
      "Train epoch : 69 loss : 0.7420425176620483 Acc : 65.41666666666667%\n",
      "\n",
      "Epoch: 69\n",
      "Test epoch : 69 loss : 0.4512852728366852 Acc : 80.0%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 70\n",
      "Train epoch : 70 loss : 0.7022707859675089 Acc : 67.91666666666667%\n",
      "\n",
      "Epoch: 70\n",
      "Test epoch : 70 loss : 0.39187030494213104 Acc : 86.66666666666667%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 71\n",
      "Train epoch : 71 loss : 0.6699857831001281 Acc : 67.91666666666667%\n",
      "\n",
      "Epoch: 71\n",
      "Test epoch : 71 loss : 0.4077383279800415 Acc : 80.0%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 72\n",
      "Train epoch : 72 loss : 0.6989103277524312 Acc : 65.83333333333333%\n",
      "\n",
      "Epoch: 72\n",
      "Test epoch : 72 loss : 0.6166701912879944 Acc : 63.333333333333336%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 73\n",
      "Train epoch : 73 loss : 0.6980845967928568 Acc : 65.83333333333333%\n",
      "\n",
      "Epoch: 73\n",
      "Test epoch : 73 loss : 0.4546183943748474 Acc : 80.0%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 74\n",
      "Train epoch : 74 loss : 0.7118780195713044 Acc : 71.25%\n",
      "\n",
      "Epoch: 74\n",
      "Test epoch : 74 loss : 0.4358316659927368 Acc : 73.33333333333333%\n",
      "86.66666666666667\n",
      "\n",
      "Epoch: 75\n",
      "Train epoch : 75 loss : 0.636716878414154 Acc : 73.75%\n",
      "\n",
      "Epoch: 75\n",
      "Test epoch : 75 loss : 0.36905501782894135 Acc : 90.0%\n",
      "90.0\n",
      "\n",
      "Epoch: 76\n",
      "Train epoch : 76 loss : 0.8475771864255269 Acc : 61.666666666666664%\n",
      "\n",
      "Epoch: 76\n",
      "Test epoch : 76 loss : 0.3403661698102951 Acc : 90.0%\n",
      "90.0\n",
      "\n",
      "Epoch: 77\n",
      "Train epoch : 77 loss : 0.6169718523820241 Acc : 75.0%\n",
      "\n",
      "Epoch: 77\n",
      "Test epoch : 77 loss : 0.6508850455284119 Acc : 66.66666666666667%\n",
      "90.0\n",
      "\n",
      "Epoch: 78\n",
      "Train epoch : 78 loss : 0.6817238807678223 Acc : 70.83333333333333%\n",
      "\n",
      "Epoch: 78\n",
      "Test epoch : 78 loss : 0.3675289452075958 Acc : 86.66666666666667%\n",
      "90.0\n",
      "\n",
      "Epoch: 79\n",
      "Train epoch : 79 loss : 0.6481139063835144 Acc : 72.91666666666667%\n",
      "\n",
      "Epoch: 79\n",
      "Test epoch : 79 loss : 12.0102858543396 Acc : 43.333333333333336%\n",
      "90.0\n",
      "\n",
      "Epoch: 80\n",
      "Train epoch : 80 loss : 0.5928385814030965 Acc : 74.58333333333333%\n",
      "\n",
      "Epoch: 80\n",
      "Test epoch : 80 loss : 0.4342869967222214 Acc : 76.66666666666667%\n",
      "90.0\n",
      "\n",
      "Epoch: 81\n",
      "Train epoch : 81 loss : 0.6277003069718678 Acc : 72.91666666666667%\n",
      "\n",
      "Epoch: 81\n",
      "Test epoch : 81 loss : 0.36341559886932373 Acc : 90.0%\n",
      "90.0\n",
      "\n",
      "Epoch: 82\n",
      "Train epoch : 82 loss : 0.9136327703793844 Acc : 58.75%\n",
      "\n",
      "Epoch: 82\n",
      "Test epoch : 82 loss : 0.35952793061733246 Acc : 83.33333333333333%\n",
      "90.0\n",
      "\n",
      "Epoch: 83\n",
      "Train epoch : 83 loss : 0.8553153236707052 Acc : 59.166666666666664%\n",
      "\n",
      "Epoch: 83\n",
      "Test epoch : 83 loss : 0.2846754789352417 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 84\n",
      "Train epoch : 84 loss : 0.6199551463127136 Acc : 76.66666666666667%\n",
      "\n",
      "Epoch: 84\n",
      "Test epoch : 84 loss : 0.36244042217731476 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 85\n",
      "Train epoch : 85 loss : 0.5994040787220001 Acc : 72.91666666666667%\n",
      "\n",
      "Epoch: 85\n",
      "Test epoch : 85 loss : 0.3685850501060486 Acc : 83.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 86\n",
      "Train epoch : 86 loss : 0.6785508394241333 Acc : 69.16666666666667%\n",
      "\n",
      "Epoch: 86\n",
      "Test epoch : 86 loss : 0.877787858247757 Acc : 46.666666666666664%\n",
      "100.0\n",
      "\n",
      "Epoch: 87\n",
      "Train epoch : 87 loss : 0.6378135065237681 Acc : 68.33333333333333%\n",
      "\n",
      "Epoch: 87\n",
      "Test epoch : 87 loss : 0.2569941431283951 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 88\n",
      "Train epoch : 88 loss : 0.6362981955210368 Acc : 74.16666666666667%\n",
      "\n",
      "Epoch: 88\n",
      "Test epoch : 88 loss : 0.6247977018356323 Acc : 63.333333333333336%\n",
      "100.0\n",
      "\n",
      "Epoch: 89\n",
      "Train epoch : 89 loss : 0.5515301247437795 Acc : 76.25%\n",
      "\n",
      "Epoch: 89\n",
      "Test epoch : 89 loss : 0.27275361865758896 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 90\n",
      "Train epoch : 90 loss : 0.586381870508194 Acc : 73.75%\n",
      "\n",
      "Epoch: 90\n",
      "Test epoch : 90 loss : 1.3180025219917297 Acc : 43.333333333333336%\n",
      "100.0\n",
      "\n",
      "Epoch: 91\n",
      "Train epoch : 91 loss : 0.5303237577279408 Acc : 75.41666666666667%\n",
      "\n",
      "Epoch: 91\n",
      "Test epoch : 91 loss : 0.6928985714912415 Acc : 66.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 92\n",
      "Train epoch : 92 loss : 0.6635221680005391 Acc : 73.33333333333333%\n",
      "\n",
      "Epoch: 92\n",
      "Test epoch : 92 loss : 0.27555912733078003 Acc : 90.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 93\n",
      "Train epoch : 93 loss : 0.6005297462145488 Acc : 72.5%\n",
      "\n",
      "Epoch: 93\n",
      "Test epoch : 93 loss : 0.23789957910776138 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 94\n",
      "Train epoch : 94 loss : 0.5271854956944784 Acc : 78.33333333333333%\n",
      "\n",
      "Epoch: 94\n",
      "Test epoch : 94 loss : 0.26305626332759857 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 95\n",
      "Train epoch : 95 loss : 0.663669764995575 Acc : 74.16666666666667%\n",
      "\n",
      "Epoch: 95\n",
      "Test epoch : 95 loss : 0.21254687011241913 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 96\n",
      "Train epoch : 96 loss : 0.6070450683434804 Acc : 74.58333333333333%\n",
      "\n",
      "Epoch: 96\n",
      "Test epoch : 96 loss : 0.17731163650751114 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 97\n",
      "Train epoch : 97 loss : 0.5315671493609746 Acc : 78.75%\n",
      "\n",
      "Epoch: 97\n",
      "Test epoch : 97 loss : 0.2558446601033211 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 98\n",
      "Train epoch : 98 loss : 0.47956398924191795 Acc : 79.16666666666667%\n",
      "\n",
      "Epoch: 98\n",
      "Test epoch : 98 loss : 0.22233880311250687 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 99\n",
      "Train epoch : 99 loss : 0.7278501689434052 Acc : 70.83333333333333%\n",
      "\n",
      "Epoch: 99\n",
      "Test epoch : 99 loss : 0.8796223402023315 Acc : 63.333333333333336%\n",
      "100.0\n",
      "\n",
      "Epoch: 100\n",
      "Train epoch : 100 loss : 0.7250568250815074 Acc : 70.41666666666667%\n",
      "\n",
      "Epoch: 100\n",
      "Test epoch : 100 loss : 0.8906331658363342 Acc : 70.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 101\n",
      "Train epoch : 101 loss : 0.5501675009727478 Acc : 76.66666666666667%\n",
      "\n",
      "Epoch: 101\n",
      "Test epoch : 101 loss : 0.7669465839862823 Acc : 53.333333333333336%\n",
      "100.0\n",
      "\n",
      "Epoch: 102\n",
      "Train epoch : 102 loss : 0.5358147184054057 Acc : 75.83333333333333%\n",
      "\n",
      "Epoch: 102\n",
      "Test epoch : 102 loss : 0.8706600666046143 Acc : 50.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 103\n",
      "Train epoch : 103 loss : 0.5695809106032054 Acc : 77.5%\n",
      "\n",
      "Epoch: 103\n",
      "Test epoch : 103 loss : 0.427252933382988 Acc : 73.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 104\n",
      "Train epoch : 104 loss : 0.4899016797542572 Acc : 80.83333333333333%\n",
      "\n",
      "Epoch: 104\n",
      "Test epoch : 104 loss : 1.1225528120994568 Acc : 60.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 105\n",
      "Train epoch : 105 loss : 0.5060268412033717 Acc : 79.16666666666667%\n",
      "\n",
      "Epoch: 105\n",
      "Test epoch : 105 loss : 0.30975082516670227 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 106\n",
      "Train epoch : 106 loss : 0.586802190542221 Acc : 75.83333333333333%\n",
      "\n",
      "Epoch: 106\n",
      "Test epoch : 106 loss : 0.17684917151927948 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 107\n",
      "Train epoch : 107 loss : 0.5752442459265391 Acc : 75.41666666666667%\n",
      "\n",
      "Epoch: 107\n",
      "Test epoch : 107 loss : 0.28311100602149963 Acc : 86.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 108\n",
      "Train epoch : 108 loss : 0.5043760001659393 Acc : 76.66666666666667%\n",
      "\n",
      "Epoch: 108\n",
      "Test epoch : 108 loss : 0.37774138897657394 Acc : 83.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 109\n",
      "Train epoch : 109 loss : 0.5176210125287374 Acc : 73.33333333333333%\n",
      "\n",
      "Epoch: 109\n",
      "Test epoch : 109 loss : 0.2741137519478798 Acc : 90.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 110\n",
      "Train epoch : 110 loss : 0.46269608835379283 Acc : 81.25%\n",
      "\n",
      "Epoch: 110\n",
      "Test epoch : 110 loss : 0.513188824057579 Acc : 70.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 111\n",
      "Train epoch : 111 loss : 0.50756889184316 Acc : 77.5%\n",
      "\n",
      "Epoch: 111\n",
      "Test epoch : 111 loss : 0.47074830532073975 Acc : 70.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 112\n",
      "Train epoch : 112 loss : 0.5332474827766418 Acc : 74.58333333333333%\n",
      "\n",
      "Epoch: 112\n",
      "Test epoch : 112 loss : 0.2926010936498642 Acc : 90.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 113\n",
      "Train epoch : 113 loss : 0.5071747680505116 Acc : 77.91666666666667%\n",
      "\n",
      "Epoch: 113\n",
      "Test epoch : 113 loss : 0.1660613715648651 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 114\n",
      "Train epoch : 114 loss : 0.46753140687942507 Acc : 80.41666666666667%\n",
      "\n",
      "Epoch: 114\n",
      "Test epoch : 114 loss : 0.15362601727247238 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 115\n",
      "Train epoch : 115 loss : 0.5307566225528717 Acc : 78.33333333333333%\n",
      "\n",
      "Epoch: 115\n",
      "Test epoch : 115 loss : 0.30981820821762085 Acc : 83.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 116\n",
      "Train epoch : 116 loss : 0.4951163411140442 Acc : 81.66666666666667%\n",
      "\n",
      "Epoch: 116\n",
      "Test epoch : 116 loss : 0.16542284935712814 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 117\n",
      "Train epoch : 117 loss : 0.5204943656921387 Acc : 79.58333333333333%\n",
      "\n",
      "Epoch: 117\n",
      "Test epoch : 117 loss : 0.18971747159957886 Acc : 93.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 118\n",
      "Train epoch : 118 loss : 0.42012527684370676 Acc : 84.16666666666667%\n",
      "\n",
      "Epoch: 118\n",
      "Test epoch : 118 loss : 0.3274054378271103 Acc : 80.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 119\n",
      "Train epoch : 119 loss : 0.5603528340657552 Acc : 77.08333333333333%\n",
      "\n",
      "Epoch: 119\n",
      "Test epoch : 119 loss : 0.9852712452411652 Acc : 60.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 120\n",
      "Train epoch : 120 loss : 0.6378790934880575 Acc : 70.41666666666667%\n",
      "\n",
      "Epoch: 120\n",
      "Test epoch : 120 loss : 0.22355906665325165 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 121\n",
      "Train epoch : 121 loss : 0.4718532939751943 Acc : 81.25%\n",
      "\n",
      "Epoch: 121\n",
      "Test epoch : 121 loss : 0.14908216893672943 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 122\n",
      "Train epoch : 122 loss : 0.47995225588480633 Acc : 78.75%\n",
      "\n",
      "Epoch: 122\n",
      "Test epoch : 122 loss : 1.211761236190796 Acc : 40.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 123\n",
      "Train epoch : 123 loss : 0.4940798888603846 Acc : 81.66666666666667%\n",
      "\n",
      "Epoch: 123\n",
      "Test epoch : 123 loss : 0.296759232878685 Acc : 83.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 124\n",
      "Train epoch : 124 loss : 0.4687073787053426 Acc : 80.41666666666667%\n",
      "\n",
      "Epoch: 124\n",
      "Test epoch : 124 loss : 0.12270745262503624 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 125\n",
      "Train epoch : 125 loss : 0.44973070720831554 Acc : 81.66666666666667%\n",
      "\n",
      "Epoch: 125\n",
      "Test epoch : 125 loss : 0.13697319477796555 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 126\n",
      "Train epoch : 126 loss : 0.41780582467714944 Acc : 83.75%\n",
      "\n",
      "Epoch: 126\n",
      "Test epoch : 126 loss : 0.6044276058673859 Acc : 60.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 127\n",
      "Train epoch : 127 loss : 0.49120480616887413 Acc : 80.83333333333333%\n",
      "\n",
      "Epoch: 127\n",
      "Test epoch : 127 loss : 0.13631682842969894 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 128\n",
      "Train epoch : 128 loss : 0.36823510626951855 Acc : 83.75%\n",
      "\n",
      "Epoch: 128\n",
      "Test epoch : 128 loss : 0.13017769902944565 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 129\n",
      "Train epoch : 129 loss : 0.4223678489526113 Acc : 85.0%\n",
      "\n",
      "Epoch: 129\n",
      "Test epoch : 129 loss : 0.31662189960479736 Acc : 90.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 130\n",
      "Train epoch : 130 loss : 0.4425829807917277 Acc : 82.91666666666667%\n",
      "\n",
      "Epoch: 130\n",
      "Test epoch : 130 loss : 0.816790908575058 Acc : 46.666666666666664%\n",
      "100.0\n",
      "\n",
      "Epoch: 131\n",
      "Train epoch : 131 loss : 0.41202379266421 Acc : 83.75%\n",
      "\n",
      "Epoch: 131\n",
      "Test epoch : 131 loss : 0.19812531769275665 Acc : 93.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 132\n",
      "Train epoch : 132 loss : 0.40042004982630414 Acc : 84.58333333333333%\n",
      "\n",
      "Epoch: 132\n",
      "Test epoch : 132 loss : 0.34748850017786026 Acc : 86.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 133\n",
      "Train epoch : 133 loss : 0.5251207609971364 Acc : 77.5%\n",
      "\n",
      "Epoch: 133\n",
      "Test epoch : 133 loss : 4.309462189674377 Acc : 43.333333333333336%\n",
      "100.0\n",
      "\n",
      "Epoch: 134\n",
      "Train epoch : 134 loss : 0.5919069677591324 Acc : 77.91666666666667%\n",
      "\n",
      "Epoch: 134\n",
      "Test epoch : 134 loss : 2.117821216583252 Acc : 43.333333333333336%\n",
      "100.0\n",
      "\n",
      "Epoch: 135\n",
      "Train epoch : 135 loss : 0.4741229474544525 Acc : 82.08333333333333%\n",
      "\n",
      "Epoch: 135\n",
      "Test epoch : 135 loss : 1.1882604360580444 Acc : 46.666666666666664%\n",
      "100.0\n",
      "\n",
      "Epoch: 136\n",
      "Train epoch : 136 loss : 0.5057428469260533 Acc : 80.0%\n",
      "\n",
      "Epoch: 136\n",
      "Test epoch : 136 loss : 0.28869568556547165 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 137\n",
      "Train epoch : 137 loss : 0.3681729167699814 Acc : 87.5%\n",
      "\n",
      "Epoch: 137\n",
      "Test epoch : 137 loss : 0.14411278814077377 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 138\n",
      "Train epoch : 138 loss : 0.4292400538921356 Acc : 82.08333333333333%\n",
      "\n",
      "Epoch: 138\n",
      "Test epoch : 138 loss : 0.09931152686476707 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 139\n",
      "Train epoch : 139 loss : 0.5388824353615443 Acc : 75.83333333333333%\n",
      "\n",
      "Epoch: 139\n",
      "Test epoch : 139 loss : 0.29841240495443344 Acc : 83.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 140\n",
      "Train epoch : 140 loss : 0.41124268968900046 Acc : 85.0%\n",
      "\n",
      "Epoch: 140\n",
      "Test epoch : 140 loss : 1.8407809138298035 Acc : 43.333333333333336%\n",
      "100.0\n",
      "\n",
      "Epoch: 141\n",
      "Train epoch : 141 loss : 0.4563384215037028 Acc : 80.41666666666667%\n",
      "\n",
      "Epoch: 141\n",
      "Test epoch : 141 loss : 0.6420862674713135 Acc : 70.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 142\n",
      "Train epoch : 142 loss : 0.3721894919872284 Acc : 85.83333333333333%\n",
      "\n",
      "Epoch: 142\n",
      "Test epoch : 142 loss : 0.11096886172890663 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 143\n",
      "Train epoch : 143 loss : 0.40019337435563407 Acc : 83.33333333333333%\n",
      "\n",
      "Epoch: 143\n",
      "Test epoch : 143 loss : 0.15057652443647385 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 144\n",
      "Train epoch : 144 loss : 0.4448311189810435 Acc : 79.58333333333333%\n",
      "\n",
      "Epoch: 144\n",
      "Test epoch : 144 loss : 0.11642251163721085 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 145\n",
      "Train epoch : 145 loss : 0.3758011182149251 Acc : 86.66666666666667%\n",
      "\n",
      "Epoch: 145\n",
      "Test epoch : 145 loss : 0.1192614771425724 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 146\n",
      "Train epoch : 146 loss : 0.39864327013492584 Acc : 87.08333333333333%\n",
      "\n",
      "Epoch: 146\n",
      "Test epoch : 146 loss : 0.7781351506710052 Acc : 53.333333333333336%\n",
      "100.0\n",
      "\n",
      "Epoch: 147\n",
      "Train epoch : 147 loss : 0.3611277058720589 Acc : 86.66666666666667%\n",
      "\n",
      "Epoch: 147\n",
      "Test epoch : 147 loss : 0.2568086013197899 Acc : 90.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 148\n",
      "Train epoch : 148 loss : 0.3905137767394384 Acc : 86.25%\n",
      "\n",
      "Epoch: 148\n",
      "Test epoch : 148 loss : 0.11905226856470108 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 149\n",
      "Train epoch : 149 loss : 0.3279924611250559 Acc : 86.25%\n",
      "\n",
      "Epoch: 149\n",
      "Test epoch : 149 loss : 1.128933385014534 Acc : 63.333333333333336%\n",
      "100.0\n",
      "\n",
      "Epoch: 150\n",
      "Train epoch : 150 loss : 0.39613528350989025 Acc : 82.5%\n",
      "\n",
      "Epoch: 150\n",
      "Test epoch : 150 loss : 0.10312279313802719 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 151\n",
      "Train epoch : 151 loss : 0.28907804091771444 Acc : 89.58333333333333%\n",
      "\n",
      "Epoch: 151\n",
      "Test epoch : 151 loss : 0.9554378688335419 Acc : 60.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 152\n",
      "Train epoch : 152 loss : 0.40804476489623387 Acc : 80.83333333333333%\n",
      "\n",
      "Epoch: 152\n",
      "Test epoch : 152 loss : 0.6424848139286041 Acc : 73.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 153\n",
      "Train epoch : 153 loss : 0.3463106711705526 Acc : 86.66666666666667%\n",
      "\n",
      "Epoch: 153\n",
      "Test epoch : 153 loss : 2.211302697658539 Acc : 56.666666666666664%\n",
      "100.0\n",
      "\n",
      "Epoch: 154\n",
      "Train epoch : 154 loss : 0.4197088619073232 Acc : 82.5%\n",
      "\n",
      "Epoch: 154\n",
      "Test epoch : 154 loss : 0.09791016206145287 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 155\n",
      "Train epoch : 155 loss : 0.33380593260129293 Acc : 87.5%\n",
      "\n",
      "Epoch: 155\n",
      "Test epoch : 155 loss : 0.20773568004369736 Acc : 90.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 156\n",
      "Train epoch : 156 loss : 0.39541214257478713 Acc : 87.08333333333333%\n",
      "\n",
      "Epoch: 156\n",
      "Test epoch : 156 loss : 2.8095487356185913 Acc : 43.333333333333336%\n",
      "100.0\n",
      "\n",
      "Epoch: 157\n",
      "Train epoch : 157 loss : 0.32981596887111664 Acc : 86.25%\n",
      "\n",
      "Epoch: 157\n",
      "Test epoch : 157 loss : 0.1253088302910328 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 158\n",
      "Train epoch : 158 loss : 0.3304434875647227 Acc : 85.83333333333333%\n",
      "\n",
      "Epoch: 158\n",
      "Test epoch : 158 loss : 0.08059963770210743 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 159\n",
      "Train epoch : 159 loss : 0.3858905643224716 Acc : 83.75%\n",
      "\n",
      "Epoch: 159\n",
      "Test epoch : 159 loss : 0.07157356664538383 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 160\n",
      "Train epoch : 160 loss : 0.3886084606250127 Acc : 83.75%\n",
      "\n",
      "Epoch: 160\n",
      "Test epoch : 160 loss : 0.7978193759918213 Acc : 53.333333333333336%\n",
      "100.0\n",
      "\n",
      "Epoch: 161\n",
      "Train epoch : 161 loss : 0.23032654871543248 Acc : 92.08333333333333%\n",
      "\n",
      "Epoch: 161\n",
      "Test epoch : 161 loss : 0.12402314320206642 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 162\n",
      "Train epoch : 162 loss : 0.5109455207983653 Acc : 80.0%\n",
      "\n",
      "Epoch: 162\n",
      "Test epoch : 162 loss : 0.1891733855009079 Acc : 90.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 163\n",
      "Train epoch : 163 loss : 0.3684011648098628 Acc : 84.16666666666667%\n",
      "\n",
      "Epoch: 163\n",
      "Test epoch : 163 loss : 1.8199747800827026 Acc : 50.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 164\n",
      "Train epoch : 164 loss : 0.40142044027646384 Acc : 85.41666666666667%\n",
      "\n",
      "Epoch: 164\n",
      "Test epoch : 164 loss : 0.23020272701978683 Acc : 86.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 165\n",
      "Train epoch : 165 loss : 0.3355514983336131 Acc : 87.91666666666667%\n",
      "\n",
      "Epoch: 165\n",
      "Test epoch : 165 loss : 0.10513888671994209 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 166\n",
      "Train epoch : 166 loss : 0.36768527229626974 Acc : 85.41666666666667%\n",
      "\n",
      "Epoch: 166\n",
      "Test epoch : 166 loss : 0.8846226632595062 Acc : 53.333333333333336%\n",
      "100.0\n",
      "\n",
      "Epoch: 167\n",
      "Train epoch : 167 loss : 0.2980160896976789 Acc : 89.58333333333333%\n",
      "\n",
      "Epoch: 167\n",
      "Test epoch : 167 loss : 0.06666357442736626 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 168\n",
      "Train epoch : 168 loss : 0.3438610975941022 Acc : 88.33333333333333%\n",
      "\n",
      "Epoch: 168\n",
      "Test epoch : 168 loss : 0.15300482511520386 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 169\n",
      "Train epoch : 169 loss : 0.3957924097776413 Acc : 81.25%\n",
      "\n",
      "Epoch: 169\n",
      "Test epoch : 169 loss : 0.8180357664823532 Acc : 73.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 170\n",
      "Train epoch : 170 loss : 0.3865087380011876 Acc : 84.58333333333333%\n",
      "\n",
      "Epoch: 170\n",
      "Test epoch : 170 loss : 3.5707556009292603 Acc : 56.666666666666664%\n",
      "100.0\n",
      "\n",
      "Epoch: 171\n",
      "Train epoch : 171 loss : 0.3073029985030492 Acc : 87.5%\n",
      "\n",
      "Epoch: 171\n",
      "Test epoch : 171 loss : 0.2426471784710884 Acc : 86.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 172\n",
      "Train epoch : 172 loss : 0.3292106678088506 Acc : 87.08333333333333%\n",
      "\n",
      "Epoch: 172\n",
      "Test epoch : 172 loss : 0.07585262507200241 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 173\n",
      "Train epoch : 173 loss : 0.29257925152778624 Acc : 88.33333333333333%\n",
      "\n",
      "Epoch: 173\n",
      "Test epoch : 173 loss : 0.10781244933605194 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 174\n",
      "Train epoch : 174 loss : 0.4320145746072133 Acc : 82.91666666666667%\n",
      "\n",
      "Epoch: 174\n",
      "Test epoch : 174 loss : 0.36044497042894363 Acc : 76.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 175\n",
      "Train epoch : 175 loss : 0.34646673997243244 Acc : 85.83333333333333%\n",
      "\n",
      "Epoch: 175\n",
      "Test epoch : 175 loss : 0.22790399193763733 Acc : 93.33333333333333%\n",
      "100.0\n",
      "\n",
      "Epoch: 176\n",
      "Train epoch : 176 loss : 0.2913541669646899 Acc : 91.25%\n",
      "\n",
      "Epoch: 176\n",
      "Test epoch : 176 loss : 0.10100025311112404 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 177\n",
      "Train epoch : 177 loss : 0.385170915722847 Acc : 83.33333333333333%\n",
      "\n",
      "Epoch: 177\n",
      "Test epoch : 177 loss : 0.4906432181596756 Acc : 70.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 178\n",
      "Train epoch : 178 loss : 0.4975816528002421 Acc : 79.58333333333333%\n",
      "\n",
      "Epoch: 178\n",
      "Test epoch : 178 loss : 0.11358942836523056 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 179\n",
      "Train epoch : 179 loss : 0.3586237614353498 Acc : 85.41666666666667%\n",
      "\n",
      "Epoch: 179\n",
      "Test epoch : 179 loss : 0.09805961325764656 Acc : 96.66666666666667%\n",
      "100.0\n",
      "\n",
      "Epoch: 180\n",
      "Train epoch : 180 loss : 0.32117243607838947 Acc : 87.5%\n",
      "\n",
      "Epoch: 180\n",
      "Test epoch : 180 loss : 0.10280168056488037 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 181\n",
      "Train epoch : 181 loss : 0.31016697188218434 Acc : 88.33333333333333%\n",
      "\n",
      "Epoch: 181\n",
      "Test epoch : 181 loss : 0.9863664507865906 Acc : 56.666666666666664%\n",
      "100.0\n",
      "\n",
      "Epoch: 182\n",
      "Train epoch : 182 loss : 0.34006503572066626 Acc : 85.41666666666667%\n",
      "\n",
      "Epoch: 182\n",
      "Test epoch : 182 loss : 0.0779338963329792 Acc : 100.0%\n",
      "100.0\n",
      "\n",
      "Epoch: 183\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_11364\\1204024335.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mBEST_SCORE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBEST_SCORE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_11364\\3098818687.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\fskd\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\USER\\Desktop\\GSH_CRP\\codes\\rock_sci_paper\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[0mout1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[0mout2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m             \u001b[0mout3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m             \u001b[0mout4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\fskd\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\fskd\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\fskd\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\USER\\Desktop\\GSH_CRP\\codes\\rock_sci_paper\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mout2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mout3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout2\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshortcut\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mout4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\fskd\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1204\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1205\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1206\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1207\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 모델 학습 및 평가\n",
    "BEST_SCORE = 0\n",
    "for epoch in range(epochs):\n",
    "    train(epoch)\n",
    "    test(epoch, valloader)\n",
    "    print(BEST_SCORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: -1\n",
      "Test epoch : -1 loss : 0.41445326805114746 Acc : 86.66666666666667%\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋에서 평가\n",
    "model.load_state_dict(torch.load(os.path.join(save_path, f'teacher.pth')))\n",
    "test(-1, testloader, 'test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fskd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

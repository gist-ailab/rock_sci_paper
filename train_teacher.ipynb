{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\fskd\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#필요한 라이브러리들 import\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import dataset\n",
    "import model\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각종 path및 하이퍼 파라미터 설정\n",
    "data_path = 'C:\\\\Users\\\\USER\\\\Desktop\\\\GSH_CRP\\\\codes\\\\rock_sci_paper\\\\data\\\\ro_sci_pa'\n",
    "save_path = 'C:\\\\Users\\\\USER\\\\Desktop\\\\GSH_CRP\\\\codes\\\\rock_sci_paper\\\\model_para'\n",
    "epochs = 200\n",
    "batch_size = 16\n",
    "learning_rate = 0.01\n",
    "seed = 0\n",
    "mode = 'hr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 설정\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# device 설정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform 설정\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomAffine((-90, 90), translate=(0.2,0.2)),\n",
    "    transforms.CenterCrop((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset 설정\n",
    "datasets = dataset.RockScissorsPaper(\n",
    "    transform=transform,\n",
    "    path = data_path\n",
    ")\n",
    "num_data = len(datasets)\n",
    "num_train = int(num_data*0.6)\n",
    "num_val = int(num_data*0.2)\n",
    "num_test = num_data - num_train - num_val\n",
    "\n",
    "train_data, val_data, test_data = torch.utils.data.random_split(datasets, [num_train, num_val, num_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader 설정\n",
    "trainloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "valloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "testloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델, 손실함수, 옵티마이저 설정\n",
    "model = model.ResNet18(num_classes=3)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    print('\\nEpoch: %d'%epoch)\n",
    "    # model train mode로 전환\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    total = 0\n",
    "    for (inputs, labels) in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if mode=='lr':\n",
    "            h,w = inputs.shape[-2], inputs.shape[-1]\n",
    "            lr_inputs = F.interpolate(inputs, (h//64, w//64))\n",
    "            lr_inputs = F.interpolate(lr_inputs, (h,w))\n",
    "            outputs, _, _, _, _ = model(lr_inputs)\n",
    "        else:\n",
    "            outputs, _, _, _, _ = model(inputs)\n",
    "            \n",
    "        _, pred = torch.max(outputs, 1)\n",
    "        total += outputs.size(0)\n",
    "        running_acc += (pred == labels).sum().item()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    total_loss = running_loss / len(trainloader)\n",
    "    total_acc = 100 * running_acc / total\n",
    "    print(f'Train epoch : {epoch} loss : {total_loss} Acc : {total_acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, loader, mode='val'):\n",
    "    print('\\nEpoch: %d'%epoch)\n",
    "    # model eval mode로 전환\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    total = 0\n",
    "    label_dict = {0:0, 1:0, 2:0}\n",
    "    global BEST_SCORE\n",
    "    with torch.no_grad():\n",
    "        for (inputs, labels) in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            if mode=='lr':\n",
    "                h,w = inputs.shape[-2], inputs.shape[-1]\n",
    "                lr_inputs = F.interpolate(inputs, (h//32, w//32))\n",
    "                lr_inputs = F.interpolate(lr_inputs, (h,w))\n",
    "                outputs, _, _, _, _ = model(lr_inputs)\n",
    "            else:\n",
    "                outputs, _, _, _, _ = model(inputs)\n",
    "\n",
    "            _, pred = torch.max(outputs, 1)\n",
    "            for label in labels:\n",
    "                label_dict[label.item()] += 1\n",
    "            total += outputs.size(0)\n",
    "            running_acc += (pred == labels).sum().item()\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "        total_loss = running_loss / len(loader)\n",
    "        total_acc = 100 * running_acc / total\n",
    "        print(label_dict)\n",
    "        if total_acc > BEST_SCORE and not mode=='test':\n",
    "            path = os.path.join(save_path, f'teacher.pth')\n",
    "            torch.save(model.state_dict(), path)\n",
    "            BEST_SCORE = total_acc\n",
    "        print(f'Test epoch : {epoch} loss : {total_loss} Acc : {total_acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "Train epoch : 0 loss : 1.1902758053370885 Acc : 27.77777777777778%\n",
      "\n",
      "Epoch: 0\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 0 loss : 1.1218647956848145 Acc : 25.0%\n",
      "25.0\n",
      "\n",
      "Epoch: 1\n",
      "Train epoch : 1 loss : 1.1819227848734175 Acc : 31.48148148148148%\n",
      "\n",
      "Epoch: 1\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 1 loss : 1.181842843691508 Acc : 25.0%\n",
      "25.0\n",
      "\n",
      "Epoch: 2\n",
      "Train epoch : 2 loss : 1.163448657308306 Acc : 26.85185185185185%\n",
      "\n",
      "Epoch: 2\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 2 loss : 1.1538198788960774 Acc : 25.0%\n",
      "25.0\n",
      "\n",
      "Epoch: 3\n",
      "Train epoch : 3 loss : 1.2115084103175573 Acc : 30.555555555555557%\n",
      "\n",
      "Epoch: 3\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 3 loss : 1.4054653247197468 Acc : 25.0%\n",
      "25.0\n",
      "\n",
      "Epoch: 4\n",
      "Train epoch : 4 loss : 1.1521106362342834 Acc : 39.81481481481482%\n",
      "\n",
      "Epoch: 4\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 4 loss : 1.282202124595642 Acc : 25.0%\n",
      "25.0\n",
      "\n",
      "Epoch: 5\n",
      "Train epoch : 5 loss : 1.0854969791003637 Acc : 37.96296296296296%\n",
      "\n",
      "Epoch: 5\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 5 loss : 1.2424412965774536 Acc : 27.77777777777778%\n",
      "27.77777777777778\n",
      "\n",
      "Epoch: 6\n",
      "Train epoch : 6 loss : 1.092854951109205 Acc : 43.51851851851852%\n",
      "\n",
      "Epoch: 6\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 6 loss : 1.1691757440567017 Acc : 33.333333333333336%\n",
      "33.333333333333336\n",
      "\n",
      "Epoch: 7\n",
      "Train epoch : 7 loss : 0.999841604913984 Acc : 48.148148148148145%\n",
      "\n",
      "Epoch: 7\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 7 loss : 1.5783020655314128 Acc : 25.0%\n",
      "33.333333333333336\n",
      "\n",
      "Epoch: 8\n",
      "Train epoch : 8 loss : 1.0833401424544198 Acc : 43.51851851851852%\n",
      "\n",
      "Epoch: 8\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 8 loss : 1.309802254041036 Acc : 30.555555555555557%\n",
      "33.333333333333336\n",
      "\n",
      "Epoch: 9\n",
      "Train epoch : 9 loss : 1.0629837172372 Acc : 43.51851851851852%\n",
      "\n",
      "Epoch: 9\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 9 loss : 1.2591387430826824 Acc : 38.888888888888886%\n",
      "38.888888888888886\n",
      "\n",
      "Epoch: 10\n",
      "Train epoch : 10 loss : 0.9397203751972744 Acc : 54.629629629629626%\n",
      "\n",
      "Epoch: 10\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 10 loss : 1.0118890404701233 Acc : 52.77777777777778%\n",
      "52.77777777777778\n",
      "\n",
      "Epoch: 11\n",
      "Train epoch : 11 loss : 0.9946912697383335 Acc : 49.074074074074076%\n",
      "\n",
      "Epoch: 11\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 11 loss : 4.3292116324106855 Acc : 30.555555555555557%\n",
      "52.77777777777778\n",
      "\n",
      "Epoch: 12\n",
      "Train epoch : 12 loss : 0.9890310253415789 Acc : 50.925925925925924%\n",
      "\n",
      "Epoch: 12\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 12 loss : 1.1143892010052998 Acc : 38.888888888888886%\n",
      "52.77777777777778\n",
      "\n",
      "Epoch: 13\n",
      "Train epoch : 13 loss : 1.0277873958860124 Acc : 52.77777777777778%\n",
      "\n",
      "Epoch: 13\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 13 loss : 1.2994830012321472 Acc : 27.77777777777778%\n",
      "52.77777777777778\n",
      "\n",
      "Epoch: 14\n",
      "Train epoch : 14 loss : 0.9662767563547406 Acc : 53.7037037037037%\n",
      "\n",
      "Epoch: 14\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 14 loss : 1.4639652967453003 Acc : 27.77777777777778%\n",
      "52.77777777777778\n",
      "\n",
      "Epoch: 15\n",
      "Train epoch : 15 loss : 0.9484908751079014 Acc : 49.074074074074076%\n",
      "\n",
      "Epoch: 15\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 15 loss : 1.6741536458333333 Acc : 27.77777777777778%\n",
      "52.77777777777778\n",
      "\n",
      "Epoch: 16\n",
      "Train epoch : 16 loss : 1.0042474099567957 Acc : 49.074074074074076%\n",
      "\n",
      "Epoch: 16\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 16 loss : 4.858053922653198 Acc : 30.555555555555557%\n",
      "52.77777777777778\n",
      "\n",
      "Epoch: 17\n",
      "Train epoch : 17 loss : 1.0133039099829537 Acc : 50.0%\n",
      "\n",
      "Epoch: 17\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 17 loss : 1.5735242366790771 Acc : 30.555555555555557%\n",
      "52.77777777777778\n",
      "\n",
      "Epoch: 18\n",
      "Train epoch : 18 loss : 0.9355221731322152 Acc : 51.851851851851855%\n",
      "\n",
      "Epoch: 18\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 18 loss : 1.227397342522939 Acc : 30.555555555555557%\n",
      "52.77777777777778\n",
      "\n",
      "Epoch: 19\n",
      "Train epoch : 19 loss : 1.0081764629908971 Acc : 51.851851851851855%\n",
      "\n",
      "Epoch: 19\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 19 loss : 1.633453090985616 Acc : 25.0%\n",
      "52.77777777777778\n",
      "\n",
      "Epoch: 20\n",
      "Train epoch : 20 loss : 0.8507898705346244 Acc : 58.333333333333336%\n",
      "\n",
      "Epoch: 20\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 20 loss : 1.2369852662086487 Acc : 50.0%\n",
      "52.77777777777778\n",
      "\n",
      "Epoch: 21\n",
      "Train epoch : 21 loss : 0.9376548954418727 Acc : 57.407407407407405%\n",
      "\n",
      "Epoch: 21\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 21 loss : 1.7557583252588909 Acc : 38.888888888888886%\n",
      "52.77777777777778\n",
      "\n",
      "Epoch: 22\n",
      "Train epoch : 22 loss : 0.9794307691710336 Acc : 57.407407407407405%\n",
      "\n",
      "Epoch: 22\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 22 loss : 6.612669467926025 Acc : 30.555555555555557%\n",
      "52.77777777777778\n",
      "\n",
      "Epoch: 23\n",
      "Train epoch : 23 loss : 0.7706203205244881 Acc : 68.51851851851852%\n",
      "\n",
      "Epoch: 23\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 23 loss : 1.4142299095789592 Acc : 36.111111111111114%\n",
      "52.77777777777778\n",
      "\n",
      "Epoch: 24\n",
      "Train epoch : 24 loss : 0.8998798131942749 Acc : 54.629629629629626%\n",
      "\n",
      "Epoch: 24\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 24 loss : 1.4899851083755493 Acc : 30.555555555555557%\n",
      "52.77777777777778\n",
      "\n",
      "Epoch: 25\n",
      "Train epoch : 25 loss : 0.7889976927212307 Acc : 62.96296296296296%\n",
      "\n",
      "Epoch: 25\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 25 loss : 1.4746379852294922 Acc : 38.888888888888886%\n",
      "52.77777777777778\n",
      "\n",
      "Epoch: 26\n",
      "Train epoch : 26 loss : 0.8616607104028974 Acc : 62.96296296296296%\n",
      "\n",
      "Epoch: 26\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 26 loss : 1.2930233478546143 Acc : 41.666666666666664%\n",
      "52.77777777777778\n",
      "\n",
      "Epoch: 27\n",
      "Train epoch : 27 loss : 0.8065188697406224 Acc : 65.74074074074075%\n",
      "\n",
      "Epoch: 27\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 27 loss : 0.9767000277837118 Acc : 47.22222222222222%\n",
      "52.77777777777778\n",
      "\n",
      "Epoch: 28\n",
      "Train epoch : 28 loss : 0.86243223292487 Acc : 62.03703703703704%\n",
      "\n",
      "Epoch: 28\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 28 loss : 1.7881523768107097 Acc : 25.0%\n",
      "52.77777777777778\n",
      "\n",
      "Epoch: 29\n",
      "Train epoch : 29 loss : 0.7677456395966666 Acc : 63.888888888888886%\n",
      "\n",
      "Epoch: 29\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 29 loss : 2.564705014228821 Acc : 25.0%\n",
      "52.77777777777778\n",
      "\n",
      "Epoch: 30\n",
      "Train epoch : 30 loss : 0.8417389392852783 Acc : 59.25925925925926%\n",
      "\n",
      "Epoch: 30\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 30 loss : 0.9310232003529867 Acc : 52.77777777777778%\n",
      "52.77777777777778\n",
      "\n",
      "Epoch: 31\n",
      "Train epoch : 31 loss : 0.7314837404659816 Acc : 70.37037037037037%\n",
      "\n",
      "Epoch: 31\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 31 loss : 0.9209208687146505 Acc : 55.55555555555556%\n",
      "55.55555555555556\n",
      "\n",
      "Epoch: 32\n",
      "Train epoch : 32 loss : 0.8698903918266296 Acc : 57.407407407407405%\n",
      "\n",
      "Epoch: 32\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 32 loss : 0.930085301399231 Acc : 47.22222222222222%\n",
      "55.55555555555556\n",
      "\n",
      "Epoch: 33\n",
      "Train epoch : 33 loss : 0.7524434753826686 Acc : 58.333333333333336%\n",
      "\n",
      "Epoch: 33\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 33 loss : 1.4974968234697978 Acc : 44.44444444444444%\n",
      "55.55555555555556\n",
      "\n",
      "Epoch: 34\n",
      "Train epoch : 34 loss : 0.7695304921695164 Acc : 63.888888888888886%\n",
      "\n",
      "Epoch: 34\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 34 loss : 1.2526757915814717 Acc : 47.22222222222222%\n",
      "55.55555555555556\n",
      "\n",
      "Epoch: 35\n",
      "Train epoch : 35 loss : 0.7071327992847988 Acc : 63.888888888888886%\n",
      "\n",
      "Epoch: 35\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 35 loss : 1.1113385756810505 Acc : 41.666666666666664%\n",
      "55.55555555555556\n",
      "\n",
      "Epoch: 36\n",
      "Train epoch : 36 loss : 0.6789468015943255 Acc : 71.29629629629629%\n",
      "\n",
      "Epoch: 36\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 36 loss : 2.4474527835845947 Acc : 27.77777777777778%\n",
      "55.55555555555556\n",
      "\n",
      "Epoch: 37\n",
      "Train epoch : 37 loss : 0.7216794448239463 Acc : 68.51851851851852%\n",
      "\n",
      "Epoch: 37\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 37 loss : 2.0467783212661743 Acc : 44.44444444444444%\n",
      "55.55555555555556\n",
      "\n",
      "Epoch: 38\n",
      "Train epoch : 38 loss : 0.853574446269444 Acc : 62.96296296296296%\n",
      "\n",
      "Epoch: 38\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 38 loss : 2.205041527748108 Acc : 44.44444444444444%\n",
      "55.55555555555556\n",
      "\n",
      "Epoch: 39\n",
      "Train epoch : 39 loss : 0.6620399185589382 Acc : 73.14814814814815%\n",
      "\n",
      "Epoch: 39\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 39 loss : 0.7469575802485148 Acc : 55.55555555555556%\n",
      "55.55555555555556\n",
      "\n",
      "Epoch: 40\n",
      "Train epoch : 40 loss : 0.7066001849515098 Acc : 63.888888888888886%\n",
      "\n",
      "Epoch: 40\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 40 loss : 0.9996904929478964 Acc : 47.22222222222222%\n",
      "55.55555555555556\n",
      "\n",
      "Epoch: 41\n",
      "Train epoch : 41 loss : 0.6078680370535169 Acc : 77.77777777777777%\n",
      "\n",
      "Epoch: 41\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 41 loss : 0.931968609491984 Acc : 50.0%\n",
      "55.55555555555556\n",
      "\n",
      "Epoch: 42\n",
      "Train epoch : 42 loss : 0.7090811644281659 Acc : 72.22222222222223%\n",
      "\n",
      "Epoch: 42\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 42 loss : 1.6623224020004272 Acc : 30.555555555555557%\n",
      "55.55555555555556\n",
      "\n",
      "Epoch: 43\n",
      "Train epoch : 43 loss : 0.7007553832871574 Acc : 73.14814814814815%\n",
      "\n",
      "Epoch: 43\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 43 loss : 6.115315119425456 Acc : 36.111111111111114%\n",
      "55.55555555555556\n",
      "\n",
      "Epoch: 44\n",
      "Train epoch : 44 loss : 0.6874186226299831 Acc : 63.888888888888886%\n",
      "\n",
      "Epoch: 44\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 44 loss : 1.7877370913823445 Acc : 38.888888888888886%\n",
      "55.55555555555556\n",
      "\n",
      "Epoch: 45\n",
      "Train epoch : 45 loss : 0.6848317001547132 Acc : 71.29629629629629%\n",
      "\n",
      "Epoch: 45\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 45 loss : 2.3249757289886475 Acc : 30.555555555555557%\n",
      "55.55555555555556\n",
      "\n",
      "Epoch: 46\n",
      "Train epoch : 46 loss : 0.7463666796684265 Acc : 62.03703703703704%\n",
      "\n",
      "Epoch: 46\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 46 loss : 1.8638227383295696 Acc : 47.22222222222222%\n",
      "55.55555555555556\n",
      "\n",
      "Epoch: 47\n",
      "Train epoch : 47 loss : 0.6875631724085126 Acc : 64.81481481481481%\n",
      "\n",
      "Epoch: 47\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 47 loss : 0.7677388588587443 Acc : 61.111111111111114%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 48\n",
      "Train epoch : 48 loss : 0.7077217868396214 Acc : 68.51851851851852%\n",
      "\n",
      "Epoch: 48\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 48 loss : 1.0615589618682861 Acc : 47.22222222222222%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 49\n",
      "Train epoch : 49 loss : 0.5802522812570844 Acc : 74.07407407407408%\n",
      "\n",
      "Epoch: 49\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 49 loss : 1.6644704739252727 Acc : 44.44444444444444%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 50\n",
      "Train epoch : 50 loss : 0.613636063677924 Acc : 71.29629629629629%\n",
      "\n",
      "Epoch: 50\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 50 loss : 3.847569227218628 Acc : 27.77777777777778%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 51\n",
      "Train epoch : 51 loss : 0.7461838892527989 Acc : 67.5925925925926%\n",
      "\n",
      "Epoch: 51\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 51 loss : 2.2205257415771484 Acc : 44.44444444444444%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 52\n",
      "Train epoch : 52 loss : 0.5887249963624137 Acc : 77.77777777777777%\n",
      "\n",
      "Epoch: 52\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 52 loss : 1.1716090838114421 Acc : 30.555555555555557%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 53\n",
      "Train epoch : 53 loss : 0.6046489988054548 Acc : 73.14814814814815%\n",
      "\n",
      "Epoch: 53\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 53 loss : 1.1630496382713318 Acc : 50.0%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 54\n",
      "Train epoch : 54 loss : 0.5079513575349536 Acc : 77.77777777777777%\n",
      "\n",
      "Epoch: 54\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 54 loss : 1.3461819887161255 Acc : 33.333333333333336%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 55\n",
      "Train epoch : 55 loss : 0.5300668520586831 Acc : 75.0%\n",
      "\n",
      "Epoch: 55\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 55 loss : 7.988213062286377 Acc : 30.555555555555557%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 56\n",
      "Train epoch : 56 loss : 0.5951126771313804 Acc : 76.85185185185185%\n",
      "\n",
      "Epoch: 56\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 56 loss : 0.9063915411631266 Acc : 58.333333333333336%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 57\n",
      "Train epoch : 57 loss : 0.5380433074065617 Acc : 77.77777777777777%\n",
      "\n",
      "Epoch: 57\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 57 loss : 1.0092807213465373 Acc : 44.44444444444444%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 58\n",
      "Train epoch : 58 loss : 0.7329873272350856 Acc : 67.5925925925926%\n",
      "\n",
      "Epoch: 58\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 58 loss : 4.122009674708049 Acc : 25.0%\n",
      "61.111111111111114\n",
      "\n",
      "Epoch: 59\n",
      "Train epoch : 59 loss : 0.6040856071880886 Acc : 70.37037037037037%\n",
      "\n",
      "Epoch: 59\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 59 loss : 0.939306894938151 Acc : 66.66666666666667%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 60\n",
      "Train epoch : 60 loss : 0.5386383363178798 Acc : 75.0%\n",
      "\n",
      "Epoch: 60\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 60 loss : 0.855949322382609 Acc : 61.111111111111114%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 61\n",
      "Train epoch : 61 loss : 0.4626078520502363 Acc : 84.25925925925925%\n",
      "\n",
      "Epoch: 61\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 61 loss : 3.334595243136088 Acc : 38.888888888888886%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 62\n",
      "Train epoch : 62 loss : 0.4650648534297943 Acc : 81.48148148148148%\n",
      "\n",
      "Epoch: 62\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 62 loss : 1.6534408926963806 Acc : 58.333333333333336%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 63\n",
      "Train epoch : 63 loss : 0.627959532397134 Acc : 76.85185185185185%\n",
      "\n",
      "Epoch: 63\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 63 loss : 4.087557077407837 Acc : 47.22222222222222%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 64\n",
      "Train epoch : 64 loss : 0.47591395463262287 Acc : 79.62962962962963%\n",
      "\n",
      "Epoch: 64\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 64 loss : 1.536752740542094 Acc : 47.22222222222222%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 65\n",
      "Train epoch : 65 loss : 0.4033361630780356 Acc : 82.4074074074074%\n",
      "\n",
      "Epoch: 65\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 65 loss : 0.9553964932759603 Acc : 41.666666666666664%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 66\n",
      "Train epoch : 66 loss : 0.742161750793457 Acc : 64.81481481481481%\n",
      "\n",
      "Epoch: 66\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 66 loss : 1.660743812719981 Acc : 30.555555555555557%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 67\n",
      "Train epoch : 67 loss : 0.5699444540909359 Acc : 74.07407407407408%\n",
      "\n",
      "Epoch: 67\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 67 loss : 1.8325440088907878 Acc : 55.55555555555556%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 68\n",
      "Train epoch : 68 loss : 0.46532899141311646 Acc : 80.55555555555556%\n",
      "\n",
      "Epoch: 68\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 68 loss : 0.7689254283905029 Acc : 63.888888888888886%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 69\n",
      "Train epoch : 69 loss : 0.5601843680654254 Acc : 74.07407407407408%\n",
      "\n",
      "Epoch: 69\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 69 loss : 2.530803640683492 Acc : 50.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 70\n",
      "Train epoch : 70 loss : 0.45882274423326763 Acc : 79.62962962962963%\n",
      "\n",
      "Epoch: 70\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 70 loss : 2.3677698373794556 Acc : 44.44444444444444%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 71\n",
      "Train epoch : 71 loss : 0.47668046823569704 Acc : 83.33333333333333%\n",
      "\n",
      "Epoch: 71\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 71 loss : 1.7877517541249592 Acc : 47.22222222222222%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 72\n",
      "Train epoch : 72 loss : 0.4058394857815334 Acc : 82.4074074074074%\n",
      "\n",
      "Epoch: 72\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 72 loss : 2.064208229382833 Acc : 44.44444444444444%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 73\n",
      "Train epoch : 73 loss : 0.48696320823260714 Acc : 78.70370370370371%\n",
      "\n",
      "Epoch: 73\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 73 loss : 1.3510783513387044 Acc : 55.55555555555556%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 74\n",
      "Train epoch : 74 loss : 0.6455894580909184 Acc : 67.5925925925926%\n",
      "\n",
      "Epoch: 74\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 74 loss : 5.33539613087972 Acc : 44.44444444444444%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 75\n",
      "Train epoch : 75 loss : 0.7370985065187726 Acc : 64.81481481481481%\n",
      "\n",
      "Epoch: 75\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 75 loss : 1.470748762289683 Acc : 50.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 76\n",
      "Train epoch : 76 loss : 0.41528355862413135 Acc : 85.18518518518519%\n",
      "\n",
      "Epoch: 76\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 76 loss : 2.048327326774597 Acc : 44.44444444444444%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 77\n",
      "Train epoch : 77 loss : 0.4343678653240204 Acc : 84.25925925925925%\n",
      "\n",
      "Epoch: 77\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 77 loss : 0.8567208449045817 Acc : 50.0%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 78\n",
      "Train epoch : 78 loss : 0.5834985375404358 Acc : 72.22222222222223%\n",
      "\n",
      "Epoch: 78\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 78 loss : 1.2225970427195232 Acc : 47.22222222222222%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 79\n",
      "Train epoch : 79 loss : 0.5043597391673497 Acc : 74.07407407407408%\n",
      "\n",
      "Epoch: 79\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 79 loss : 0.8643494049708048 Acc : 55.55555555555556%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 80\n",
      "Train epoch : 80 loss : 0.4333636313676834 Acc : 81.48148148148148%\n",
      "\n",
      "Epoch: 80\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 80 loss : 0.756043016910553 Acc : 66.66666666666667%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 81\n",
      "Train epoch : 81 loss : 0.5626865710530963 Acc : 77.77777777777777%\n",
      "\n",
      "Epoch: 81\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 81 loss : 1.305765410264333 Acc : 61.111111111111114%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 82\n",
      "Train epoch : 82 loss : 0.49758083479745047 Acc : 83.33333333333333%\n",
      "\n",
      "Epoch: 82\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 82 loss : 1.6018472909927368 Acc : 55.55555555555556%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 83\n",
      "Train epoch : 83 loss : 0.3465688228607178 Acc : 88.88888888888889%\n",
      "\n",
      "Epoch: 83\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 83 loss : 1.2412782907485962 Acc : 55.55555555555556%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 84\n",
      "Train epoch : 84 loss : 0.4276840090751648 Acc : 81.48148148148148%\n",
      "\n",
      "Epoch: 84\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 84 loss : 1.4445420503616333 Acc : 58.333333333333336%\n",
      "66.66666666666667\n",
      "\n",
      "Epoch: 85\n",
      "Train epoch : 85 loss : 0.38947926674570355 Acc : 86.11111111111111%\n",
      "\n",
      "Epoch: 85\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 85 loss : 0.5362658500671387 Acc : 75.0%\n",
      "75.0\n",
      "\n",
      "Epoch: 86\n",
      "Train epoch : 86 loss : 0.47849604061671663 Acc : 81.48148148148148%\n",
      "\n",
      "Epoch: 86\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 86 loss : 1.3021682898203533 Acc : 58.333333333333336%\n",
      "75.0\n",
      "\n",
      "Epoch: 87\n",
      "Train epoch : 87 loss : 0.45625702823911396 Acc : 80.55555555555556%\n",
      "\n",
      "Epoch: 87\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 87 loss : 0.8096986611684164 Acc : 50.0%\n",
      "75.0\n",
      "\n",
      "Epoch: 88\n",
      "Train epoch : 88 loss : 0.6098970004490444 Acc : 76.85185185185185%\n",
      "\n",
      "Epoch: 88\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 88 loss : 1.1686030824979146 Acc : 50.0%\n",
      "75.0\n",
      "\n",
      "Epoch: 89\n",
      "Train epoch : 89 loss : 0.6327319145202637 Acc : 78.70370370370371%\n",
      "\n",
      "Epoch: 89\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 89 loss : 1.2695467472076416 Acc : 47.22222222222222%\n",
      "75.0\n",
      "\n",
      "Epoch: 90\n",
      "Train epoch : 90 loss : 0.437231855733054 Acc : 85.18518518518519%\n",
      "\n",
      "Epoch: 90\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 90 loss : 0.7694167296091715 Acc : 58.333333333333336%\n",
      "75.0\n",
      "\n",
      "Epoch: 91\n",
      "Train epoch : 91 loss : 0.4240475765296391 Acc : 85.18518518518519%\n",
      "\n",
      "Epoch: 91\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 91 loss : 0.7115064263343811 Acc : 72.22222222222223%\n",
      "75.0\n",
      "\n",
      "Epoch: 92\n",
      "Train epoch : 92 loss : 0.34940290238176075 Acc : 85.18518518518519%\n",
      "\n",
      "Epoch: 92\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 92 loss : 1.005504051844279 Acc : 55.55555555555556%\n",
      "75.0\n",
      "\n",
      "Epoch: 93\n",
      "Train epoch : 93 loss : 0.34745428604739054 Acc : 86.11111111111111%\n",
      "\n",
      "Epoch: 93\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 93 loss : 0.7123722930749258 Acc : 72.22222222222223%\n",
      "75.0\n",
      "\n",
      "Epoch: 94\n",
      "Train epoch : 94 loss : 0.35145229952675955 Acc : 84.25925925925925%\n",
      "\n",
      "Epoch: 94\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 94 loss : 1.080188790957133 Acc : 63.888888888888886%\n",
      "75.0\n",
      "\n",
      "Epoch: 95\n",
      "Train epoch : 95 loss : 0.37319364292281015 Acc : 87.03703703703704%\n",
      "\n",
      "Epoch: 95\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 95 loss : 2.432977537314097 Acc : 38.888888888888886%\n",
      "75.0\n",
      "\n",
      "Epoch: 96\n",
      "Train epoch : 96 loss : 0.5853124069316047 Acc : 75.92592592592592%\n",
      "\n",
      "Epoch: 96\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 96 loss : 1.5922831694285076 Acc : 33.333333333333336%\n",
      "75.0\n",
      "\n",
      "Epoch: 97\n",
      "Train epoch : 97 loss : 0.520037191254752 Acc : 75.92592592592592%\n",
      "\n",
      "Epoch: 97\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 97 loss : 0.6546377936999003 Acc : 69.44444444444444%\n",
      "75.0\n",
      "\n",
      "Epoch: 98\n",
      "Train epoch : 98 loss : 0.4158343481166022 Acc : 84.25925925925925%\n",
      "\n",
      "Epoch: 98\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 98 loss : 0.9432209531466166 Acc : 72.22222222222223%\n",
      "75.0\n",
      "\n",
      "Epoch: 99\n",
      "Train epoch : 99 loss : 0.35527548619679045 Acc : 85.18518518518519%\n",
      "\n",
      "Epoch: 99\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 99 loss : 1.1528204878171284 Acc : 47.22222222222222%\n",
      "75.0\n",
      "\n",
      "Epoch: 100\n",
      "Train epoch : 100 loss : 0.2926502994128636 Acc : 89.81481481481481%\n",
      "\n",
      "Epoch: 100\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 100 loss : 1.0100806752840679 Acc : 50.0%\n",
      "75.0\n",
      "\n",
      "Epoch: 101\n",
      "Train epoch : 101 loss : 0.31892240260328564 Acc : 88.88888888888889%\n",
      "\n",
      "Epoch: 101\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 101 loss : 0.8663197755813599 Acc : 63.888888888888886%\n",
      "75.0\n",
      "\n",
      "Epoch: 102\n",
      "Train epoch : 102 loss : 0.27800577878952026 Acc : 87.96296296296296%\n",
      "\n",
      "Epoch: 102\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 102 loss : 1.0309363305568695 Acc : 55.55555555555556%\n",
      "75.0\n",
      "\n",
      "Epoch: 103\n",
      "Train epoch : 103 loss : 0.4131937793322972 Acc : 85.18518518518519%\n",
      "\n",
      "Epoch: 103\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 103 loss : 0.7997544010480245 Acc : 63.888888888888886%\n",
      "75.0\n",
      "\n",
      "Epoch: 104\n",
      "Train epoch : 104 loss : 0.42043774894305636 Acc : 83.33333333333333%\n",
      "\n",
      "Epoch: 104\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 104 loss : 1.2123160362243652 Acc : 55.55555555555556%\n",
      "75.0\n",
      "\n",
      "Epoch: 105\n",
      "Train epoch : 105 loss : 0.33211618661880493 Acc : 88.88888888888889%\n",
      "\n",
      "Epoch: 105\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 105 loss : 1.1167314648628235 Acc : 55.55555555555556%\n",
      "75.0\n",
      "\n",
      "Epoch: 106\n",
      "Train epoch : 106 loss : 0.35598720823015484 Acc : 84.25925925925925%\n",
      "\n",
      "Epoch: 106\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 106 loss : 0.6141716241836548 Acc : 72.22222222222223%\n",
      "75.0\n",
      "\n",
      "Epoch: 107\n",
      "Train epoch : 107 loss : 0.3768726033823831 Acc : 84.25925925925925%\n",
      "\n",
      "Epoch: 107\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 107 loss : 0.728549599647522 Acc : 66.66666666666667%\n",
      "75.0\n",
      "\n",
      "Epoch: 108\n",
      "Train epoch : 108 loss : 0.40734937148434774 Acc : 81.48148148148148%\n",
      "\n",
      "Epoch: 108\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 108 loss : 5.087776819864909 Acc : 47.22222222222222%\n",
      "75.0\n",
      "\n",
      "Epoch: 109\n",
      "Train epoch : 109 loss : 0.31379689276218414 Acc : 88.88888888888889%\n",
      "\n",
      "Epoch: 109\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 109 loss : 0.5544077257315317 Acc : 72.22222222222223%\n",
      "75.0\n",
      "\n",
      "Epoch: 110\n",
      "Train epoch : 110 loss : 0.34576249548367094 Acc : 88.88888888888889%\n",
      "\n",
      "Epoch: 110\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 110 loss : 1.12580539782842 Acc : 61.111111111111114%\n",
      "75.0\n",
      "\n",
      "Epoch: 111\n",
      "Train epoch : 111 loss : 0.38157844117709566 Acc : 84.25925925925925%\n",
      "\n",
      "Epoch: 111\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 111 loss : 0.7400665680567423 Acc : 63.888888888888886%\n",
      "75.0\n",
      "\n",
      "Epoch: 112\n",
      "Train epoch : 112 loss : 0.2925979771784374 Acc : 90.74074074074075%\n",
      "\n",
      "Epoch: 112\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 112 loss : 2.1145150661468506 Acc : 50.0%\n",
      "75.0\n",
      "\n",
      "Epoch: 113\n",
      "Train epoch : 113 loss : 0.6211156334195819 Acc : 73.14814814814815%\n",
      "\n",
      "Epoch: 113\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 113 loss : 0.9038998633623123 Acc : 63.888888888888886%\n",
      "75.0\n",
      "\n",
      "Epoch: 114\n",
      "Train epoch : 114 loss : 0.3135921997683389 Acc : 88.88888888888889%\n",
      "\n",
      "Epoch: 114\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 114 loss : 0.8587312897046407 Acc : 58.333333333333336%\n",
      "75.0\n",
      "\n",
      "Epoch: 115\n",
      "Train epoch : 115 loss : 0.37776344801698414 Acc : 85.18518518518519%\n",
      "\n",
      "Epoch: 115\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 115 loss : 0.8403228720029196 Acc : 47.22222222222222%\n",
      "75.0\n",
      "\n",
      "Epoch: 116\n",
      "Train epoch : 116 loss : 0.3210917264223099 Acc : 87.96296296296296%\n",
      "\n",
      "Epoch: 116\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 116 loss : 0.6980208953221639 Acc : 63.888888888888886%\n",
      "75.0\n",
      "\n",
      "Epoch: 117\n",
      "Train epoch : 117 loss : 0.32631987120424 Acc : 87.03703703703704%\n",
      "\n",
      "Epoch: 117\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 117 loss : 1.082548459370931 Acc : 61.111111111111114%\n",
      "75.0\n",
      "\n",
      "Epoch: 118\n",
      "Train epoch : 118 loss : 0.23737692939383642 Acc : 93.51851851851852%\n",
      "\n",
      "Epoch: 118\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 118 loss : 0.998808354139328 Acc : 58.333333333333336%\n",
      "75.0\n",
      "\n",
      "Epoch: 119\n",
      "Train epoch : 119 loss : 0.44107934832572937 Acc : 84.25925925925925%\n",
      "\n",
      "Epoch: 119\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 119 loss : 2.8450915813446045 Acc : 47.22222222222222%\n",
      "75.0\n",
      "\n",
      "Epoch: 120\n",
      "Train epoch : 120 loss : 0.3929713900600161 Acc : 84.25925925925925%\n",
      "\n",
      "Epoch: 120\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 120 loss : 0.7725211381912231 Acc : 61.111111111111114%\n",
      "75.0\n",
      "\n",
      "Epoch: 121\n",
      "Train epoch : 121 loss : 0.3613803195101874 Acc : 83.33333333333333%\n",
      "\n",
      "Epoch: 121\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 121 loss : 1.4733501275380452 Acc : 44.44444444444444%\n",
      "75.0\n",
      "\n",
      "Epoch: 122\n",
      "Train epoch : 122 loss : 0.511724095259394 Acc : 82.4074074074074%\n",
      "\n",
      "Epoch: 122\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 122 loss : 4.588468233744304 Acc : 50.0%\n",
      "75.0\n",
      "\n",
      "Epoch: 123\n",
      "Train epoch : 123 loss : 0.3588287851640156 Acc : 87.96296296296296%\n",
      "\n",
      "Epoch: 123\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 123 loss : 1.1063746809959412 Acc : 52.77777777777778%\n",
      "75.0\n",
      "\n",
      "Epoch: 124\n",
      "Train epoch : 124 loss : 0.31255245740924564 Acc : 88.88888888888889%\n",
      "\n",
      "Epoch: 124\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 124 loss : 1.3128761152426403 Acc : 58.333333333333336%\n",
      "75.0\n",
      "\n",
      "Epoch: 125\n",
      "Train epoch : 125 loss : 0.4578371218272618 Acc : 79.62962962962963%\n",
      "\n",
      "Epoch: 125\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 125 loss : 2.4688803950945535 Acc : 33.333333333333336%\n",
      "75.0\n",
      "\n",
      "Epoch: 126\n",
      "Train epoch : 126 loss : 0.2637461381299155 Acc : 93.51851851851852%\n",
      "\n",
      "Epoch: 126\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 126 loss : 0.932904064655304 Acc : 58.333333333333336%\n",
      "75.0\n",
      "\n",
      "Epoch: 127\n",
      "Train epoch : 127 loss : 0.3051191142627171 Acc : 89.81481481481481%\n",
      "\n",
      "Epoch: 127\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 127 loss : 1.2889430920283 Acc : 58.333333333333336%\n",
      "75.0\n",
      "\n",
      "Epoch: 128\n",
      "Train epoch : 128 loss : 0.36391774884292055 Acc : 81.48148148148148%\n",
      "\n",
      "Epoch: 128\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 128 loss : 0.9302060604095459 Acc : 58.333333333333336%\n",
      "75.0\n",
      "\n",
      "Epoch: 129\n",
      "Train epoch : 129 loss : 0.37500346984182087 Acc : 83.33333333333333%\n",
      "\n",
      "Epoch: 129\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 129 loss : 3.9506206115086875 Acc : 38.888888888888886%\n",
      "75.0\n",
      "\n",
      "Epoch: 130\n",
      "Train epoch : 130 loss : 0.432813789163317 Acc : 84.25925925925925%\n",
      "\n",
      "Epoch: 130\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 130 loss : 2.8295695781707764 Acc : 30.555555555555557%\n",
      "75.0\n",
      "\n",
      "Epoch: 131\n",
      "Train epoch : 131 loss : 0.3328183442354202 Acc : 88.88888888888889%\n",
      "\n",
      "Epoch: 131\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 131 loss : 0.9556625485420227 Acc : 55.55555555555556%\n",
      "75.0\n",
      "\n",
      "Epoch: 132\n",
      "Train epoch : 132 loss : 0.3275653358016695 Acc : 87.03703703703704%\n",
      "\n",
      "Epoch: 132\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 132 loss : 1.028737634420395 Acc : 66.66666666666667%\n",
      "75.0\n",
      "\n",
      "Epoch: 133\n",
      "Train epoch : 133 loss : 0.3411377966403961 Acc : 82.4074074074074%\n",
      "\n",
      "Epoch: 133\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 133 loss : 0.8675612012545267 Acc : 58.333333333333336%\n",
      "75.0\n",
      "\n",
      "Epoch: 134\n",
      "Train epoch : 134 loss : 0.2505561943565096 Acc : 89.81481481481481%\n",
      "\n",
      "Epoch: 134\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 134 loss : 0.9455231428146362 Acc : 63.888888888888886%\n",
      "75.0\n",
      "\n",
      "Epoch: 135\n",
      "Train epoch : 135 loss : 0.2409320558820452 Acc : 88.88888888888889%\n",
      "\n",
      "Epoch: 135\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 135 loss : 1.4062949816385906 Acc : 50.0%\n",
      "75.0\n",
      "\n",
      "Epoch: 136\n",
      "Train epoch : 136 loss : 0.34596153029373716 Acc : 84.25925925925925%\n",
      "\n",
      "Epoch: 136\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 136 loss : 0.6887157956759135 Acc : 66.66666666666667%\n",
      "75.0\n",
      "\n",
      "Epoch: 137\n",
      "Train epoch : 137 loss : 0.2292065652353423 Acc : 94.44444444444444%\n",
      "\n",
      "Epoch: 137\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 137 loss : 1.1627864837646484 Acc : 69.44444444444444%\n",
      "75.0\n",
      "\n",
      "Epoch: 138\n",
      "Train epoch : 138 loss : 0.2941052094101906 Acc : 88.88888888888889%\n",
      "\n",
      "Epoch: 138\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 138 loss : 1.865288257598877 Acc : 58.333333333333336%\n",
      "75.0\n",
      "\n",
      "Epoch: 139\n",
      "Train epoch : 139 loss : 0.3577257011617933 Acc : 87.96296296296296%\n",
      "\n",
      "Epoch: 139\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 139 loss : 0.770797441403071 Acc : 63.888888888888886%\n",
      "75.0\n",
      "\n",
      "Epoch: 140\n",
      "Train epoch : 140 loss : 0.2299643840108599 Acc : 91.66666666666667%\n",
      "\n",
      "Epoch: 140\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 140 loss : 0.5125808119773865 Acc : 72.22222222222223%\n",
      "75.0\n",
      "\n",
      "Epoch: 141\n",
      "Train epoch : 141 loss : 0.2792112933737891 Acc : 87.03703703703704%\n",
      "\n",
      "Epoch: 141\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 141 loss : 0.4539664586385091 Acc : 77.77777777777777%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 142\n",
      "Train epoch : 142 loss : 0.2623540737799236 Acc : 92.5925925925926%\n",
      "\n",
      "Epoch: 142\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 142 loss : 0.712326834599177 Acc : 66.66666666666667%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 143\n",
      "Train epoch : 143 loss : 0.22720717319420405 Acc : 89.81481481481481%\n",
      "\n",
      "Epoch: 143\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 143 loss : 1.0065218210220337 Acc : 63.888888888888886%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 144\n",
      "Train epoch : 144 loss : 0.3732587162937437 Acc : 82.4074074074074%\n",
      "\n",
      "Epoch: 144\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 144 loss : 1.2652347087860107 Acc : 50.0%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 145\n",
      "Train epoch : 145 loss : 0.23348769545555115 Acc : 92.5925925925926%\n",
      "\n",
      "Epoch: 145\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 145 loss : 0.6130536198616028 Acc : 72.22222222222223%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 146\n",
      "Train epoch : 146 loss : 0.35392057044165476 Acc : 85.18518518518519%\n",
      "\n",
      "Epoch: 146\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 146 loss : 1.3987054030100505 Acc : 47.22222222222222%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 147\n",
      "Train epoch : 147 loss : 0.33249777449028833 Acc : 86.11111111111111%\n",
      "\n",
      "Epoch: 147\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 147 loss : 0.993787924448649 Acc : 58.333333333333336%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 148\n",
      "Train epoch : 148 loss : 0.26559782347508837 Acc : 90.74074074074075%\n",
      "\n",
      "Epoch: 148\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 148 loss : 1.1843343178431194 Acc : 61.111111111111114%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 149\n",
      "Train epoch : 149 loss : 0.23265252581664495 Acc : 90.74074074074075%\n",
      "\n",
      "Epoch: 149\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 149 loss : 1.6144137382507324 Acc : 50.0%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 150\n",
      "Train epoch : 150 loss : 0.2532216102949211 Acc : 91.66666666666667%\n",
      "\n",
      "Epoch: 150\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 150 loss : 1.3412083387374878 Acc : 69.44444444444444%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 151\n",
      "Train epoch : 151 loss : 0.29760450550488066 Acc : 87.96296296296296%\n",
      "\n",
      "Epoch: 151\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 151 loss : 0.9670470058917999 Acc : 66.66666666666667%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 152\n",
      "Train epoch : 152 loss : 0.367131093783038 Acc : 83.33333333333333%\n",
      "\n",
      "Epoch: 152\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 152 loss : 0.48838526010513306 Acc : 72.22222222222223%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 153\n",
      "Train epoch : 153 loss : 0.2507318492446627 Acc : 92.5925925925926%\n",
      "\n",
      "Epoch: 153\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 153 loss : 1.1081496874491374 Acc : 61.111111111111114%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 154\n",
      "Train epoch : 154 loss : 0.27757589519023895 Acc : 90.74074074074075%\n",
      "\n",
      "Epoch: 154\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 154 loss : 2.639411369959513 Acc : 41.666666666666664%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 155\n",
      "Train epoch : 155 loss : 0.22940534779003688 Acc : 92.5925925925926%\n",
      "\n",
      "Epoch: 155\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 155 loss : 0.7867136100927988 Acc : 66.66666666666667%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 156\n",
      "Train epoch : 156 loss : 0.262994113777365 Acc : 90.74074074074075%\n",
      "\n",
      "Epoch: 156\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 156 loss : 0.9506201806167761 Acc : 61.111111111111114%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 157\n",
      "Train epoch : 157 loss : 0.2606283032468387 Acc : 90.74074074074075%\n",
      "\n",
      "Epoch: 157\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 157 loss : 1.6859334309895833 Acc : 41.666666666666664%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 158\n",
      "Train epoch : 158 loss : 0.3053812086582184 Acc : 88.88888888888889%\n",
      "\n",
      "Epoch: 158\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 158 loss : 0.758785605430603 Acc : 61.111111111111114%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 159\n",
      "Train epoch : 159 loss : 0.3480519290481295 Acc : 88.88888888888889%\n",
      "\n",
      "Epoch: 159\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 159 loss : 3.9238500595092773 Acc : 47.22222222222222%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 160\n",
      "Train epoch : 160 loss : 0.49126163125038147 Acc : 81.48148148148148%\n",
      "\n",
      "Epoch: 160\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 160 loss : 10.690419514973959 Acc : 27.77777777777778%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 161\n",
      "Train epoch : 161 loss : 0.33136784923928125 Acc : 86.11111111111111%\n",
      "\n",
      "Epoch: 161\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 161 loss : 2.359575947125753 Acc : 33.333333333333336%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 162\n",
      "Train epoch : 162 loss : 0.2181218255843435 Acc : 90.74074074074075%\n",
      "\n",
      "Epoch: 162\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 162 loss : 1.4293891588846843 Acc : 44.44444444444444%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 163\n",
      "Train epoch : 163 loss : 0.2340575499194009 Acc : 89.81481481481481%\n",
      "\n",
      "Epoch: 163\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 163 loss : 0.8203146656354269 Acc : 63.888888888888886%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 164\n",
      "Train epoch : 164 loss : 0.18816076245691096 Acc : 92.5925925925926%\n",
      "\n",
      "Epoch: 164\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 164 loss : 0.5804389094312986 Acc : 69.44444444444444%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 165\n",
      "Train epoch : 165 loss : 0.2722187861800194 Acc : 89.81481481481481%\n",
      "\n",
      "Epoch: 165\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 165 loss : 3.5265018542607627 Acc : 47.22222222222222%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 166\n",
      "Train epoch : 166 loss : 0.27031381002494265 Acc : 91.66666666666667%\n",
      "\n",
      "Epoch: 166\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 166 loss : 0.4912390510241191 Acc : 75.0%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 167\n",
      "Train epoch : 167 loss : 0.2878239420907838 Acc : 91.66666666666667%\n",
      "\n",
      "Epoch: 167\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 167 loss : 0.6828131874402364 Acc : 63.888888888888886%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 168\n",
      "Train epoch : 168 loss : 0.13939918684107916 Acc : 95.37037037037037%\n",
      "\n",
      "Epoch: 168\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 168 loss : 0.8972026060024897 Acc : 66.66666666666667%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 169\n",
      "Train epoch : 169 loss : 0.18972577420728548 Acc : 91.66666666666667%\n",
      "\n",
      "Epoch: 169\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 169 loss : 0.6137356956799825 Acc : 75.0%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 170\n",
      "Train epoch : 170 loss : 0.191154345870018 Acc : 96.29629629629629%\n",
      "\n",
      "Epoch: 170\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 170 loss : 1.7145926157633464 Acc : 61.111111111111114%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 171\n",
      "Train epoch : 171 loss : 0.20029477242912566 Acc : 93.51851851851852%\n",
      "\n",
      "Epoch: 171\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 171 loss : 1.463301698366801 Acc : 58.333333333333336%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 172\n",
      "Train epoch : 172 loss : 0.19115307288510458 Acc : 94.44444444444444%\n",
      "\n",
      "Epoch: 172\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 172 loss : 2.0567872524261475 Acc : 61.111111111111114%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 173\n",
      "Train epoch : 173 loss : 0.30291849055460524 Acc : 88.88888888888889%\n",
      "\n",
      "Epoch: 173\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 173 loss : 0.8237507045269012 Acc : 58.333333333333336%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 174\n",
      "Train epoch : 174 loss : 0.2665748564260347 Acc : 85.18518518518519%\n",
      "\n",
      "Epoch: 174\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 174 loss : 1.065009633700053 Acc : 66.66666666666667%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 175\n",
      "Train epoch : 175 loss : 0.19523063514913833 Acc : 93.51851851851852%\n",
      "\n",
      "Epoch: 175\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 175 loss : 1.8178375909725826 Acc : 38.888888888888886%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 176\n",
      "Train epoch : 176 loss : 0.16160405852964946 Acc : 94.44444444444444%\n",
      "\n",
      "Epoch: 176\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 176 loss : 0.7911520004272461 Acc : 72.22222222222223%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 177\n",
      "Train epoch : 177 loss : 0.17820789452110017 Acc : 95.37037037037037%\n",
      "\n",
      "Epoch: 177\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 177 loss : 0.7783105572064718 Acc : 72.22222222222223%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 178\n",
      "Train epoch : 178 loss : 0.2459135502576828 Acc : 90.74074074074075%\n",
      "\n",
      "Epoch: 178\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 178 loss : 1.2578376332918804 Acc : 75.0%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 179\n",
      "Train epoch : 179 loss : 0.17026872773255622 Acc : 94.44444444444444%\n",
      "\n",
      "Epoch: 179\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 179 loss : 1.1242717107137044 Acc : 58.333333333333336%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 180\n",
      "Train epoch : 180 loss : 0.21310744328158243 Acc : 92.5925925925926%\n",
      "\n",
      "Epoch: 180\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 180 loss : 1.4702906608581543 Acc : 61.111111111111114%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 181\n",
      "Train epoch : 181 loss : 0.22707117455346243 Acc : 91.66666666666667%\n",
      "\n",
      "Epoch: 181\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 181 loss : 3.441699186960856 Acc : 47.22222222222222%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 182\n",
      "Train epoch : 182 loss : 0.2106773475451129 Acc : 92.5925925925926%\n",
      "\n",
      "Epoch: 182\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 182 loss : 1.8921126127243042 Acc : 61.111111111111114%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 183\n",
      "Train epoch : 183 loss : 0.3409596383571625 Acc : 84.25925925925925%\n",
      "\n",
      "Epoch: 183\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 183 loss : 1.0088192025820415 Acc : 63.888888888888886%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 184\n",
      "Train epoch : 184 loss : 0.19680234576974595 Acc : 94.44444444444444%\n",
      "\n",
      "Epoch: 184\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 184 loss : 6.076554457346599 Acc : 38.888888888888886%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 185\n",
      "Train epoch : 185 loss : 0.25356294959783554 Acc : 90.74074074074075%\n",
      "\n",
      "Epoch: 185\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 185 loss : 7.673834164937337 Acc : 44.44444444444444%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 186\n",
      "Train epoch : 186 loss : 0.2817076284970556 Acc : 88.88888888888889%\n",
      "\n",
      "Epoch: 186\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 186 loss : 2.071967442830404 Acc : 58.333333333333336%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 187\n",
      "Train epoch : 187 loss : 0.2809109538793564 Acc : 87.96296296296296%\n",
      "\n",
      "Epoch: 187\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 187 loss : 0.5435485442479452 Acc : 69.44444444444444%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 188\n",
      "Train epoch : 188 loss : 0.21245079381125315 Acc : 94.44444444444444%\n",
      "\n",
      "Epoch: 188\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 188 loss : 1.9315896431605022 Acc : 66.66666666666667%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 189\n",
      "Train epoch : 189 loss : 0.19968039223126002 Acc : 95.37037037037037%\n",
      "\n",
      "Epoch: 189\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 189 loss : 0.8830269575119019 Acc : 55.55555555555556%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 190\n",
      "Train epoch : 190 loss : 0.2369102963379451 Acc : 90.74074074074075%\n",
      "\n",
      "Epoch: 190\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 190 loss : 1.3498677015304565 Acc : 61.111111111111114%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 191\n",
      "Train epoch : 191 loss : 0.23581928546939576 Acc : 91.66666666666667%\n",
      "\n",
      "Epoch: 191\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 191 loss : 1.5116702516873677 Acc : 61.111111111111114%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 192\n",
      "Train epoch : 192 loss : 0.278458942260061 Acc : 84.25925925925925%\n",
      "\n",
      "Epoch: 192\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 192 loss : 1.10676904519399 Acc : 63.888888888888886%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 193\n",
      "Train epoch : 193 loss : 0.16069258749485016 Acc : 96.29629629629629%\n",
      "\n",
      "Epoch: 193\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 193 loss : 1.3917123079299927 Acc : 55.55555555555556%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 194\n",
      "Train epoch : 194 loss : 0.10018152637141091 Acc : 97.22222222222223%\n",
      "\n",
      "Epoch: 194\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 194 loss : 0.6500483751296997 Acc : 72.22222222222223%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 195\n",
      "Train epoch : 195 loss : 0.14193214795419148 Acc : 95.37037037037037%\n",
      "\n",
      "Epoch: 195\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 195 loss : 0.6905301511287689 Acc : 75.0%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 196\n",
      "Train epoch : 196 loss : 0.14647885518414633 Acc : 96.29629629629629%\n",
      "\n",
      "Epoch: 196\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 196 loss : 1.3153361876805623 Acc : 52.77777777777778%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 197\n",
      "Train epoch : 197 loss : 0.21360925159284047 Acc : 90.74074074074075%\n",
      "\n",
      "Epoch: 197\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 197 loss : 1.275050679842631 Acc : 61.111111111111114%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 198\n",
      "Train epoch : 198 loss : 0.18477667229516165 Acc : 93.51851851851852%\n",
      "\n",
      "Epoch: 198\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 198 loss : 0.8507151305675507 Acc : 63.888888888888886%\n",
      "77.77777777777777\n",
      "\n",
      "Epoch: 199\n",
      "Train epoch : 199 loss : 0.2857977364744459 Acc : 86.11111111111111%\n",
      "\n",
      "Epoch: 199\n",
      "{0: 9, 1: 16, 2: 11}\n",
      "Test epoch : 199 loss : 6.830209573109944 Acc : 38.888888888888886%\n",
      "77.77777777777777\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 및 평가\n",
    "BEST_SCORE = 0\n",
    "for epoch in range(epochs):\n",
    "    train(epoch)\n",
    "    test(epoch, valloader)\n",
    "    print(BEST_SCORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: -1\n",
      "{0: 10, 1: 9, 2: 17}\n",
      "Test epoch : -1 loss : 0.6348754266897837 Acc : 83.33333333333333%\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋에서 평가\n",
    "model.load_state_dict(torch.load(os.path.join(save_path, f'teacher.pth')))\n",
    "test(-1, testloader, 'test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fskd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
